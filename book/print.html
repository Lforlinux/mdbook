<!DOCTYPE HTML>
<html lang="en" class="navy sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Projects Portfolio</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="A comprehensive portfolio showcasing DevOps, SRE, and Cloud engineering projects">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "navy";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Projects Portfolio</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/Lforlinux/mdbook" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="projects-portfolio"><a class="header" href="#projects-portfolio">Projects Portfolio</a></h1>
<p>Welcome to my projects portfolio! This documentation showcases three major projects I've developed, each demonstrating different aspects of modern DevOps, SRE, and cloud engineering practices.</p>
<h2 id="-projects-overview"><a class="header" href="#-projects-overview">üöÄ Projects Overview</a></h2>
<h3 id="cloud-cv"><a class="header" href="#cloud-cv"><a href="cloud-cv/introduction.html">Cloud-CV</a></a></h3>
<p>A modern, cloud-hosted resume showcasing SRE/DevOps expertise with AWS best practices. Features infrastructure as code with Terraform, CI/CD pipelines, serverless architecture, and comprehensive monitoring.</p>
<p><strong>Key Technologies:</strong> AWS, Terraform, GitHub Actions, Lambda, CloudFront, S3, LocalStack</p>
<h3 id="stack-quest"><a class="header" href="#stack-quest"><a href="stack-quest/introduction.html">Stack-Quest</a></a></h3>
<p>A comprehensive knowledge base and challenge platform for DevOps, SRE, and Cloud engineering. Features curated questions across 12+ categories and hands-on challenges for practical learning.</p>
<p><strong>Key Technologies:</strong> GitHub Pages, JavaScript, Markdown, Responsive Design</p>
<h3 id="opensource-llm-rag-stack"><a class="header" href="#opensource-llm-rag-stack"><a href="opensource-llm-rag-stack/introduction.html">Opensource-LLM-RAG-Stack</a></a></h3>
<p>A production-ready, containerized RAG (Retrieval-Augmented Generation) stack with comprehensive monitoring, observability, and enterprise-grade DevOps practices.</p>
<p><strong>Key Technologies:</strong> Docker, Ollama, Chroma, PostgreSQL, Prometheus, Grafana, Open WebUI</p>
<h3 id="kubernetes-gitops-platform"><a class="header" href="#kubernetes-gitops-platform"><a href="kubernetes-gitops-platform/introduction.html">Kubernetes GitOps Platform</a></a></h3>
<p>A production-ready AWS EKS cluster with complete GitOps platform toolkit, automated deployment, monitoring, and observability. Combines infrastructure as code with ArgoCD for automated platform management.</p>
<p><strong>Key Technologies:</strong> Terraform, AWS EKS, Kubernetes, ArgoCD, Prometheus, Grafana, Loki, Helm</p>
<hr />
<h2 id="-navigation"><a class="header" href="#-navigation">üìö Navigation</a></h2>
<p>Use the sidebar to navigate through each project's detailed documentation, including:</p>
<ul>
<li>Architecture diagrams</li>
<li>Setup and deployment guides</li>
<li>Feature documentation</li>
<li>Technical implementation details</li>
<li>Best practices and troubleshooting</li>
</ul>
<hr />
<p><em>This portfolio demonstrates modern DevOps practices, cloud-native architecture, and production-ready system design.</em></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-1"><a class="header" href="#cloud-cv-1">Cloud-CV</a></h1>
<p>A modern, cloud-hosted resume showcasing SRE/DevOps expertise with AWS best practices.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Cloud-CV is a serverless, cloud-hosted portfolio website that demonstrates enterprise-grade DevOps practices. The project showcases infrastructure as code, CI/CD automation, serverless architecture, and comprehensive cloud security.</p>
<p><img src="cloud-cv/../images/Cloud-CV.png" alt="Cloud CV Architecture" /></p>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<ul>
<li><strong>Infrastructure as Code</strong>: Terraform for reproducible infrastructure</li>
<li><strong>CI/CD Pipeline</strong>: GitHub Actions for automated deployment</li>
<li><strong>Serverless</strong>: AWS Lambda for visitor counter</li>
<li><strong>CDN</strong>: CloudFront for global content delivery</li>
<li><strong>Security</strong>: SSL/TLS, IAM roles, least privilege access</li>
<li><strong>Monitoring</strong>: CloudWatch for observability</li>
</ul>
<h2 id="project-highlights"><a class="header" href="#project-highlights">Project Highlights</a></h2>
<p>This project demonstrates:</p>
<ul>
<li>Modern cloud architecture patterns</li>
<li>Infrastructure automation</li>
<li>DevOps best practices</li>
<li>Cost-effective serverless solutions</li>
<li>Security-first design principles</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-architecture"><a class="header" href="#cloud-cv-architecture">Cloud-CV Architecture</a></h1>
<h2 id="system-architecture"><a class="header" href="#system-architecture">System Architecture</a></h2>
<p><img src="cloud-cv/../images/Cloud-CV.png" alt="Cloud CV Architecture" /></p>
<p>The Cloud-CV architecture is built on AWS serverless services, providing a scalable, cost-effective solution for hosting a static portfolio website.</p>
<h2 id="components"><a class="header" href="#components">Components</a></h2>
<h3 id="frontend"><a class="header" href="#frontend">Frontend</a></h3>
<ul>
<li><strong>Static Website</strong>: HTML, CSS, and JavaScript files</li>
<li><strong>Hosting</strong>: AWS S3 bucket with static website hosting enabled</li>
<li><strong>CDN</strong>: CloudFront distribution for global content delivery</li>
<li><strong>SSL/TLS</strong>: Automatic HTTPS via CloudFront</li>
</ul>
<h3 id="backend-services"><a class="header" href="#backend-services">Backend Services</a></h3>
<ul>
<li><strong>Visitor Counter</strong>: AWS Lambda function for tracking page views</li>
<li><strong>Database</strong>: DynamoDB table for storing visitor count data</li>
<li><strong>API Gateway</strong>: REST API endpoint for Lambda function</li>
</ul>
<h3 id="infrastructure"><a class="header" href="#infrastructure">Infrastructure</a></h3>
<ul>
<li><strong>Infrastructure as Code</strong>: Terraform for all AWS resources</li>
<li><strong>CI/CD</strong>: GitHub Actions for automated deployment</li>
<li><strong>Monitoring</strong>: CloudWatch for logs and metrics</li>
</ul>
<h2 id="data-flow"><a class="header" href="#data-flow">Data Flow</a></h2>
<ol>
<li>User accesses website via CloudFront</li>
<li>CloudFront serves static content from S3</li>
<li>Frontend JavaScript calls API Gateway endpoint</li>
<li>API Gateway invokes Lambda function</li>
<li>Lambda updates DynamoDB with visitor count</li>
<li>Response returned to frontend for display</li>
</ol>
<h2 id="security-features"><a class="header" href="#security-features">Security Features</a></h2>
<ul>
<li><strong>IAM Roles</strong>: Least privilege access for Lambda function</li>
<li><strong>S3 Bucket Policies</strong>: Restrictive access controls</li>
<li><strong>CloudFront OAC</strong>: Origin Access Control for S3</li>
<li><strong>HTTPS Only</strong>: Enforced SSL/TLS encryption</li>
<li><strong>No Public S3 Access</strong>: All access through CloudFront</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-deployment"><a class="header" href="#cloud-cv-deployment">Cloud-CV Deployment</a></h1>
<h2 id="production-deployment"><a class="header" href="#production-deployment">Production Deployment</a></h2>
<h3 id="infrastructure-as-code-terraform"><a class="header" href="#infrastructure-as-code-terraform">Infrastructure as Code (Terraform)</a></h3>
<p>The project uses Terraform to provision AWS resources:</p>
<pre><code class="language-hcl"># S3 Bucket for static website hosting
resource "aws_s3_bucket" "website" {
  bucket = "cloud-cv-${random_id.bucket_suffix.hex}"
}

# CloudFront distribution for CDN
resource "aws_cloudfront_distribution" "website" {
  origin {
    domain_name = aws_s3_bucket.website.bucket_regional_domain_name
    origin_access_control_id = aws_cloudfront_origin_access_control.website.id
  }
}

# Lambda function for visitor counter
resource "aws_lambda_function" "visitor_counter" {
  filename         = "../lambda/visitor_counter.zip"
  function_name    = "cloud-cv-visitor-counter"
  runtime         = "python3.11"
}

# DynamoDB table for visitor data
resource "aws_dynamodb_table" "visitor_counter" {
  name           = "visitor-counter"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"
}
</code></pre>
<h3 id="github-actions-cicd-pipeline"><a class="header" href="#github-actions-cicd-pipeline">GitHub Actions CI/CD Pipeline</a></h3>
<p>The project uses GitHub Actions for automated deployment:</p>
<pre><code class="language-yaml">name: Deploy Cloud CV
on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Deploy Infrastructure
        run: |
          cd infra/terraform
          terraform init
          terraform plan
          terraform apply -auto-approve
      
      - name: Upload Frontend Files
        run: |
          aws s3 cp frontend/index.html s3://$(terraform output -raw bucket_name)/
          aws s3 cp frontend/styles.css s3://$(terraform output -raw bucket_name)/
          aws s3 cp frontend/script.js s3://$(terraform output -raw bucket_name)/
          aws s3 cp cv.pdf s3://$(terraform output -raw bucket_name)/
      
      - name: Invalidate CloudFront Cache
        run: |
          aws cloudfront create-invalidation --distribution-id $(terraform output -raw cloudfront_distribution_id) --paths "/*"
</code></pre>
<h3 id="deployment-process"><a class="header" href="#deployment-process">Deployment Process</a></h3>
<ol>
<li><strong>Push to main branch</strong> triggers GitHub Actions</li>
<li><strong>Terraform applies</strong> infrastructure changes</li>
<li><strong>Frontend files</strong> are uploaded to S3</li>
<li><strong>CloudFront cache</strong> is invalidated</li>
<li><strong>Website</strong> is live with latest changes</li>
</ol>
<h3 id="required-github-secrets"><a class="header" href="#required-github-secrets">Required GitHub Secrets</a></h3>
<ul>
<li><code>AWS_ACCESS_KEY_ID</code></li>
<li><code>AWS_SECRET_ACCESS_KEY</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-local-development-with-localstack"><a class="header" href="#cloud-cv-local-development-with-localstack">Cloud-CV Local Development with LocalStack</a></h1>
<h2 id="what-is-localstack"><a class="header" href="#what-is-localstack">What is LocalStack?</a></h2>
<p>LocalStack is a fully functional local AWS cloud stack that runs on your machine. It provides:</p>
<ul>
<li><strong>Real AWS APIs</strong>: Use actual AWS SDKs and CLI commands</li>
<li><strong>Cost-Free Development</strong>: No AWS charges during development</li>
<li><strong>Offline Development</strong>: Works without internet connection</li>
<li><strong>Terraform Compatibility</strong>: Works seamlessly with existing Terraform code</li>
<li><strong>Realistic Testing</strong>: Closer to production environment than mocks</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<h3 id="1-start-localstack"><a class="header" href="#1-start-localstack">1. Start LocalStack</a></h3>
<pre><code class="language-bash"># Start LocalStack development environment
./scripts/local-dev-start.sh start

# Or simply (start is the default)
./scripts/local-dev-start.sh
</code></pre>
<h3 id="2-upload-frontend-files"><a class="header" href="#2-upload-frontend-files">2. Upload Frontend Files</a></h3>
<pre><code class="language-bash"># Upload frontend files to S3
./scripts/local-dev-start.sh upload
</code></pre>
<h3 id="3-check-status"><a class="header" href="#3-check-status">3. Check Status</a></h3>
<pre><code class="language-bash"># Check LocalStack status
./scripts/local-dev-start.sh status
</code></pre>
<h3 id="4-stop-localstack"><a class="header" href="#4-stop-localstack">4. Stop LocalStack</a></h3>
<pre><code class="language-bash"># Stop LocalStack when done
./scripts/local-dev-start.sh stop
</code></pre>
<h2 id="localstack-architecture"><a class="header" href="#localstack-architecture">LocalStack Architecture</a></h2>
<h3 id="services-included"><a class="header" href="#services-included">Services Included</a></h3>
<ul>
<li><strong>S3</strong>: Static website hosting</li>
<li><strong>DynamoDB</strong>: NoSQL database for visitor counter</li>
<li><strong>Lambda</strong>: Serverless visitor counter function</li>
<li><strong>API Gateway</strong>: REST API endpoint</li>
<li><strong>IAM</strong>: Identity and access management</li>
<li><strong>CloudWatch</strong>: Monitoring and logging</li>
</ul>
<h3 id="access-urls"><a class="header" href="#access-urls">Access URLs</a></h3>
<ul>
<li><strong>Main Website</strong>: http://localhost:4566/cloud-cv-local/index.html</li>
<li><strong>S3 Browser</strong>: http://localhost:4566/cloud-cv-local/</li>
<li><strong>Health Check</strong>: http://localhost:4566/_localstack/health</li>
</ul>
<h2 id="development-workflow"><a class="header" href="#development-workflow">Development Workflow</a></h2>
<h3 id="1-start-development-environment"><a class="header" href="#1-start-development-environment">1. Start Development Environment</a></h3>
<pre><code class="language-bash"># Start LocalStack
./scripts/local-dev-start.sh start
</code></pre>
<h3 id="2-make-changes"><a class="header" href="#2-make-changes">2. Make Changes</a></h3>
<pre><code class="language-bash"># Edit frontend files
nano frontend/index.html
nano frontend/styles.css
nano frontend/script.js
</code></pre>
<h3 id="3-upload-changes"><a class="header" href="#3-upload-changes">3. Upload Changes</a></h3>
<pre><code class="language-bash"># Upload updated files
./scripts/local-dev-start.sh upload
</code></pre>
<h3 id="4-test-changes"><a class="header" href="#4-test-changes">4. Test Changes</a></h3>
<pre><code class="language-bash"># Open browser
open http://localhost:4566/cloud-cv-local/index.html
</code></pre>
<h3 id="5-stop-when-done"><a class="header" href="#5-stop-when-done">5. Stop When Done</a></h3>
<pre><code class="language-bash"># Stop LocalStack
./scripts/local-dev-start.sh stop
</code></pre>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="localstack-not-starting"><a class="header" href="#localstack-not-starting">LocalStack Not Starting</a></h3>
<pre><code class="language-bash"># Check if port 4566 is in use
lsof -i :4566

# Kill process using port
sudo kill -9 $(lsof -t -i:4566)

# Start LocalStack again
./scripts/local-dev-start.sh start
</code></pre>
<h3 id="container-conflicts"><a class="header" href="#container-conflicts">Container Conflicts</a></h3>
<pre><code class="language-bash"># Remove existing containers
docker rm -f localstack

# Start fresh
./scripts/local-dev-start.sh start
</code></pre>
<h3 id="aws-cli-issues"><a class="header" href="#aws-cli-issues">AWS CLI Issues</a></h3>
<pre><code class="language-bash"># Check AWS credentials
aws configure list

# Set LocalStack endpoint
export AWS_ENDPOINT_URL=http://localhost:4566

# Test S3 access
aws s3 ls --endpoint-url=http://localhost:4566
</code></pre>
<h2 id="security"><a class="header" href="#security">Security</a></h2>
<h3 id="localstack-credentials"><a class="header" href="#localstack-credentials">LocalStack Credentials</a></h3>
<pre><code class="language-bash"># Default LocalStack credentials
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
AWS_DEFAULT_REGION=us-east-1
</code></pre>
<h3 id="network-isolation"><a class="header" href="#network-isolation">Network Isolation</a></h3>
<ul>
<li>LocalStack runs in Docker container</li>
<li>Isolated from host network</li>
<li>No external access required</li>
<li>Safe for development</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-technical-implementation"><a class="header" href="#cloud-cv-technical-implementation">Cloud-CV Technical Implementation</a></h1>
<h2 id="frontend-implementation"><a class="header" href="#frontend-implementation">Frontend Implementation</a></h2>
<h3 id="html-structure"><a class="header" href="#html-structure">HTML Structure</a></h3>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;title&gt;Lekshmi Kolappan - Site Reliability Engineer&lt;/title&gt;
    &lt;link rel="stylesheet" href="styles.css"&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class="container"&gt;
        &lt;!-- Header with profile information --&gt;
        &lt;header class="header"&gt;
            &lt;div class="profile-section"&gt;
                &lt;div class="profile-image"&gt;
                    &lt;img src="profile.jpg" alt="Lekshmi Kolappan"&gt;
                &lt;/div&gt;
                &lt;div class="profile-info"&gt;
                    &lt;h1 class="name"&gt;Lekshmi Kolappan&lt;/h1&gt;
                    &lt;p class="title"&gt;SRE/DevOps Engineer&lt;/p&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/header&gt;
        
        &lt;!-- Main content sections --&gt;
        &lt;main class="main-content"&gt;
            &lt;!-- About, Skills, Experience, Education sections --&gt;
        &lt;/main&gt;
        
        &lt;!-- Visitor counter section --&gt;
        &lt;section class="section"&gt;
            &lt;h2&gt;Website Statistics&lt;/h2&gt;
            &lt;div class="stats-container"&gt;
                &lt;div class="stat-item"&gt;
                    &lt;div class="stat-number" id="visitor-count"&gt;Loading...&lt;/div&gt;
                    &lt;div class="stat-label"&gt;Total Visitors&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/section&gt;
    &lt;/div&gt;
    
    &lt;script src="script.js"&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="javascript-api-integration"><a class="header" href="#javascript-api-integration">JavaScript API Integration</a></h3>
<pre><code class="language-javascript">class CloudCV {
    constructor() {
        this.apiUrl = 'https://api-gateway-url/visitor-count';
        this.visitorCount = 0;
        this.init();
    }

    async loadVisitorCount() {
        try {
            const response = await fetch(this.apiUrl, {
                method: 'GET',
                headers: {
                    'Content-Type': 'application/json',
                },
                mode: 'cors'
            });

            if (!response.ok) {
                throw new Error('HTTP error! status: ' + response.status);
            }

            const data = await response.json();
            this.updateVisitorCount(data.visitor_count);
        } catch (error) {
            console.error('Error loading visitor count:', error);
            this.updateVisitorCount(0);
        }
    }

    updateVisitorCount(count) {
        this.visitorCount = count;
        const countElement = document.getElementById('visitor-count');
        if (countElement) {
            countElement.textContent = count.toLocaleString();
        }
    }
}
</code></pre>
<h2 id="backend-implementation"><a class="header" href="#backend-implementation">Backend Implementation</a></h2>
<h3 id="lambda-function-python"><a class="header" href="#lambda-function-python">Lambda Function (Python)</a></h3>
<pre><code class="language-python">import json
import boto3
import os
from datetime import datetime
from decimal import Decimal

# Initialize DynamoDB client
dynamodb = boto3.resource('dynamodb')
table_name = os.environ.get('DYNAMODB_TABLE', 'visitor-counter')
table = dynamodb.Table(table_name)

def decimal_default(obj):
    """Convert Decimal objects to int/float for JSON serialization"""
    if isinstance(obj, Decimal):
        return int(obj) if obj % 1 == 0 else float(obj)
    raise TypeError

def lambda_handler(event, context):
    """
    Lambda handler for visitor counter API
    """
    try:
        # Handle CORS preflight request
        if event.get('httpMethod') == 'OPTIONS':
            return {
                'statusCode': 200,
                'headers': {
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Headers': 'Content-Type',
                    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS'
                },
                'body': json.dumps({'message': 'CORS preflight'})
            }
        
        # Get current visitor count
        response = table.get_item(Key={'id': 'visitor_count'})
        
        if 'Item' in response:
            current_count = int(response['Item']['count'])
        else:
            current_count = 0
        
        # Increment visitor count
        new_count = current_count + 1
        
        # Update DynamoDB
        table.put_item(
            Item={
                'id': 'visitor_count',
                'count': new_count,
                'last_updated': datetime.utcnow().isoformat(),
                'timestamp': int(datetime.utcnow().timestamp())
            }
        )
        
        # Return response
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Content-Type': 'application/json'
            },
            'body': json.dumps({
                'visitor_count': new_count,
                'timestamp': datetime.utcnow().isoformat(),
                'status': 'success'
            }, default=decimal_default)
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Content-Type': 'application/json'
            },
            'body': json.dumps({
                'error': 'Internal server error',
                'message': str(e),
                'status': 'error'
            }, default=decimal_default)
        }
</code></pre>
<h2 id="infrastructure-as-code"><a class="header" href="#infrastructure-as-code">Infrastructure as Code</a></h2>
<h3 id="terraform-configuration"><a class="header" href="#terraform-configuration">Terraform Configuration</a></h3>
<pre><code class="language-hcl"># S3 Bucket for static website hosting
resource "aws_s3_bucket" "website" {
  bucket = "cloud-cv-${random_id.bucket_suffix.hex}"
  
  tags = {
    Project     = "Cloud-CV"
    Environment = "production"
    Owner       = "SRE-DevOps-Engineer"
    ManagedBy   = "Terraform"
  }
}

# S3 Bucket versioning
resource "aws_s3_bucket_versioning" "website" {
  bucket = aws_s3_bucket.website.id
  versioning_configuration {
    status = "Enabled"
  }
}

# S3 Bucket server-side encryption
resource "aws_s3_bucket_server_side_encryption_configuration" "website" {
  bucket = aws_s3_bucket.website.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
    bucket_key_enabled = true
  }
}

# CloudFront Distribution
resource "aws_cloudfront_distribution" "website" {
  origin {
    domain_name              = aws_s3_bucket.website.bucket_regional_domain_name
    origin_access_control_id = aws_cloudfront_origin_access_control.website.id
    origin_id                = "S3-${aws_s3_bucket.website.bucket}"
  }

  enabled             = true
  is_ipv6_enabled     = true
  comment             = "Cloud CV Website Distribution"
  default_root_object = "index.html"

  default_cache_behavior {
    allowed_methods        = ["DELETE", "GET", "HEAD", "OPTIONS", "PATCH", "POST", "PUT"]
    cached_methods        = ["GET", "HEAD"]
    target_origin_id       = "S3-${aws_s3_bucket.website.bucket}"
    compress               = true
    viewer_protocol_policy = "redirect-to-https"

    forwarded_values {
      query_string = false
      cookies {
        forward = "none"
      }
    }

    min_ttl     = 0
    default_ttl = 3600
    max_ttl     = 86400
  }

  # Error pages
  custom_error_response {
    error_code         = 404
    response_code      = 200
    response_page_path = "/index.html"
  }
}

# DynamoDB table for visitor counter
resource "aws_dynamodb_table" "visitor_counter" {
  name           = "cloud-cv-visitor-counter"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }
}

# Lambda function for visitor counter
resource "aws_lambda_function" "visitor_counter" {
  filename         = "../lambda/visitor_counter.zip"
  function_name    = "cloud-cv-visitor-counter"
  role            = aws_iam_role.lambda_role.arn
  handler         = "lambda_function.lambda_handler"
  runtime         = "python3.11"
  timeout         = 30

  environment {
    variables = {
      DYNAMODB_TABLE = aws_dynamodb_table.visitor_counter.name
    }
  }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-security--best-practices"><a class="header" href="#cloud-cv-security--best-practices">Cloud-CV Security &amp; Best Practices</a></h1>
<h2 id="s3-security"><a class="header" href="#s3-security">S3 Security</a></h2>
<ul>
<li><strong>Public Access Block</strong>: All public access blocked</li>
<li><strong>Encryption</strong>: Server-side encryption with AES256</li>
<li><strong>Versioning</strong>: Enabled for data protection</li>
<li><strong>Access Control</strong>: CloudFront OAC for secure access</li>
</ul>
<h2 id="lambda-security"><a class="header" href="#lambda-security">Lambda Security</a></h2>
<ul>
<li><strong>IAM Roles</strong>: Least privilege access</li>
<li><strong>Environment Variables</strong>: Secure configuration</li>
<li><strong>VPC</strong>: Not required for this use case</li>
<li><strong>Timeout</strong>: 30-second timeout limit</li>
</ul>
<h2 id="api-gateway-security"><a class="header" href="#api-gateway-security">API Gateway Security</a></h2>
<ul>
<li><strong>CORS</strong>: Properly configured</li>
<li><strong>HTTPS</strong>: Enforced redirect</li>
<li><strong>Rate Limiting</strong>: Built-in throttling</li>
<li><strong>Authentication</strong>: None required for public API</li>
</ul>
<h2 id="dynamodb-security"><a class="header" href="#dynamodb-security">DynamoDB Security</a></h2>
<ul>
<li><strong>Encryption</strong>: At rest encryption enabled</li>
<li><strong>Access Control</strong>: IAM-based permissions</li>
<li><strong>Backup</strong>: Point-in-time recovery</li>
<li><strong>Monitoring</strong>: CloudWatch integration</li>
</ul>
<h2 id="infrastructure-security"><a class="header" href="#infrastructure-security">Infrastructure Security</a></h2>
<h3 id="iam-roles-and-policies"><a class="header" href="#iam-roles-and-policies">IAM Roles and Policies</a></h3>
<pre><code class="language-hcl"># Lambda execution role
resource "aws_iam_role" "lambda_role" {
  name = "cloud-cv-lambda-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "lambda.amazonaws.com"
        }
      }
    ]
  })
}

# Lambda permissions for DynamoDB
resource "aws_iam_role_policy" "lambda_dynamodb" {
  name = "lambda-dynamodb-policy"
  role = aws_iam_role.lambda_role.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "dynamodb:GetItem",
          "dynamodb:PutItem",
          "dynamodb:UpdateItem"
        ]
        Resource = aws_dynamodb_table.visitor_counter.arn
      }
    ]
  })
}
</code></pre>
<h2 id="security-best-practices"><a class="header" href="#security-best-practices">Security Best Practices</a></h2>
<ol>
<li><strong>Defense in Depth</strong>: Multiple security layers</li>
<li><strong>Least Privilege</strong>: Minimal IAM permissions</li>
<li><strong>Encryption</strong>: Data at rest and in transit</li>
<li><strong>Monitoring</strong>: Security event logging</li>
<li><strong>Compliance</strong>: Follow AWS security guidelines</li>
<li><strong>Regular Audits</strong>: Review access and permissions</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-monitoring--observability"><a class="header" href="#cloud-cv-monitoring--observability">Cloud-CV Monitoring &amp; Observability</a></h1>
<h2 id="cloudwatch-metrics"><a class="header" href="#cloudwatch-metrics">CloudWatch Metrics</a></h2>
<h3 id="lambda-metrics"><a class="header" href="#lambda-metrics">Lambda Metrics</a></h3>
<ul>
<li><strong>Invocations</strong>: Number of function invocations</li>
<li><strong>Errors</strong>: Error count and error rate</li>
<li><strong>Duration</strong>: Execution time</li>
<li><strong>Throttles</strong>: Concurrent execution limits</li>
</ul>
<h3 id="dynamodb-metrics"><a class="header" href="#dynamodb-metrics">DynamoDB Metrics</a></h3>
<ul>
<li><strong>Read/Write Capacity</strong>: Throughput metrics</li>
<li><strong>Throttling</strong>: Throttled requests</li>
<li><strong>Consistent Reads</strong>: Strongly consistent reads</li>
<li><strong>Item Count</strong>: Table size metrics</li>
</ul>
<h3 id="cloudfront-metrics"><a class="header" href="#cloudfront-metrics">CloudFront Metrics</a></h3>
<ul>
<li><strong>Requests</strong>: Total request count</li>
<li><strong>Cache Hit Ratio</strong>: CDN efficiency</li>
<li><strong>Data Transfer</strong>: Bandwidth usage</li>
<li><strong>Error Rates</strong>: 4xx and 5xx errors</li>
</ul>
<h3 id="s3-metrics"><a class="header" href="#s3-metrics">S3 Metrics</a></h3>
<ul>
<li><strong>Request Metrics</strong>: GET, PUT, DELETE requests</li>
<li><strong>Storage Metrics</strong>: Bucket size</li>
<li><strong>Data Transfer</strong>: Bandwidth usage</li>
</ul>
<h2 id="custom-metrics"><a class="header" href="#custom-metrics">Custom Metrics</a></h2>
<pre><code class="language-python"># Lambda function with custom metrics
import boto3
from datetime import datetime

cloudwatch = boto3.client('cloudwatch')

def put_custom_metric(metric_name, value, unit='Count'):
    cloudwatch.put_metric_data(
        Namespace='CloudCV/VisitorCounter',
        MetricData=[
            {
                'MetricName': metric_name,
                'Value': value,
                'Unit': unit,
                'Timestamp': datetime.utcnow()
            }
        ]
    )

# Usage in Lambda
def lambda_handler(event, context):
    # ... visitor counter logic ...
    
    # Send custom metric
    put_custom_metric('VisitorCount', new_count)
    put_custom_metric('APIResponseTime', response_time, 'Milliseconds')
    
    return response
</code></pre>
<h2 id="logging-strategy"><a class="header" href="#logging-strategy">Logging Strategy</a></h2>
<h3 id="lambda-logs"><a class="header" href="#lambda-logs">Lambda Logs</a></h3>
<ul>
<li><strong>CloudWatch Logs</strong>: Automatic log collection</li>
<li><strong>Log Levels</strong>: INFO, WARNING, ERROR</li>
<li><strong>Structured Logging</strong>: JSON format</li>
<li><strong>Log Retention</strong>: 30 days default</li>
</ul>
<h3 id="api-gateway-logs"><a class="header" href="#api-gateway-logs">API Gateway Logs</a></h3>
<ul>
<li><strong>Access Logs</strong>: Request/response logging</li>
<li><strong>Execution Logs</strong>: API execution details</li>
<li><strong>Error Logs</strong>: Error tracking</li>
</ul>
<h3 id="cloudfront-logs"><a class="header" href="#cloudfront-logs">CloudFront Logs</a></h3>
<ul>
<li><strong>Access Logs</strong>: Request logging</li>
<li><strong>Real-time Logs</strong>: Stream to CloudWatch</li>
<li><strong>Log Analysis</strong>: Query with CloudWatch Insights</li>
</ul>
<h2 id="alerting"><a class="header" href="#alerting">Alerting</a></h2>
<h3 id="cloudwatch-alarms"><a class="header" href="#cloudwatch-alarms">CloudWatch Alarms</a></h3>
<pre><code class="language-hcl"># Lambda error rate alarm
resource "aws_cloudwatch_metric_alarm" "lambda_errors" {
  alarm_name          = "cloud-cv-lambda-errors"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 2
  metric_name         = "Errors"
  namespace           = "AWS/Lambda"
  period              = 300
  statistic           = "Sum"
  threshold           = 5
  alarm_description   = "Alert when Lambda errors exceed 5"
  alarm_actions       = [aws_sns_topic.alerts.arn]
}
</code></pre>
<h3 id="alert-conditions"><a class="header" href="#alert-conditions">Alert Conditions</a></h3>
<ul>
<li><strong>Error Rate</strong>: &gt; 5% error rate</li>
<li><strong>Latency</strong>: &gt; 1 second response time</li>
<li><strong>Availability</strong>: &lt; 99% uptime</li>
<li><strong>Cost</strong>: Unusual cost spikes</li>
</ul>
<h2 id="dashboards"><a class="header" href="#dashboards">Dashboards</a></h2>
<h3 id="cloudwatch-dashboard"><a class="header" href="#cloudwatch-dashboard">CloudWatch Dashboard</a></h3>
<ul>
<li><strong>Service Health</strong>: Overall system status</li>
<li><strong>Performance Metrics</strong>: Response times and throughput</li>
<li><strong>Error Tracking</strong>: Error rates and types</li>
<li><strong>Cost Monitoring</strong>: Resource usage and costs</li>
</ul>
<h3 id="key-metrics-to-monitor"><a class="header" href="#key-metrics-to-monitor">Key Metrics to Monitor</a></h3>
<ol>
<li>Lambda invocation count and errors</li>
<li>DynamoDB read/write capacity</li>
<li>CloudFront cache hit ratio</li>
<li>API Gateway latency</li>
<li>S3 request metrics</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-cost-optimization"><a class="header" href="#cloud-cv-cost-optimization">Cloud-CV Cost Optimization</a></h1>
<h2 id="s3-costs"><a class="header" href="#s3-costs">S3 Costs</a></h2>
<ul>
<li><strong>Storage Class</strong>: Standard for active content</li>
<li><strong>Lifecycle</strong>: Move to IA after 30 days</li>
<li><strong>Compression</strong>: Gzip compression enabled</li>
<li><strong>CDN</strong>: CloudFront reduces S3 requests</li>
</ul>
<h3 id="cost-breakdown"><a class="header" href="#cost-breakdown">Cost Breakdown</a></h3>
<ul>
<li><strong>Storage</strong>: ~$0.023 per GB/month</li>
<li><strong>Requests</strong>: ~$0.0004 per 1,000 GET requests</li>
<li><strong>Data Transfer</strong>: ~$0.09 per GB (first 10 TB)</li>
</ul>
<h2 id="lambda-costs"><a class="header" href="#lambda-costs">Lambda Costs</a></h2>
<ul>
<li><strong>Memory</strong>: Optimized for 128MB</li>
<li><strong>Timeout</strong>: 30-second limit</li>
<li><strong>Cold Start</strong>: Minimized with provisioned concurrency</li>
<li><strong>Monitoring</strong>: Cost tracking enabled</li>
</ul>
<h3 id="cost-breakdown-1"><a class="header" href="#cost-breakdown-1">Cost Breakdown</a></h3>
<ul>
<li><strong>Requests</strong>: First 1M requests free, then $0.20 per 1M</li>
<li><strong>Compute</strong>: $0.0000166667 per GB-second</li>
<li><strong>Example</strong>: 1M requests at 128MB, 100ms = ~$0.21</li>
</ul>
<h2 id="dynamodb-costs"><a class="header" href="#dynamodb-costs">DynamoDB Costs</a></h2>
<ul>
<li><strong>Billing</strong>: Pay-per-request model</li>
<li><strong>Capacity</strong>: No provisioned capacity</li>
<li><strong>Indexes</strong>: No GSI required</li>
<li><strong>Backup</strong>: Point-in-time recovery</li>
</ul>
<h3 id="cost-breakdown-2"><a class="header" href="#cost-breakdown-2">Cost Breakdown</a></h3>
<ul>
<li><strong>On-Demand</strong>: $1.25 per million write units, $0.25 per million read units</li>
<li><strong>Storage</strong>: $0.25 per GB/month</li>
<li><strong>Backup</strong>: $0.20 per GB/month</li>
</ul>
<h2 id="cloudfront-costs"><a class="header" href="#cloudfront-costs">CloudFront Costs</a></h2>
<ul>
<li><strong>Edge Locations</strong>: Global distribution</li>
<li><strong>Cache</strong>: Optimized cache policies</li>
<li><strong>Compression</strong>: Gzip compression</li>
<li><strong>HTTPS</strong>: Free SSL certificates</li>
</ul>
<h3 id="cost-breakdown-3"><a class="header" href="#cost-breakdown-3">Cost Breakdown</a></h3>
<ul>
<li><strong>Data Transfer Out</strong>: $0.085 per GB (first 10 TB)</li>
<li><strong>Requests</strong>: $0.0075 per 10,000 HTTPS requests</li>
<li><strong>Invalidation</strong>: First 1,000 paths/month free</li>
</ul>
<h2 id="total-monthly-cost-estimate"><a class="header" href="#total-monthly-cost-estimate">Total Monthly Cost Estimate</a></h2>
<h3 id="low-traffic-scenario-1000-visitorsmonth"><a class="header" href="#low-traffic-scenario-1000-visitorsmonth">Low Traffic Scenario (1,000 visitors/month)</a></h3>
<ul>
<li><strong>S3</strong>: ~$0.50 (storage + requests)</li>
<li><strong>Lambda</strong>: ~$0.10 (executions)</li>
<li><strong>DynamoDB</strong>: ~$0.25 (requests)</li>
<li><strong>CloudFront</strong>: ~$1.00 (data transfer)</li>
<li><strong>Total</strong>: ~$1.85/month</li>
</ul>
<h3 id="medium-traffic-scenario-10000-visitorsmonth"><a class="header" href="#medium-traffic-scenario-10000-visitorsmonth">Medium Traffic Scenario (10,000 visitors/month)</a></h3>
<ul>
<li><strong>S3</strong>: ~$1.00</li>
<li><strong>Lambda</strong>: ~$0.50</li>
<li><strong>DynamoDB</strong>: ~$0.50</li>
<li><strong>CloudFront</strong>: ~$2.00</li>
<li><strong>Total</strong>: ~$4.00/month</li>
</ul>
<h3 id="high-traffic-scenario-100000-visitorsmonth"><a class="header" href="#high-traffic-scenario-100000-visitorsmonth">High Traffic Scenario (100,000 visitors/month)</a></h3>
<ul>
<li><strong>S3</strong>: ~$2.00</li>
<li><strong>Lambda</strong>: ~$2.00</li>
<li><strong>DynamoDB</strong>: ~$2.00</li>
<li><strong>CloudFront</strong>: ~$5.00</li>
<li><strong>Total</strong>: ~$11.00/month</li>
</ul>
<h2 id="cost-optimization-strategies"><a class="header" href="#cost-optimization-strategies">Cost Optimization Strategies</a></h2>
<ol>
<li><strong>Right-Sizing</strong>: Optimize Lambda memory allocation</li>
<li><strong>Caching</strong>: Maximize CloudFront cache hit ratio</li>
<li><strong>Compression</strong>: Enable Gzip compression</li>
<li><strong>Lifecycle Policies</strong>: Move old data to cheaper storage</li>
<li><strong>Monitoring</strong>: Track costs with AWS Cost Explorer</li>
<li><strong>Reserved Capacity</strong>: Not applicable for serverless</li>
</ol>
<h2 id="cost-monitoring"><a class="header" href="#cost-monitoring">Cost Monitoring</a></h2>
<h3 id="aws-cost-explorer"><a class="header" href="#aws-cost-explorer">AWS Cost Explorer</a></h3>
<ul>
<li><strong>Daily Costs</strong>: Track spending trends</li>
<li><strong>Service Breakdown</strong>: Per-service costs</li>
<li><strong>Forecasting</strong>: Predict future costs</li>
<li><strong>Budget Alerts</strong>: Set spending limits</li>
</ul>
<h3 id="cloudwatch-billing-alarms"><a class="header" href="#cloudwatch-billing-alarms">CloudWatch Billing Alarms</a></h3>
<pre><code class="language-hcl">resource "aws_cloudwatch_metric_alarm" "billing" {
  alarm_name          = "cloud-cv-billing-alert"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = 1
  metric_name         = "EstimatedCharges"
  namespace           = "AWS/Billing"
  period              = 86400
  statistic           = "Maximum"
  threshold           = 10
  alarm_description   = "Alert when monthly costs exceed $10"
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-troubleshooting-scenarios"><a class="header" href="#cloud-cv-troubleshooting-scenarios">Cloud-CV Troubleshooting Scenarios</a></h1>
<h2 id="lambda-function-issues"><a class="header" href="#lambda-function-issues">Lambda Function Issues</a></h2>
<h3 id="problem-lambda-timeout"><a class="header" href="#problem-lambda-timeout">Problem: Lambda Timeout</a></h3>
<pre><code class="language-bash"># Check CloudWatch logs
aws logs describe-log-groups --log-group-name-prefix /aws/lambda/cloud-cv

# Check function configuration
aws lambda get-function --function-name cloud-cv-visitor-counter

# View recent logs
aws logs tail /aws/lambda/cloud-cv-visitor-counter --follow
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Increase timeout in Terraform configuration</li>
<li>Optimize code performance</li>
<li>Check DynamoDB connection</li>
<li>Review function memory allocation</li>
</ul>
<h3 id="problem-lambda-memory-issues"><a class="header" href="#problem-lambda-memory-issues">Problem: Lambda Memory Issues</a></h3>
<pre><code class="language-bash"># Check memory usage
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name MemoryUtilization \
  --dimensions Name=FunctionName,Value=cloud-cv-visitor-counter \
  --start-time 2024-01-01T00:00:00Z \
  --end-time 2024-01-02T00:00:00Z \
  --period 3600 \
  --statistics Maximum
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Increase Lambda memory allocation</li>
<li>Optimize code to reduce memory usage</li>
<li>Check for memory leaks</li>
</ul>
<h2 id="api-gateway-issues"><a class="header" href="#api-gateway-issues">API Gateway Issues</a></h2>
<h3 id="problem-cors-errors"><a class="header" href="#problem-cors-errors">Problem: CORS Errors</a></h3>
<pre><code class="language-javascript">// Check browser console for CORS errors
// Verify API Gateway CORS configuration
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Update API Gateway CORS settings</li>
<li>Check Lambda response headers</li>
<li>Verify preflight OPTIONS method</li>
<li>Ensure proper Access-Control-Allow-Origin header</li>
</ul>
<h3 id="problem-502-bad-gateway"><a class="header" href="#problem-502-bad-gateway">Problem: 502 Bad Gateway</a></h3>
<pre><code class="language-bash"># Check API Gateway logs
aws apigateway get-rest-apis

# Test endpoint directly
curl -X GET https://api-gateway-url/visitor-count
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Verify Lambda function is deployed</li>
<li>Check Lambda function permissions</li>
<li>Review API Gateway integration settings</li>
<li>Check Lambda function logs</li>
</ul>
<h2 id="cloudfront-issues"><a class="header" href="#cloudfront-issues">CloudFront Issues</a></h2>
<h3 id="problem-cache-not-updating"><a class="header" href="#problem-cache-not-updating">Problem: Cache Not Updating</a></h3>
<pre><code class="language-bash"># Create cache invalidation
aws cloudfront create-invalidation \
  --distribution-id DISTRIBUTION_ID \
  --paths "/*"

# Check invalidation status
aws cloudfront list-invalidations --distribution-id DISTRIBUTION_ID
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Invalidate CloudFront cache</li>
<li>Check cache policies</li>
<li>Verify origin settings</li>
<li>Review TTL configurations</li>
</ul>
<h3 id="problem-403-forbidden-errors"><a class="header" href="#problem-403-forbidden-errors">Problem: 403 Forbidden Errors</a></h3>
<pre><code class="language-bash"># Check S3 bucket policy
aws s3api get-bucket-policy --bucket cloud-cv-bucket

# Verify CloudFront OAC
aws cloudfront get-distribution --id DISTRIBUTION_ID
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Verify S3 bucket permissions</li>
<li>Check CloudFront Origin Access Control</li>
<li>Review bucket policy</li>
<li>Ensure proper IAM roles</li>
</ul>
<h2 id="dynamodb-issues"><a class="header" href="#dynamodb-issues">DynamoDB Issues</a></h2>
<h3 id="problem-throttling-errors"><a class="header" href="#problem-throttling-errors">Problem: Throttling Errors</a></h3>
<pre><code class="language-bash"># Check DynamoDB metrics
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name ThrottledRequests \
  --dimensions Name=TableName,Value=cloud-cv-visitor-counter \
  --start-time 2024-01-01T00:00:00Z \
  --end-time 2024-01-02T00:00:00Z \
  --period 3600 \
  --statistics Sum
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Enable auto-scaling</li>
<li>Optimize read/write patterns</li>
<li>Consider provisioned capacity</li>
<li>Implement exponential backoff</li>
</ul>
<h3 id="problem-item-not-found"><a class="header" href="#problem-item-not-found">Problem: Item Not Found</a></h3>
<pre><code class="language-bash"># Check table items
aws dynamodb scan --table-name cloud-cv-visitor-counter

# Verify table structure
aws dynamodb describe-table --table-name cloud-cv-visitor-counter
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Verify table name in Lambda environment</li>
<li>Check item key structure</li>
<li>Review DynamoDB permissions</li>
<li>Ensure table exists</li>
</ul>
<h2 id="s3-issues"><a class="header" href="#s3-issues">S3 Issues</a></h2>
<h3 id="problem-404-not-found"><a class="header" href="#problem-404-not-found">Problem: 404 Not Found</a></h3>
<pre><code class="language-bash"># List bucket contents
aws s3 ls s3://cloud-cv-bucket/

# Check bucket configuration
aws s3api get-bucket-website --bucket cloud-cv-bucket
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Verify files are uploaded</li>
<li>Check file paths</li>
<li>Review bucket website configuration</li>
<li>Ensure index.html exists</li>
</ul>
<h3 id="problem-access-denied"><a class="header" href="#problem-access-denied">Problem: Access Denied</a></h3>
<pre><code class="language-bash"># Check bucket policy
aws s3api get-bucket-policy --bucket cloud-cv-bucket

# Verify IAM permissions
aws iam get-user-policy --user-name USER_NAME --policy-name POLICY_NAME
</code></pre>
<p><strong>Solution:</strong></p>
<ul>
<li>Review bucket policy</li>
<li>Check IAM permissions</li>
<li>Verify CloudFront OAC</li>
<li>Ensure proper access controls</li>
</ul>
<h2 id="common-debugging-commands"><a class="header" href="#common-debugging-commands">Common Debugging Commands</a></h2>
<pre><code class="language-bash"># Check all resources
aws cloudformation describe-stacks

# View Lambda logs
aws logs tail /aws/lambda/cloud-cv-visitor-counter --follow

# Test API endpoint
curl -X GET https://api-gateway-url/visitor-count

# Check CloudFront distribution
aws cloudfront get-distribution --id DISTRIBUTION_ID

# Verify DynamoDB table
aws dynamodb describe-table --table-name cloud-cv-visitor-counter

# Check S3 bucket
aws s3 ls s3://cloud-cv-bucket/ --recursive
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-technical-qa"><a class="header" href="#cloud-cv-technical-qa">Cloud-CV Technical Q&amp;A</a></h1>
<h2 id="architecture--design-questions"><a class="header" href="#architecture--design-questions">Architecture &amp; Design Questions</a></h2>
<h3 id="q1-walk-me-through-the-architecture-of-your-cloud-cv-project"><a class="header" href="#q1-walk-me-through-the-architecture-of-your-cloud-cv-project">Q1: "Walk me through the architecture of your Cloud CV project."</a></h3>
<p><strong>Answer:</strong>
"The Cloud CV project follows a serverless, event-driven architecture. The frontend is hosted on S3 with CloudFront for global distribution. The visitor counter uses a Lambda function triggered by API Gateway, which stores data in DynamoDB. This design provides scalability, cost-effectiveness, and high availability.</p>
<p>Key components:</p>
<ul>
<li><strong>Frontend</strong>: S3 + CloudFront for static hosting</li>
<li><strong>API</strong>: API Gateway for REST endpoints</li>
<li><strong>Compute</strong>: Lambda for serverless processing</li>
<li><strong>Database</strong>: DynamoDB for NoSQL storage</li>
<li><strong>Infrastructure</strong>: Terraform for IaC</li>
<li><strong>CI/CD</strong>: GitHub Actions for automation"</li>
</ul>
<h3 id="q2-why-did-you-choose-serverless-over-containers"><a class="header" href="#q2-why-did-you-choose-serverless-over-containers">Q2: "Why did you choose serverless over containers?"</a></h3>
<p><strong>Answer:</strong>
"Serverless was chosen for several reasons:</p>
<ol>
<li><strong>Cost</strong>: Pay only for actual usage, not idle time</li>
<li><strong>Scalability</strong>: Automatic scaling based on demand</li>
<li><strong>Maintenance</strong>: No server management required</li>
<li><strong>Performance</strong>: Cold start latency is acceptable for this use case</li>
<li><strong>Simplicity</strong>: Easier deployment and monitoring</li>
</ol>
<p>For a simple visitor counter, serverless provides the right balance of cost, performance, and operational overhead."</p>
<h3 id="q3-how-would-you-handle-high-traffic-spikes"><a class="header" href="#q3-how-would-you-handle-high-traffic-spikes">Q3: "How would you handle high traffic spikes?"</a></h3>
<p><strong>Answer:</strong>
"Several strategies:</p>
<ol>
<li><strong>CloudFront</strong>: Global CDN with edge caching</li>
<li><strong>Lambda</strong>: Auto-scaling up to 1000 concurrent executions</li>
<li><strong>DynamoDB</strong>: On-demand billing with auto-scaling</li>
<li><strong>API Gateway</strong>: Built-in throttling and caching</li>
<li><strong>Monitoring</strong>: CloudWatch alarms for proactive scaling</li>
</ol>
<p>The architecture is designed to handle traffic spikes automatically without manual intervention."</p>
<h2 id="infrastructure-questions"><a class="header" href="#infrastructure-questions">Infrastructure Questions</a></h2>
<h3 id="q4-explain-your-terraform-configuration"><a class="header" href="#q4-explain-your-terraform-configuration">Q4: "Explain your Terraform configuration."</a></h3>
<p><strong>Answer:</strong>
"The Terraform configuration follows best practices:</p>
<ul>
<li><strong>Modularity</strong>: Reusable components</li>
<li><strong>State Management</strong>: Local state with backup</li>
<li><strong>Security</strong>: IAM roles with least privilege</li>
<li><strong>Tagging</strong>: Consistent resource tagging</li>
<li><strong>Variables</strong>: Environment-specific configurations</li>
</ul>
<p>Key resources:</p>
<ul>
<li>S3 bucket with versioning and encryption</li>
<li>CloudFront distribution with OAC</li>
<li>Lambda function with IAM role</li>
<li>DynamoDB table with on-demand billing</li>
<li>API Gateway with CORS configuration"</li>
</ul>
<h3 id="q5-how-do-you-ensure-infrastructure-security"><a class="header" href="#q5-how-do-you-ensure-infrastructure-security">Q5: "How do you ensure infrastructure security?"</a></h3>
<p><strong>Answer:</strong>
"Multiple security layers:</p>
<ol>
<li><strong>S3</strong>: Public access blocked, encryption at rest</li>
<li><strong>CloudFront</strong>: OAC for secure S3 access</li>
<li><strong>Lambda</strong>: IAM roles with minimal permissions</li>
<li><strong>DynamoDB</strong>: Encryption and access control</li>
<li><strong>API Gateway</strong>: HTTPS enforcement and CORS</li>
<li><strong>Terraform</strong>: State file security and access control"</li>
</ol>
<h2 id="devops-questions"><a class="header" href="#devops-questions">DevOps Questions</a></h2>
<h3 id="q6-describe-your-cicd-pipeline"><a class="header" href="#q6-describe-your-cicd-pipeline">Q6: "Describe your CI/CD pipeline."</a></h3>
<p><strong>Answer:</strong>
"The pipeline uses GitHub Actions:</p>
<ol>
<li><strong>Trigger</strong>: Push to main branch</li>
<li><strong>Infrastructure</strong>: Terraform plan and apply</li>
<li><strong>Deployment</strong>: S3 file upload</li>
<li><strong>Cache</strong>: CloudFront invalidation</li>
<li><strong>Monitoring</strong>: Health checks and alerts</li>
</ol>
<p>Benefits:</p>
<ul>
<li>Automated deployment</li>
<li>Infrastructure consistency</li>
<li>Rollback capability</li>
<li>Cost tracking"</li>
</ul>
<h3 id="q7-how-do-you-handle-rollbacks"><a class="header" href="#q7-how-do-you-handle-rollbacks">Q7: "How do you handle rollbacks?"</a></h3>
<p><strong>Answer:</strong>
"Multiple rollback strategies:</p>
<ol>
<li><strong>Infrastructure</strong>: Terraform state management</li>
<li><strong>Application</strong>: S3 versioning for file rollback</li>
<li><strong>Database</strong>: DynamoDB point-in-time recovery</li>
<li><strong>Cache</strong>: CloudFront cache invalidation</li>
<li><strong>Monitoring</strong>: CloudWatch for health checks</li>
</ol>
<p>The process is automated and can be triggered manually or automatically based on health metrics."</p>
<h2 id="monitoring-questions"><a class="header" href="#monitoring-questions">Monitoring Questions</a></h2>
<h3 id="q8-how-do-you-monitor-the-application"><a class="header" href="#q8-how-do-you-monitor-the-application">Q8: "How do you monitor the application?"</a></h3>
<p><strong>Answer:</strong>
"Comprehensive monitoring strategy:</p>
<ol>
<li><strong>Metrics</strong>: CloudWatch for all services</li>
<li><strong>Logs</strong>: Centralized logging with CloudWatch</li>
<li><strong>Alerts</strong>: Proactive alerting for issues</li>
<li><strong>Dashboards</strong>: Real-time monitoring</li>
<li><strong>Tracing</strong>: X-Ray for distributed tracing</li>
</ol>
<p>Key metrics:</p>
<ul>
<li>Lambda invocations and errors</li>
<li>DynamoDB read/write capacity</li>
<li>CloudFront cache hit ratio</li>
<li>API Gateway latency and errors"</li>
</ul>
<h3 id="q9-what-would-you-do-if-the-visitor-counter-stopped-working"><a class="header" href="#q9-what-would-you-do-if-the-visitor-counter-stopped-working">Q9: "What would you do if the visitor counter stopped working?"</a></h3>
<p><strong>Answer:</strong>
"Troubleshooting steps:</p>
<ol>
<li><strong>Check CloudWatch</strong>: Lambda logs and metrics</li>
<li><strong>Verify API</strong>: Test API Gateway endpoint</li>
<li><strong>Database</strong>: Check DynamoDB connectivity</li>
<li><strong>Permissions</strong>: Verify IAM roles</li>
<li><strong>Network</strong>: Check VPC and security groups</li>
</ol>
<p>Common issues:</p>
<ul>
<li>Lambda timeout or memory issues</li>
<li>DynamoDB throttling</li>
<li>API Gateway CORS problems</li>
<li>IAM permission errors"</li>
</ul>
<h2 id="cost-optimization-questions"><a class="header" href="#cost-optimization-questions">Cost Optimization Questions</a></h2>
<h3 id="q10-how-do-you-optimize-costs"><a class="header" href="#q10-how-do-you-optimize-costs">Q10: "How do you optimize costs?"</a></h3>
<p><strong>Answer:</strong>
"Cost optimization strategies:</p>
<ol>
<li><strong>S3</strong>: Lifecycle policies and compression</li>
<li><strong>Lambda</strong>: Memory optimization and timeout tuning</li>
<li><strong>DynamoDB</strong>: On-demand billing and efficient queries</li>
<li><strong>CloudFront</strong>: Cache optimization and compression</li>
<li><strong>Monitoring</strong>: Cost alerts and budget tracking</li>
</ol>
<p>Expected monthly costs:</p>
<ul>
<li>S3: ~$1-2 for storage</li>
<li>Lambda: ~$0.50 for executions</li>
<li>DynamoDB: ~$0.25 for requests</li>
<li>CloudFront: ~$1-2 for data transfer</li>
<li>Total: ~$3-5 per month"</li>
</ul>
<h2 id="advanced-questions"><a class="header" href="#advanced-questions">Advanced Questions</a></h2>
<h3 id="q11-how-would-you-scale-this-to-handle-1-million-visitors-per-day"><a class="header" href="#q11-how-would-you-scale-this-to-handle-1-million-visitors-per-day">Q11: "How would you scale this to handle 1 million visitors per day?"</a></h3>
<p><strong>Answer:</strong>
"Scaling strategies:</p>
<ol>
<li><strong>Lambda</strong>: Increase concurrency limits</li>
<li><strong>DynamoDB</strong>: Enable auto-scaling</li>
<li><strong>CloudFront</strong>: Optimize cache policies</li>
<li><strong>Monitoring</strong>: Enhanced alerting</li>
<li><strong>Architecture</strong>: Consider read replicas</li>
</ol>
<p>Additional considerations:</p>
<ul>
<li>Database sharding for high write loads</li>
<li>Caching strategies for read-heavy workloads</li>
<li>CDN optimization for global distribution</li>
<li>Cost analysis for high-traffic scenarios"</li>
</ul>
<h3 id="q12-how-would-you-implement-disaster-recovery"><a class="header" href="#q12-how-would-you-implement-disaster-recovery">Q12: "How would you implement disaster recovery?"</a></h3>
<p><strong>Answer:</strong>
"DR strategy:</p>
<ol>
<li><strong>Backup</strong>: S3 cross-region replication</li>
<li><strong>Database</strong>: DynamoDB point-in-time recovery</li>
<li><strong>Infrastructure</strong>: Multi-region Terraform</li>
<li><strong>Monitoring</strong>: Cross-region health checks</li>
<li><strong>Testing</strong>: Regular DR drills</li>
</ol>
<p>Recovery time objective: &lt; 1 hour
Recovery point objective: &lt; 15 minutes"</p>
<h3 id="q13-how-do-you-handle-lambda-cold-starts"><a class="header" href="#q13-how-do-you-handle-lambda-cold-starts">Q13: "How do you handle Lambda cold starts?"</a></h3>
<p><strong>Answer:</strong>
"Cold start mitigation:</p>
<ol>
<li><strong>Provisioned Concurrency</strong>: Keep functions warm</li>
<li><strong>Memory Optimization</strong>: Right-size Lambda memory</li>
<li><strong>Package Size</strong>: Minimize deployment package</li>
<li><strong>VPC Configuration</strong>: Avoid VPC if not needed</li>
<li><strong>Reserved Capacity</strong>: Use reserved concurrency</li>
</ol>
<p>For visitor counter, cold starts are acceptable (&lt; 1s), but can be optimized if needed."</p>
<h3 id="q14-what-would-you-do-if-dynamodb-throttling-occurred"><a class="header" href="#q14-what-would-you-do-if-dynamodb-throttling-occurred">Q14: "What would you do if DynamoDB throttling occurred?"</a></h3>
<p><strong>Answer:</strong>
"Throttling resolution:</p>
<ol>
<li><strong>On-Demand Mode</strong>: Switch to on-demand billing</li>
<li><strong>Auto-Scaling</strong>: Enable auto-scaling for provisioned capacity</li>
<li><strong>Retry Logic</strong>: Implement exponential backoff</li>
<li><strong>Batch Operations</strong>: Use batch writes when possible</li>
<li><strong>Monitoring</strong>: Set up CloudWatch alarms</li>
</ol>
<p>The current setup uses on-demand mode which auto-scales automatically."</p>
<h3 id="q15-how-do-you-ensure-cloudfront-cache-invalidation-works-correctly"><a class="header" href="#q15-how-do-you-ensure-cloudfront-cache-invalidation-works-correctly">Q15: "How do you ensure CloudFront cache invalidation works correctly?"</a></h3>
<p><strong>Answer:</strong>
"Cache invalidation strategy:</p>
<ol>
<li><strong>Selective Invalidation</strong>: Invalidate only changed files</li>
<li><strong>Versioning</strong>: Use file versioning in URLs</li>
<li><strong>TTL Configuration</strong>: Set appropriate cache TTLs</li>
<li><strong>Automation</strong>: Automate invalidation in CI/CD</li>
<li><strong>Monitoring</strong>: Track cache hit ratios</li>
</ol>
<p>GitHub Actions automatically invalidates cache on deployment."</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-cv-advanced-topics"><a class="header" href="#cloud-cv-advanced-topics">Cloud-CV Advanced Topics</a></h1>
<h2 id="multi-environment-strategy"><a class="header" href="#multi-environment-strategy">Multi-Environment Strategy</a></h2>
<pre><code class="language-hcl"># Environment-specific configurations
variable "environment" {
  description = "Environment name"
  type        = string
  default     = "production"
}

# Environment-specific tags
locals {
  common_tags = {
    Environment = var.environment
    Project     = "Cloud-CV"
    Owner       = "SRE-DevOps-Engineer"
  }
}

# Environment-specific resource naming
resource "aws_s3_bucket" "website" {
  bucket = "cloud-cv-${var.environment}-${random_id.bucket_suffix.hex}"
  
  tags = merge(local.common_tags, {
    Name = "cloud-cv-${var.environment}"
  })
}
</code></pre>
<h2 id="blue-green-deployment"><a class="header" href="#blue-green-deployment">Blue-Green Deployment</a></h2>
<pre><code class="language-yaml"># Blue-green deployment strategy
- name: Deploy to Blue Environment
  run: |
    terraform apply -var="environment=blue"
    
- name: Test Blue Environment
  run: |
    curl -f https://blue.cloud-cv.com/health
    
- name: Switch to Blue
  run: |
    aws route53 change-resource-record-sets \
      --hosted-zone-id ZONE_ID \
      --change-batch file://blue-deployment.json
</code></pre>
<h2 id="canary-deployment"><a class="header" href="#canary-deployment">Canary Deployment</a></h2>
<pre><code class="language-yaml"># Canary deployment with CloudFront
- name: Deploy Canary
  run: |
    aws cloudfront create-distribution \
      --distribution-config file://canary-config.json
    
- name: Monitor Canary
  run: |
    aws cloudwatch get-metric-statistics \
      --namespace AWS/CloudFront \
      --metric-name Requests \
      --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
      --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
      --period 300 \
      --statistics Sum
</code></pre>
<h2 id="chaos-engineering"><a class="header" href="#chaos-engineering">Chaos Engineering</a></h2>
<pre><code class="language-python"># Chaos engineering for resilience testing
import boto3
import random
import time

def chaos_test():
    """
    Simulate various failure scenarios
    """
    lambda_client = boto3.client('lambda')
    dynamodb = boto3.resource('dynamodb')
    
    # Simulate Lambda failures
    def simulate_lambda_failure():
        # Inject errors randomly
        if random.random() &lt; 0.1:  # 10% failure rate
            raise Exception("Simulated Lambda failure")
    
    # Test DynamoDB throttling
    def test_dynamodb_throttling():
        table = dynamodb.Table('cloud-cv-visitor-counter')
        # Rapid requests to trigger throttling
        for i in range(100):
            try:
                table.get_item(Key={'id': 'visitor_count'})
            except Exception as e:
                print(f"Throttling detected: {e}")
    
    # Verify CloudFront fallback
    def verify_cloudfront_fallback():
        # Test CDN behavior under load
        pass
    
    # Check error handling
    def check_error_handling():
        # Verify graceful degradation
        pass
    
    return {
        'lambda_failures': simulate_lambda_failure(),
        'dynamodb_throttling': test_dynamodb_throttling(),
        'cloudfront_fallback': verify_cloudfront_fallback(),
        'error_handling': check_error_handling()
    }
</code></pre>
<h2 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h2>
<h3 id="frontend-optimization"><a class="header" href="#frontend-optimization">Frontend Optimization</a></h3>
<pre><code class="language-javascript">// Frontend performance optimization
class PerformanceOptimizer {
    constructor() {
        this.enableLazyLoading();
        this.optimizeImages();
        this.enableCaching();
        this.minimizeRequests();
    }
    
    enableLazyLoading() {
        // Lazy load images and scripts
        const images = document.querySelectorAll('img[data-src]');
        const imageObserver = new IntersectionObserver((entries, observer) =&gt; {
            entries.forEach(entry =&gt; {
                if (entry.isIntersecting) {
                    const img = entry.target;
                    img.src = img.dataset.src;
                    img.removeAttribute('data-src');
                    observer.unobserve(img);
                }
            });
        });
        
        images.forEach(img =&gt; imageObserver.observe(img));
    }
    
    optimizeImages() {
        // WebP format with fallbacks
        const supportsWebP = document.createElement('canvas')
            .toDataURL('image/webp').indexOf('data:image/webp') === 0;
        
        if (supportsWebP) {
            // Use WebP images
        }
    }
    
    enableCaching() {
        // Service worker for offline support
        if ('serviceWorker' in navigator) {
            navigator.serviceWorker.register('/sw.js');
        }
    }
    
    minimizeRequests() {
        // Combine API calls
        // Use request batching
    }
}
</code></pre>
<h3 id="backend-optimization"><a class="header" href="#backend-optimization">Backend Optimization</a></h3>
<pre><code class="language-python"># Lambda optimization
import json
import boto3
from functools import lru_cache

# Cache DynamoDB client
@lru_cache(maxsize=1)
def get_dynamodb_table():
    dynamodb = boto3.resource('dynamodb')
    return dynamodb.Table('cloud-cv-visitor-counter')

# Optimize Lambda handler
def lambda_handler(event, context):
    # Reuse connections
    table = get_dynamodb_table()
    
    # Batch operations
    # Minimize API calls
    # Use connection pooling
    
    return response
</code></pre>
<h2 id="infrastructure-as-code-best-practices"><a class="header" href="#infrastructure-as-code-best-practices">Infrastructure as Code Best Practices</a></h2>
<h3 id="module-structure"><a class="header" href="#module-structure">Module Structure</a></h3>
<pre><code class="language-hcl"># modules/s3/main.tf
resource "aws_s3_bucket" "this" {
  bucket = var.bucket_name
  
  tags = var.tags
}

# modules/s3/variables.tf
variable "bucket_name" {
  description = "S3 bucket name"
  type        = string
}

variable "tags" {
  description = "Resource tags"
  type        = map(string)
  default     = {}
}

# modules/s3/outputs.tf
output "bucket_id" {
  description = "S3 bucket ID"
  value       = aws_s3_bucket.this.id
}
</code></pre>
<h3 id="state-management"><a class="header" href="#state-management">State Management</a></h3>
<pre><code class="language-hcl"># backend.tf
terraform {
  backend "s3" {
    bucket         = "cloud-cv-terraform-state"
    key            = "terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
</code></pre>
<h2 id="security-hardening"><a class="header" href="#security-hardening">Security Hardening</a></h2>
<h3 id="secrets-management"><a class="header" href="#secrets-management">Secrets Management</a></h3>
<pre><code class="language-hcl"># Use AWS Secrets Manager
data "aws_secretsmanager_secret_version" "api_key" {
  secret_id = "cloud-cv-api-key"
}

resource "aws_lambda_function" "visitor_counter" {
  environment {
    variables = {
      API_KEY = data.aws_secretsmanager_secret_version.api_key.secret_string
    }
  }
}
</code></pre>
<h3 id="network-security"><a class="header" href="#network-security">Network Security</a></h3>
<pre><code class="language-hcl"># VPC configuration for Lambda (if needed)
resource "aws_lambda_function" "visitor_counter" {
  vpc_config {
    subnet_ids         = var.subnet_ids
    security_group_ids = [aws_security_group.lambda.id]
  }
}
</code></pre>
<h2 id="monitoring-and-alerting"><a class="header" href="#monitoring-and-alerting">Monitoring and Alerting</a></h2>
<h3 id="advanced-monitoring"><a class="header" href="#advanced-monitoring">Advanced Monitoring</a></h3>
<pre><code class="language-hcl"># Custom CloudWatch dashboard
resource "aws_cloudwatch_dashboard" "main" {
  dashboard_name = "cloud-cv-dashboard"

  dashboard_body = jsonencode({
    widgets = [
      {
        type   = "metric"
        properties = {
          metrics = [
            ["AWS/Lambda", "Invocations", {"stat": "Sum"}],
            ["AWS/Lambda", "Errors", {"stat": "Sum"}],
            ["AWS/DynamoDB", "ConsumedReadCapacityUnits", {"stat": "Sum"}],
            ["AWS/DynamoDB", "ConsumedWriteCapacityUnits", {"stat": "Sum"}]
          ]
          period = 300
          stat   = "Sum"
          region = "us-east-1"
          title  = "Cloud CV Metrics"
        }
      }
    ]
  })
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-1"><a class="header" href="#stack-quest-1">Stack-Quest</a></h1>
<p>A quest for stack knowledge across DevOps, SRE, and Cloud engineering.</p>
<p><img src="stack-quest/../images/stack-quest.png" alt="StackQuest Interface" /></p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>StackQuest is a comprehensive knowledge base and challenge platform designed for DevOps, SRE, and Cloud engineers. It provides curated questions across 12+ categories and hands-on challenges for practical learning.</p>
<h2 id="key-features-1"><a class="header" href="#key-features-1">Key Features</a></h2>
<ul>
<li>üìö <strong>Curated Questions</strong>: High-quality questions across 12+ categories</li>
<li>‚ö° <strong>Hands-on Challenges</strong>: Practical DevOps scenarios</li>
<li>üéØ <strong>Category Selection</strong>: Choose specific topics to focus on</li>
<li>üîÑ <strong>Session Tracking</strong>: Prevents question repetition</li>
<li>üì± <strong>Responsive Design</strong>: Works on desktop and mobile</li>
<li>üöÄ <strong>Auto Deployment</strong>: GitHub Actions + GitHub Pages</li>
</ul>
<h2 id="project-highlights-1"><a class="header" href="#project-highlights-1">Project Highlights</a></h2>
<p>This project demonstrates:</p>
<ul>
<li>Modern web development practices</li>
<li>Responsive design principles</li>
<li>Knowledge management systems</li>
<li>Automated deployment workflows</li>
<li>Educational content organization</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-features"><a class="header" href="#stack-quest-features">Stack-Quest Features</a></h1>
<h2 id="core-features"><a class="header" href="#core-features">Core Features</a></h2>
<h3 id="question-categories"><a class="header" href="#question-categories">Question Categories</a></h3>
<p>StackQuest covers 12+ technical categories:</p>
<ul>
<li><strong>Linux</strong> üêß - System administration, shell scripting, process management</li>
<li><strong>Networking</strong> üåê - TCP/IP, DNS, load balancing, network protocols</li>
<li><strong>Git</strong> - Version control, branching strategies, workflows</li>
<li><strong>Cloud</strong> ‚òÅÔ∏è - AWS and Azure services, cloud architecture</li>
<li><strong>Terraform</strong> üèóÔ∏è - Infrastructure as code, state management</li>
<li><strong>Docker</strong> üê≥ - Containerization, Dockerfiles, orchestration</li>
<li><strong>Kubernetes</strong> üéª - Pods, services, deployments, cluster management</li>
<li><strong>Config Management</strong> üîß - Ansible, Puppet, Chef</li>
<li><strong>CI/CD</strong> üîÑ - Jenkins, GitHub Actions, GitLab CI</li>
<li><strong>DevOps</strong> üõ†Ô∏è - Best practices, methodologies, tools</li>
<li><strong>System Design</strong> üç• - Architecture patterns, scalability</li>
<li><strong>Security</strong> üîí - Security best practices, vulnerabilities</li>
</ul>
<h3 id="challenge-types"><a class="header" href="#challenge-types">Challenge Types</a></h3>
<h4 id="random-questions"><a class="header" href="#random-questions">Random Questions</a></h4>
<ul>
<li>Browse questions by category</li>
<li>Randomized question selection</li>
<li>Session-based tracking</li>
<li>No repetition within session</li>
</ul>
<h4 id="hands-on-challenges"><a class="header" href="#hands-on-challenges">Hands-on Challenges</a></h4>
<ul>
<li><strong>DevOps Challenges</strong>: Real-world scenarios</li>
<li><strong>SRE Challenges</strong>: Site reliability engineering tasks</li>
<li><strong>AWS Challenges</strong>: Cloud infrastructure challenges</li>
<li><strong>Kubernetes Challenges</strong>: Container orchestration tasks</li>
</ul>
<h2 id="user-experience"><a class="header" href="#user-experience">User Experience</a></h2>
<h3 id="responsive-design"><a class="header" href="#responsive-design">Responsive Design</a></h3>
<ul>
<li>Works seamlessly on desktop and mobile devices</li>
<li>Touch-friendly interface</li>
<li>Adaptive layout for different screen sizes</li>
</ul>
<h3 id="session-management"><a class="header" href="#session-management">Session Management</a></h3>
<ul>
<li>Tracks questions shown in current session</li>
<li>Prevents duplicate questions</li>
<li>Session reset functionality</li>
</ul>
<h3 id="category-filtering"><a class="header" href="#category-filtering">Category Filtering</a></h3>
<ul>
<li>Select specific categories to focus on</li>
<li>Multiple category selection</li>
<li>Quick category switching</li>
</ul>
<h2 id="deployment"><a class="header" href="#deployment">Deployment</a></h2>
<h3 id="automated-deployment"><a class="header" href="#automated-deployment">Automated Deployment</a></h3>
<ul>
<li>GitHub Actions for CI/CD</li>
<li>Automatic deployment to GitHub Pages</li>
<li>Zero-downtime updates</li>
<li>Version control integration</li>
</ul>
<h3 id="static-site-generation"><a class="header" href="#static-site-generation">Static Site Generation</a></h3>
<ul>
<li>Pure HTML, CSS, and JavaScript</li>
<li>No backend required</li>
<li>Fast loading times</li>
<li>SEO-friendly structure</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-content-structure"><a class="header" href="#stack-quest-content-structure">Stack-Quest Content Structure</a></h1>
<h2 id="content-organization"><a class="header" href="#content-organization">Content Organization</a></h2>
<p>StackQuest organizes content into two main sections:</p>
<h3 id="random-questions-1"><a class="header" href="#random-questions-1">Random Questions</a></h3>
<p>Browse questions by category with comprehensive coverage of DevOps, SRE, and Cloud engineering topics.</p>
<h4 id="available-categories"><a class="header" href="#available-categories">Available Categories</a></h4>
<ol>
<li><strong>Linux</strong> - System administration, shell scripting, process management</li>
<li><strong>Networking</strong> - TCP/IP, DNS, load balancing, network protocols</li>
<li><strong>Git</strong> - Version control, branching strategies, workflows</li>
<li><strong>AWS</strong> - Cloud services, architecture, best practices</li>
<li><strong>Azure</strong> - Microsoft cloud platform services</li>
<li><strong>Terraform</strong> - Infrastructure as code, state management</li>
<li><strong>Docker</strong> - Containerization, Dockerfiles, orchestration</li>
<li><strong>Kubernetes</strong> - Pods, services, deployments, cluster management</li>
<li><strong>Config Management</strong> - Ansible, Puppet, Chef</li>
<li><strong>CI/CD</strong> - Jenkins, GitHub Actions, GitLab CI</li>
<li><strong>DevOps</strong> - Best practices, methodologies, tools</li>
<li><strong>System Design</strong> - Architecture patterns, scalability</li>
<li><strong>Security</strong> - Security best practices, vulnerabilities</li>
</ol>
<h3 id="challenges"><a class="header" href="#challenges">Challenges</a></h3>
<p>Practice with hands-on challenges designed to test practical skills:</p>
<h4 id="devops-challenges"><a class="header" href="#devops-challenges">DevOps Challenges</a></h4>
<ul>
<li>Infrastructure automation scenarios</li>
<li>CI/CD pipeline design</li>
<li>Monitoring and alerting setup</li>
<li>Disaster recovery planning</li>
</ul>
<h4 id="sre-challenges"><a class="header" href="#sre-challenges">SRE Challenges</a></h4>
<ul>
<li>Service level objectives (SLOs)</li>
<li>Error budget management</li>
<li>Incident response procedures</li>
<li>Capacity planning</li>
</ul>
<h4 id="aws-challenges"><a class="header" href="#aws-challenges">AWS Challenges</a></h4>
<ul>
<li>Cloud architecture design</li>
<li>Cost optimization</li>
<li>Security hardening</li>
<li>Multi-region deployment</li>
</ul>
<h4 id="kubernetes-challenges"><a class="header" href="#kubernetes-challenges">Kubernetes Challenges</a></h4>
<ul>
<li>Cluster setup and configuration</li>
<li>Application deployment</li>
<li>Service mesh implementation</li>
<li>Resource management</li>
</ul>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>Help grow the knowledge base by:</p>
<ul>
<li>Adding new questions and answers to specific category files</li>
<li>Adding new challenges to specific challenge files</li>
<li>Improving existing content</li>
<li>Creating new category files for additional topics</li>
</ul>
<p>Simply raise a Pull Request with your contributions.</p>
<h2 id="content-quality"><a class="header" href="#content-quality">Content Quality</a></h2>
<p>All content is:</p>
<ul>
<li><strong>Curated</strong>: Reviewed for accuracy and relevance</li>
<li><strong>Practical</strong>: Focused on real-world scenarios</li>
<li><strong>Up-to-date</strong>: Regularly updated with latest practices</li>
<li><strong>Comprehensive</strong>: Covers beginner to advanced topics</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-technical-implementation"><a class="header" href="#stack-quest-technical-implementation">Stack-Quest Technical Implementation</a></h1>
<h2 id="frontend-architecture"><a class="header" href="#frontend-architecture">Frontend Architecture</a></h2>
<h3 id="html-structure-1"><a class="header" href="#html-structure-1">HTML Structure</a></h3>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;title&gt;StackQuest - DevOps Knowledge Base&lt;/title&gt;
    &lt;link rel="stylesheet" href="styles.css"&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class="container"&gt;
        &lt;header class="header"&gt;
            &lt;h1&gt;StackQuest üöÄ&lt;/h1&gt;
            &lt;p&gt;A quest for stack knowledge&lt;/p&gt;
        &lt;/header&gt;
        
        &lt;main class="main-content"&gt;
            &lt;!-- Category selection --&gt;
            &lt;section class="categories"&gt;
                &lt;!-- Category buttons --&gt;
            &lt;/section&gt;
            
            &lt;!-- Question display --&gt;
            &lt;section class="question-section"&gt;
                &lt;div class="question-card"&gt;
                    &lt;h2 id="question-title"&gt;Select a category to begin&lt;/h2&gt;
                    &lt;div id="question-content"&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/section&gt;
        &lt;/main&gt;
    &lt;/div&gt;
    
    &lt;script src="script.js"&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h2 id="javascript-implementation"><a class="header" href="#javascript-implementation">JavaScript Implementation</a></h2>
<h3 id="core-application-class"><a class="header" href="#core-application-class">Core Application Class</a></h3>
<pre><code class="language-javascript">class StackQuest {
    constructor() {
        this.categories = [];
        this.currentCategory = null;
        this.questions = [];
        this.shownQuestions = new Set();
        this.currentQuestion = null;
        this.init();
    }

    async init() {
        await this.loadCategories();
        await this.loadQuestions();
        this.setupEventListeners();
        this.renderCategories();
    }

    async loadCategories() {
        // Load category definitions
        this.categories = [
            { id: 'linux', name: 'Linux üêß', file: 'Random-Questions/linux.md' },
            { id: 'networking', name: 'Networking üåê', file: 'Random-Questions/networking.md' },
            { id: 'git', name: 'Git', file: 'Random-Questions/git.md' },
            { id: 'aws', name: 'AWS ‚òÅÔ∏è', file: 'Random-Questions/aws.md' },
            { id: 'terraform', name: 'Terraform üèóÔ∏è', file: 'Random-Questions/terraform.md' },
            { id: 'docker', name: 'Docker üê≥', file: 'Random-Questions/docker.md' },
            { id: 'kubernetes', name: 'Kubernetes üéª', file: 'Random-Questions/kubernetes.md' },
            { id: 'cicd', name: 'CI/CD üîÑ', file: 'Random-Questions/cicd.md' },
            { id: 'devops', name: 'DevOps üõ†Ô∏è', file: 'Random-Questions/devops.md' },
            { id: 'system-design', name: 'System Design üç•', file: 'Random-Questions/system-design.md' },
            { id: 'security', name: 'Security üîí', file: 'Random-Questions/security.md' }
        ];
    }

    async loadQuestions() {
        // Load questions from markdown files
        const category = this.currentCategory;
        if (!category) return;

        try {
            const response = await fetch(category.file);
            const content = await response.text();
            this.questions = this.parseQuestions(content, category.id);
        } catch (error) {
            console.error('Error loading questions:', error);
        }
    }

    parseQuestions(content, category) {
        // Parse markdown content to extract questions
        const questions = [];
        const lines = content.split('\n');
        let currentQuestion = null;
        let inDetails = false;

        for (let i = 0; i &lt; lines.length; i++) {
            const line = lines[i].trim();
            
            if (line === '&lt;details&gt;') {
                inDetails = true;
                currentQuestion = { category, content: [] };
            } else if (line.startsWith('&lt;summary&gt;') &amp;&amp; line.endsWith('&lt;/summary&gt;')) {
                currentQuestion.title = line.replace('&lt;summary&gt;', '').replace('&lt;/summary&gt;', '');
            } else if (inDetails &amp;&amp; currentQuestion) {
                if (line === '&lt;/details&gt;') {
                    questions.push(currentQuestion);
                    currentQuestion = null;
                    inDetails = false;
                } else if (line &amp;&amp; !line.startsWith('&lt;summary&gt;')) {
                    currentQuestion.content.push(line);
                }
            }
        }

        return questions;
    }

    getRandomQuestion() {
        const availableQuestions = this.questions.filter(
            q =&gt; !this.shownQuestions.has(q.title)
        );

        if (availableQuestions.length === 0) {
            // Reset shown questions if all have been shown
            this.shownQuestions.clear();
            return this.questions[Math.floor(Math.random() * this.questions.length)];
        }

        const question = availableQuestions[
            Math.floor(Math.random() * availableQuestions.length)
        ];
        this.shownQuestions.add(question.title);
        return question;
    }

    displayQuestion(question) {
        const titleElement = document.getElementById('question-title');
        const contentElement = document.getElementById('question-content');
        
        titleElement.textContent = question.title;
        contentElement.innerHTML = this.formatQuestionContent(question.content);
    }

    formatQuestionContent(content) {
        // Convert markdown-like content to HTML
        return content.map(line =&gt; {
            if (line.startsWith('**')) {
                return `&lt;p&gt;&lt;strong&gt;${line.replace(/\*\*/g, '')}&lt;/strong&gt;&lt;/p&gt;`;
            } else if (line.startsWith('- ')) {
                return `&lt;li&gt;${line.substring(2)}&lt;/li&gt;`;
            } else if (line.startsWith('```')) {
                return '&lt;pre&gt;&lt;code&gt;';
            } else {
                return `&lt;p&gt;${line}&lt;/p&gt;`;
            }
        }).join('');
    }

    setupEventListeners() {
        // Category selection
        document.querySelectorAll('.category-btn').forEach(btn =&gt; {
            btn.addEventListener('click', (e) =&gt; {
                this.selectCategory(e.target.dataset.category);
            });
        });

        // Next question button
        document.getElementById('next-question').addEventListener('click', () =&gt; {
            this.showNextQuestion();
        });

        // Reset session button
        document.getElementById('reset-session').addEventListener('click', () =&gt; {
            this.resetSession();
        });
    }

    selectCategory(categoryId) {
        this.currentCategory = this.categories.find(c =&gt; c.id === categoryId);
        this.shownQuestions.clear();
        this.loadQuestions().then(() =&gt; {
            this.showNextQuestion();
        });
    }

    showNextQuestion() {
        const question = this.getRandomQuestion();
        this.currentQuestion = question;
        this.displayQuestion(question);
    }

    resetSession() {
        this.shownQuestions.clear();
        this.showNextQuestion();
    }
}

// Initialize application
const app = new StackQuest();
</code></pre>
<h2 id="responsive-design-1"><a class="header" href="#responsive-design-1">Responsive Design</a></h2>
<h3 id="css-implementation"><a class="header" href="#css-implementation">CSS Implementation</a></h3>
<pre><code class="language-css">.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}

.categories {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 15px;
    margin-bottom: 30px;
}

.category-btn {
    padding: 15px 20px;
    border: 2px solid #007bff;
    border-radius: 8px;
    background: white;
    cursor: pointer;
    transition: all 0.3s;
}

.category-btn:hover {
    background: #007bff;
    color: white;
}

.question-card {
    background: white;
    border-radius: 8px;
    padding: 30px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}

@media (max-width: 768px) {
    .categories {
        grid-template-columns: 1fr;
    }
    
    .question-card {
        padding: 20px;
    }
}
</code></pre>
<h2 id="session-management-1"><a class="header" href="#session-management-1">Session Management</a></h2>
<h3 id="localstorage-implementation"><a class="header" href="#localstorage-implementation">LocalStorage Implementation</a></h3>
<pre><code class="language-javascript">class SessionManager {
    constructor() {
        this.storageKey = 'stackquest-session';
    }

    saveSession(sessionData) {
        localStorage.setItem(this.storageKey, JSON.stringify(sessionData));
    }

    loadSession() {
        const data = localStorage.getItem(this.storageKey);
        return data ? JSON.parse(data) : null;
    }

    clearSession() {
        localStorage.removeItem(this.storageKey);
    }

    getShownQuestions() {
        const session = this.loadSession();
        return session ? session.shownQuestions : [];
    }

    addShownQuestion(questionTitle) {
        const session = this.loadSession() || { shownQuestions: [] };
        if (!session.shownQuestions.includes(questionTitle)) {
            session.shownQuestions.push(questionTitle);
            this.saveSession(session);
        }
    }
}
</code></pre>
<h2 id="content-management"><a class="header" href="#content-management">Content Management</a></h2>
<h3 id="markdown-question-format"><a class="header" href="#markdown-question-format">Markdown Question Format</a></h3>
<pre><code class="language-markdown">&lt;details&gt;
&lt;summary&gt;What is the difference between TCP and UDP?&lt;/summary&gt;

**Answer:**

TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are both transport layer protocols but serve different purposes:

- **TCP**: Connection-oriented, reliable, ordered delivery
  - Guarantees delivery
  - Error checking and correction
  - Flow control
  - Used for: HTTP, HTTPS, FTP, SSH

- **UDP**: Connectionless, unreliable, faster
  - No delivery guarantee
  - No error checking
  - Lower overhead
  - Used for: DNS, DHCP, streaming, gaming

&lt;/details&gt;
</code></pre>
<h2 id="performance-optimization-1"><a class="header" href="#performance-optimization-1">Performance Optimization</a></h2>
<h3 id="lazy-loading"><a class="header" href="#lazy-loading">Lazy Loading</a></h3>
<pre><code class="language-javascript">class LazyLoader {
    constructor() {
        this.loadedCategories = new Set();
    }

    async loadCategoryOnDemand(categoryId) {
        if (this.loadedCategories.has(categoryId)) {
            return; // Already loaded
        }

        const category = this.categories.find(c =&gt; c.id === categoryId);
        if (!category) return;

        try {
            const response = await fetch(category.file);
            const content = await response.text();
            this.parseAndCacheQuestions(content, categoryId);
            this.loadedCategories.add(categoryId);
        } catch (error) {
            console.error(`Error loading category ${categoryId}:`, error);
        }
    }

    parseAndCacheQuestions(content, categoryId) {
        // Parse and cache questions for faster access
        const questions = this.parseQuestions(content, categoryId);
        this.questionCache[categoryId] = questions;
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-architecture--design"><a class="header" href="#stack-quest-architecture--design">Stack-Quest Architecture &amp; Design</a></h1>
<h2 id="system-architecture-1"><a class="header" href="#system-architecture-1">System Architecture</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User Browser  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ HTTP/HTTPS
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GitHub Pages   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  Markdown Files ‚îÇ
‚îÇ  (Static Host)  ‚îÇ    ‚îÇ  (Content)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  JavaScript     ‚îÇ
‚îÇ  (Client-side)  ‚îÇ
‚îÇ  - Session Mgmt‚îÇ
‚îÇ  - Question Parser‚îÇ
‚îÇ  - UI Rendering ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h2>
<h3 id="1-static-site-architecture"><a class="header" href="#1-static-site-architecture">1. <strong>Static Site Architecture</strong></a></h3>
<ul>
<li><strong>No Backend</strong>: Pure client-side application</li>
<li><strong>GitHub Pages</strong>: Free hosting for static sites</li>
<li><strong>CDN</strong>: Global content delivery via GitHub's CDN</li>
<li><strong>Fast Loading</strong>: No server-side processing</li>
</ul>
<h3 id="2-content-management"><a class="header" href="#2-content-management">2. <strong>Content Management</strong></a></h3>
<ul>
<li><strong>Markdown Files</strong>: Easy to maintain and version control</li>
<li><strong>Git-based</strong>: Content changes via pull requests</li>
<li><strong>Structured Format</strong>: Consistent question format</li>
<li><strong>Category Organization</strong>: Logical content grouping</li>
</ul>
<h3 id="3-user-experience"><a class="header" href="#3-user-experience">3. <strong>User Experience</strong></a></h3>
<ul>
<li><strong>Session Tracking</strong>: Prevents question repetition</li>
<li><strong>Category Selection</strong>: Focused learning paths</li>
<li><strong>Responsive Design</strong>: Works on all devices</li>
<li><strong>Fast Navigation</strong>: Instant question loading</li>
</ul>
<h2 id="component-architecture"><a class="header" href="#component-architecture">Component Architecture</a></h2>
<h3 id="frontend-components"><a class="header" href="#frontend-components">Frontend Components</a></h3>
<ol>
<li><strong>Category Selector</strong>: Choose learning topics</li>
<li><strong>Question Display</strong>: Show questions and answers</li>
<li><strong>Session Manager</strong>: Track shown questions</li>
<li><strong>Content Parser</strong>: Parse markdown to HTML</li>
<li><strong>UI Controller</strong>: Manage user interactions</li>
</ol>
<h3 id="data-flow-1"><a class="header" href="#data-flow-1">Data Flow</a></h3>
<ol>
<li>User selects category</li>
<li>JavaScript loads markdown file</li>
<li>Content parsed into question objects</li>
<li>Random question selected (excluding shown)</li>
<li>Question displayed with formatted content</li>
<li>Session updated with shown question</li>
</ol>
<h2 id="scalability-considerations"><a class="header" href="#scalability-considerations">Scalability Considerations</a></h2>
<h3 id="content-scaling"><a class="header" href="#content-scaling">Content Scaling</a></h3>
<ul>
<li><strong>Modular Structure</strong>: Easy to add new categories</li>
<li><strong>File-based</strong>: No database limits</li>
<li><strong>Version Control</strong>: Git tracks all changes</li>
<li><strong>Contributions</strong>: Community can add content</li>
</ul>
<h3 id="performance-scaling"><a class="header" href="#performance-scaling">Performance Scaling</a></h3>
<ul>
<li><strong>Static Assets</strong>: Served from CDN</li>
<li><strong>Client-side Processing</strong>: No server load</li>
<li><strong>Lazy Loading</strong>: Load categories on demand</li>
<li><strong>Caching</strong>: Browser caches static files</li>
</ul>
<h2 id="technology-stack"><a class="header" href="#technology-stack">Technology Stack</a></h2>
<ul>
<li><strong>HTML5</strong>: Semantic markup</li>
<li><strong>CSS3</strong>: Modern styling and responsive design</li>
<li><strong>JavaScript (ES6+)</strong>: Client-side logic</li>
<li><strong>Markdown</strong>: Content format</li>
<li><strong>GitHub Pages</strong>: Hosting platform</li>
<li><strong>GitHub Actions</strong>: CI/CD automation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-deployment--cicd"><a class="header" href="#stack-quest-deployment--cicd">Stack-Quest Deployment &amp; CI/CD</a></h1>
<h2 id="github-pages-deployment"><a class="header" href="#github-pages-deployment">GitHub Pages Deployment</a></h2>
<h3 id="automatic-deployment"><a class="header" href="#automatic-deployment">Automatic Deployment</a></h3>
<pre><code class="language-yaml">name: Deploy to GitHub Pages

on:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Pages
        uses: actions/configure-pages@v3
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v1
        with:
          path: '.'
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v2
</code></pre>
<h2 id="deployment-process-1"><a class="header" href="#deployment-process-1">Deployment Process</a></h2>
<ol>
<li><strong>Code Push</strong>: Developer pushes to main branch</li>
<li><strong>Trigger</strong>: GitHub Actions workflow starts</li>
<li><strong>Build</strong>: No build step needed (static site)</li>
<li><strong>Deploy</strong>: Files uploaded to GitHub Pages</li>
<li><strong>Live</strong>: Site available immediately</li>
</ol>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="github-pages-settings"><a class="header" href="#github-pages-settings">GitHub Pages Settings</a></h3>
<ul>
<li><strong>Source</strong>: Deploy from branch (main)</li>
<li><strong>Branch</strong>: / (root)</li>
<li><strong>Custom Domain</strong>: Optional</li>
<li><strong>HTTPS</strong>: Automatically enabled</li>
</ul>
<h3 id="repository-structure"><a class="header" href="#repository-structure">Repository Structure</a></h3>
<pre><code>stack-quest/
‚îú‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ script.js
‚îú‚îÄ‚îÄ styles.css
‚îú‚îÄ‚îÄ Random-Questions/
‚îÇ   ‚îú‚îÄ‚îÄ linux.md
‚îÇ   ‚îú‚îÄ‚îÄ aws.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Challenge/
‚îÇ   ‚îú‚îÄ‚îÄ devops-challenges.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ deploy.yml
</code></pre>
<h2 id="custom-domain-setup"><a class="header" href="#custom-domain-setup">Custom Domain Setup</a></h2>
<h3 id="dns-configuration"><a class="header" href="#dns-configuration">DNS Configuration</a></h3>
<ol>
<li>Add CNAME record pointing to GitHub Pages</li>
<li>Configure custom domain in repository settings</li>
<li>Enable HTTPS (automatic)</li>
<li>Wait for DNS propagation</li>
</ol>
<h3 id="example-dns-records"><a class="header" href="#example-dns-records">Example DNS Records</a></h3>
<pre><code>Type: CNAME
Name: www
Value: username.github.io
</code></pre>
<h2 id="rollback-strategy"><a class="header" href="#rollback-strategy">Rollback Strategy</a></h2>
<h3 id="version-control"><a class="header" href="#version-control">Version Control</a></h3>
<ul>
<li><strong>Git History</strong>: All versions tracked</li>
<li><strong>Branch Strategy</strong>: Feature branches for changes</li>
<li><strong>Tagging</strong>: Tag releases for easy rollback</li>
<li><strong>Revert Commits</strong>: Quick rollback via git revert</li>
</ul>
<h3 id="rollback-process"><a class="header" href="#rollback-process">Rollback Process</a></h3>
<ol>
<li>Identify problematic commit</li>
<li>Revert commit or checkout previous version</li>
<li>Push to main branch</li>
<li>GitHub Actions redeploys automatically</li>
</ol>
<h2 id="monitoring-deployment"><a class="header" href="#monitoring-deployment">Monitoring Deployment</a></h2>
<h3 id="github-actions-logs"><a class="header" href="#github-actions-logs">GitHub Actions Logs</a></h3>
<ul>
<li><strong>Workflow Runs</strong>: View deployment history</li>
<li><strong>Build Logs</strong>: Check for errors</li>
<li><strong>Deployment Status</strong>: Monitor deployment progress</li>
</ul>
<h3 id="health-checks"><a class="header" href="#health-checks">Health Checks</a></h3>
<pre><code class="language-bash"># Check site availability
curl -I https://username.github.io/stack-quest/

# Verify content loading
curl https://username.github.io/stack-quest/Random-Questions/linux.md
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li><strong>Test Locally</strong>: Verify changes before pushing</li>
<li><strong>Review Changes</strong>: Use pull requests for review</li>
<li><strong>Monitor Deployments</strong>: Check GitHub Actions status</li>
<li><strong>Version Control</strong>: Commit frequently with clear messages</li>
<li><strong>Documentation</strong>: Keep README updated</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-performance-optimization"><a class="header" href="#stack-quest-performance-optimization">Stack-Quest Performance Optimization</a></h1>
<h2 id="frontend-performance"><a class="header" href="#frontend-performance">Frontend Performance</a></h2>
<h3 id="asset-optimization"><a class="header" href="#asset-optimization">Asset Optimization</a></h3>
<ul>
<li><strong>Minification</strong>: Minify CSS and JavaScript</li>
<li><strong>Compression</strong>: Enable Gzip compression</li>
<li><strong>Caching</strong>: Set appropriate cache headers</li>
<li><strong>CDN</strong>: Leverage GitHub Pages CDN</li>
</ul>
<h3 id="code-optimization"><a class="header" href="#code-optimization">Code Optimization</a></h3>
<pre><code class="language-javascript">// Debounce category selection
function debounce(func, wait) {
    let timeout;
    return function executedFunction(...args) {
        const later = () =&gt; {
            clearTimeout(timeout);
            func(...args);
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
    };
}

// Lazy load questions
const questionLoader = {
    cache: new Map(),
    
    async load(category) {
        if (this.cache.has(category)) {
            return this.cache.get(category);
        }
        
        const questions = await fetch(`Random-Questions/${category}.md`)
            .then(r =&gt; r.text())
            .then(parseQuestions);
        
        this.cache.set(category, questions);
        return questions;
    }
};
</code></pre>
<h2 id="loading-performance"><a class="header" href="#loading-performance">Loading Performance</a></h2>
<h3 id="lazy-loading-strategy"><a class="header" href="#lazy-loading-strategy">Lazy Loading Strategy</a></h3>
<ul>
<li><strong>On-Demand Loading</strong>: Load categories when selected</li>
<li><strong>Caching</strong>: Cache loaded questions in memory</li>
<li><strong>Preloading</strong>: Preload popular categories</li>
<li><strong>Progressive Enhancement</strong>: Basic functionality first</li>
</ul>
<h3 id="resource-hints"><a class="header" href="#resource-hints">Resource Hints</a></h3>
<pre><code class="language-html">&lt;!-- Preconnect to GitHub CDN --&gt;
&lt;link rel="preconnect" href="https://github.com"&gt;

&lt;!-- Prefetch popular categories --&gt;
&lt;link rel="prefetch" href="Random-Questions/linux.md"&gt;
&lt;link rel="prefetch" href="Random-Questions/aws.md"&gt;
</code></pre>
<h2 id="caching-strategy"><a class="header" href="#caching-strategy">Caching Strategy</a></h2>
<h3 id="browser-caching"><a class="header" href="#browser-caching">Browser Caching</a></h3>
<pre><code class="language-javascript">// Service Worker for offline support
self.addEventListener('install', (event) =&gt; {
    event.waitUntil(
        caches.open('stackquest-v1').then((cache) =&gt; {
            return cache.addAll([
                '/',
                '/index.html',
                '/script.js',
                '/styles.css'
            ]);
        })
    );
});

self.addEventListener('fetch', (event) =&gt; {
    event.respondWith(
        caches.match(event.request).then((response) =&gt; {
            return response || fetch(event.request);
        })
    );
});
</code></pre>
<h3 id="localstorage-caching"><a class="header" href="#localstorage-caching">LocalStorage Caching</a></h3>
<pre><code class="language-javascript">class CacheManager {
    constructor() {
        this.cachePrefix = 'stackquest_';
        this.cacheExpiry = 24 * 60 * 60 * 1000; // 24 hours
    }

    set(key, value) {
        const item = {
            value,
            timestamp: Date.now()
        };
        localStorage.setItem(
            this.cachePrefix + key,
            JSON.stringify(item)
        );
    }

    get(key) {
        const item = localStorage.getItem(this.cachePrefix + key);
        if (!item) return null;

        const parsed = JSON.parse(item);
        if (Date.now() - parsed.timestamp &gt; this.cacheExpiry) {
            localStorage.removeItem(this.cachePrefix + key);
            return null;
        }

        return parsed.value;
    }
}
</code></pre>
<h2 id="performance-metrics"><a class="header" href="#performance-metrics">Performance Metrics</a></h2>
<h3 id="key-metrics"><a class="header" href="#key-metrics">Key Metrics</a></h3>
<ul>
<li><strong>First Contentful Paint (FCP)</strong>: &lt; 1.5s</li>
<li><strong>Largest Contentful Paint (LCP)</strong>: &lt; 2.5s</li>
<li><strong>Time to Interactive (TTI)</strong>: &lt; 3.5s</li>
<li><strong>Cumulative Layout Shift (CLS)</strong>: &lt; 0.1</li>
</ul>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<pre><code class="language-javascript">// Performance monitoring
window.addEventListener('load', () =&gt; {
    const perfData = performance.getEntriesByType('navigation')[0];
    
    console.log('Page Load Time:', perfData.loadEventEnd - perfData.fetchStart);
    console.log('DOM Content Loaded:', perfData.domContentLoadedEventEnd - perfData.fetchStart);
    console.log('First Paint:', performance.getEntriesByType('paint')[0].startTime);
});
</code></pre>
<h2 id="optimization-techniques"><a class="header" href="#optimization-techniques">Optimization Techniques</a></h2>
<ol>
<li><strong>Code Splitting</strong>: Load only needed code</li>
<li><strong>Tree Shaking</strong>: Remove unused code</li>
<li><strong>Image Optimization</strong>: Use WebP format</li>
<li><strong>Font Optimization</strong>: Subset fonts, use font-display</li>
<li><strong>Critical CSS</strong>: Inline critical CSS</li>
<li><strong>Async Loading</strong>: Load non-critical scripts async</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stack-quest-technical-qa"><a class="header" href="#stack-quest-technical-qa">Stack-Quest Technical Q&amp;A</a></h1>
<h2 id="architecture--design-questions-1"><a class="header" href="#architecture--design-questions-1">Architecture &amp; Design Questions</a></h2>
<h3 id="q1-walk-me-through-the-architecture-of-stackquest"><a class="header" href="#q1-walk-me-through-the-architecture-of-stackquest">Q1: "Walk me through the architecture of StackQuest."</a></h3>
<p><strong>Answer:</strong>
"StackQuest is a static site application hosted on GitHub Pages. It uses pure client-side JavaScript to parse markdown files containing questions and answers. The architecture is simple yet effective:</p>
<ul>
<li><strong>Frontend</strong>: HTML, CSS, JavaScript (ES6+)</li>
<li><strong>Content</strong>: Markdown files organized by category</li>
<li><strong>Hosting</strong>: GitHub Pages (free, CDN-backed)</li>
<li><strong>Deployment</strong>: Automated via GitHub Actions</li>
<li><strong>Session Management</strong>: LocalStorage for client-side tracking</li>
</ul>
<p>The design prioritizes simplicity, performance, and maintainability."</p>
<h3 id="q2-why-did-you-choose-a-static-site-over-a-dynamic-application"><a class="header" href="#q2-why-did-you-choose-a-static-site-over-a-dynamic-application">Q2: "Why did you choose a static site over a dynamic application?"</a></h3>
<p><strong>Answer:</strong>
"Static site was chosen for several reasons:</p>
<ol>
<li><strong>Cost</strong>: Free hosting on GitHub Pages</li>
<li><strong>Performance</strong>: No server-side processing, fast loading</li>
<li><strong>Simplicity</strong>: Easy to maintain and deploy</li>
<li><strong>Scalability</strong>: CDN handles traffic automatically</li>
<li><strong>Reliability</strong>: No server downtime concerns</li>
<li><strong>Version Control</strong>: Content changes tracked in Git</li>
</ol>
<p>For a knowledge base with read-only content, static site is the optimal choice."</p>
<h3 id="q3-how-do-you-handle-session-management-without-a-backend"><a class="header" href="#q3-how-do-you-handle-session-management-without-a-backend">Q3: "How do you handle session management without a backend?"</a></h3>
<p><strong>Answer:</strong>
"Client-side session management using LocalStorage:</p>
<ol>
<li><strong>Question Tracking</strong>: Store shown question IDs in LocalStorage</li>
<li><strong>Session Persistence</strong>: Survives page refreshes</li>
<li><strong>Reset Capability</strong>: Clear session on demand</li>
<li><strong>Privacy</strong>: All data stays in browser</li>
</ol>
<p>This approach works well for the use case and maintains user privacy."</p>
<h2 id="technical-implementation-questions"><a class="header" href="#technical-implementation-questions">Technical Implementation Questions</a></h2>
<h3 id="q4-how-do-you-parse-markdown-files-in-the-browser"><a class="header" href="#q4-how-do-you-parse-markdown-files-in-the-browser">Q4: "How do you parse markdown files in the browser?"</a></h3>
<p><strong>Answer:</strong>
"Custom markdown parser for the question format:</p>
<ol>
<li><strong>Fetch</strong>: Load markdown file via fetch API</li>
<li><strong>Parse</strong>: Extract questions from <code>&lt;details&gt;</code> blocks</li>
<li><strong>Structure</strong>: Convert to JavaScript objects</li>
<li><strong>Cache</strong>: Store parsed questions in memory</li>
<li><strong>Render</strong>: Convert to HTML for display</li>
</ol>
<p>The parser handles the specific markdown format used for questions."</p>
<h3 id="q5-how-would-you-scale-this-to-handle-more-content"><a class="header" href="#q5-how-would-you-scale-this-to-handle-more-content">Q5: "How would you scale this to handle more content?"</a></h3>
<p><strong>Answer:</strong>
"Scaling strategies:</p>
<ol>
<li><strong>Lazy Loading</strong>: Load categories on demand</li>
<li><strong>Pagination</strong>: Split large categories into pages</li>
<li><strong>Search</strong>: Add client-side search functionality</li>
<li><strong>Indexing</strong>: Pre-build question index</li>
<li><strong>Caching</strong>: Aggressive browser caching</li>
<li><strong>CDN</strong>: Leverage GitHub Pages CDN</li>
</ol>
<p>The static architecture scales naturally with CDN distribution."</p>
<h2 id="performance-questions"><a class="header" href="#performance-questions">Performance Questions</a></h2>
<h3 id="q6-how-do-you-optimize-performance"><a class="header" href="#q6-how-do-you-optimize-performance">Q6: "How do you optimize performance?"</a></h3>
<p><strong>Answer:</strong>
"Multiple optimization strategies:</p>
<ol>
<li><strong>Asset Minification</strong>: Minify CSS and JavaScript</li>
<li><strong>Lazy Loading</strong>: Load content on demand</li>
<li><strong>Caching</strong>: Browser and LocalStorage caching</li>
<li><strong>CDN</strong>: GitHub Pages CDN for global distribution</li>
<li><strong>Code Splitting</strong>: Load only needed code</li>
<li><strong>Service Worker</strong>: Offline support and caching</li>
</ol>
<p>Performance is critical for user experience."</p>
<h3 id="q7-what-are-the-performance-metrics-you-track"><a class="header" href="#q7-what-are-the-performance-metrics-you-track">Q7: "What are the performance metrics you track?"</a></h3>
<p><strong>Answer:</strong>
"Key metrics:</p>
<ol>
<li><strong>First Contentful Paint (FCP)</strong>: &lt; 1.5s</li>
<li><strong>Largest Contentful Paint (LCP)</strong>: &lt; 2.5s</li>
<li><strong>Time to Interactive (TTI)</strong>: &lt; 3.5s</li>
<li><strong>Cumulative Layout Shift (CLS)</strong>: &lt; 0.1</li>
<li><strong>Page Load Time</strong>: Monitor via Performance API</li>
</ol>
<p>These metrics ensure good user experience."</p>
<h2 id="deployment-questions"><a class="header" href="#deployment-questions">Deployment Questions</a></h2>
<h3 id="q8-describe-your-cicd-pipeline"><a class="header" href="#q8-describe-your-cicd-pipeline">Q8: "Describe your CI/CD pipeline."</a></h3>
<p><strong>Answer:</strong>
"GitHub Actions workflow:</p>
<ol>
<li><strong>Trigger</strong>: Push to main branch</li>
<li><strong>Build</strong>: No build step (static site)</li>
<li><strong>Deploy</strong>: Upload to GitHub Pages</li>
<li><strong>Automation</strong>: Fully automated deployment</li>
<li><strong>Rollback</strong>: Git revert for quick rollback</li>
</ol>
<p>Simple and effective for static site deployment."</p>
<h3 id="q9-how-do-you-handle-rollbacks"><a class="header" href="#q9-how-do-you-handle-rollbacks">Q9: "How do you handle rollbacks?"</a></h3>
<p><strong>Answer:</strong>
"Rollback strategies:</p>
<ol>
<li><strong>Git Revert</strong>: Revert problematic commits</li>
<li><strong>Branch Strategy</strong>: Keep stable branch</li>
<li><strong>Version Tags</strong>: Tag releases for reference</li>
<li><strong>Git History</strong>: All versions in Git history</li>
<li><strong>Quick Deploy</strong>: GitHub Actions redeploys automatically</li>
</ol>
<p>Fast and reliable rollback process."</p>
<h2 id="content-management-questions"><a class="header" href="#content-management-questions">Content Management Questions</a></h2>
<h3 id="q10-how-do-you-manage-content-updates"><a class="header" href="#q10-how-do-you-manage-content-updates">Q10: "How do you manage content updates?"</a></h3>
<p><strong>Answer:</strong>
"Git-based content management:</p>
<ol>
<li><strong>Markdown Files</strong>: Easy to edit and review</li>
<li><strong>Pull Requests</strong>: Review before merging</li>
<li><strong>Version Control</strong>: All changes tracked</li>
<li><strong>Contributions</strong>: Community can contribute</li>
<li><strong>Automation</strong>: Auto-deploy on merge</li>
</ol>
<p>This approach ensures quality and traceability."</p>
<h3 id="q11-how-would-you-add-search-functionality"><a class="header" href="#q11-how-would-you-add-search-functionality">Q11: "How would you add search functionality?"</a></h3>
<p><strong>Answer:</strong>
"Client-side search implementation:</p>
<ol>
<li><strong>Index Building</strong>: Pre-build search index</li>
<li><strong>Full-Text Search</strong>: Search question titles and content</li>
<li><strong>Fuzzy Matching</strong>: Handle typos and variations</li>
<li><strong>Category Filtering</strong>: Filter by category</li>
<li><strong>Performance</strong>: Efficient search algorithm</li>
</ol>
<p>Would use libraries like Fuse.js or implement custom search."</p>
<h2 id="advanced-questions-1"><a class="header" href="#advanced-questions-1">Advanced Questions</a></h2>
<h3 id="q12-how-would-you-add-user-progress-tracking"><a class="header" href="#q12-how-would-you-add-user-progress-tracking">Q12: "How would you add user progress tracking?"</a></h3>
<p><strong>Answer:</strong>
"Enhanced session management:</p>
<ol>
<li><strong>Progress Storage</strong>: Track completed questions</li>
<li><strong>Statistics</strong>: Show progress per category</li>
<li><strong>Achievements</strong>: Badge system for milestones</li>
<li><strong>Export</strong>: Export progress data</li>
<li><strong>Sync</strong>: Optional cloud sync (future)</li>
</ol>
<p>Would extend LocalStorage with structured progress data."</p>
<h3 id="q13-how-do-you-handle-browser-compatibility"><a class="header" href="#q13-how-do-you-handle-browser-compatibility">Q13: "How do you handle browser compatibility?"</a></h3>
<p><strong>Answer:</strong>
"Browser compatibility strategy:</p>
<ol>
<li><strong>ES6+ Support</strong>: Modern JavaScript features</li>
<li><strong>Polyfills</strong>: Add polyfills for older browsers</li>
<li><strong>Feature Detection</strong>: Check for API support</li>
<li><strong>Graceful Degradation</strong>: Fallback for unsupported features</li>
<li><strong>Testing</strong>: Test on multiple browsers</li>
</ol>
<p>The application targets modern browsers with ES6+ support."</p>
<h3 id="q14-what-would-you-do-if-github-pages-went-down"><a class="header" href="#q14-what-would-you-do-if-github-pages-went-down">Q14: "What would you do if GitHub Pages went down?"</a></h3>
<p><strong>Answer:</strong>
"Contingency planning:</p>
<ol>
<li><strong>Backup Hosting</strong>: Alternative static hosting (Netlify, Vercel)</li>
<li><strong>CDN</strong>: Use multiple CDN providers</li>
<li><strong>Monitoring</strong>: Set up uptime monitoring</li>
<li><strong>Quick Migration</strong>: Terraform/automation for quick switch</li>
<li><strong>DNS</strong>: Quick DNS changes for failover</li>
</ol>
<p>GitHub Pages has high availability, but having a backup plan is prudent."</p>
<h3 id="q15-how-would-you-add-analytics-to-track-usage"><a class="header" href="#q15-how-would-you-add-analytics-to-track-usage">Q15: "How would you add analytics to track usage?"</a></h3>
<p><strong>Answer:</strong>
"Analytics implementation:</p>
<ol>
<li><strong>Privacy-First</strong>: Use privacy-respecting analytics (Plausible, Fathom)</li>
<li><strong>Client-Side</strong>: JavaScript-based tracking</li>
<li><strong>No Cookies</strong>: Cookie-free analytics</li>
<li><strong>GDPR Compliant</strong>: Respect user privacy</li>
<li><strong>Custom Events</strong>: Track question views, category selections</li>
</ol>
<p>Would implement lightweight, privacy-focused analytics."</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-1"><a class="header" href="#opensource-llm-rag-stack-1">Opensource-LLM-RAG-Stack</a></h1>
<p>A production-ready, containerized RAG (Retrieval-Augmented Generation) stack with comprehensive monitoring, observability, and enterprise-grade DevOps practices.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>The Opensource-LLM-RAG-Stack is a complete, self-contained RAG system that demonstrates enterprise-grade AI infrastructure practices. It combines vector databases, LLM inference, web interfaces, and comprehensive monitoring in a single Docker Compose setup.</p>
<p><img src="opensource-llm-rag-stack/../images/RAG-LLM-stack.png" alt="OpenSource RAG LLM Stack Architecture" /></p>
<h2 id="key-features-2"><a class="header" href="#key-features-2">Key Features</a></h2>
<ul>
<li><strong>Containerized Microservices</strong>: Docker Compose orchestration with complete service isolation</li>
<li><strong>Vector Database</strong>: Chroma for semantic search and embeddings storage</li>
<li><strong>LLM Integration</strong>: Containerized Ollama for reproducible LLM inference with Open WebUI interface</li>
<li><strong>Data Persistence</strong>: PostgreSQL with optimized schema for chat history and RAG documents</li>
<li><strong>Observability</strong>: Prometheus metrics collection with Grafana dashboards</li>
<li><strong>Monitoring</strong>: Real-time service health monitoring and performance metrics</li>
<li><strong>Security</strong>: Network isolation, environment-based configuration, and data encryption</li>
</ul>
<h2 id="project-highlights-2"><a class="header" href="#project-highlights-2">Project Highlights</a></h2>
<p>This project demonstrates:</p>
<ul>
<li>Modern AI/ML infrastructure patterns</li>
<li>Containerized microservices architecture</li>
<li>Vector database integration</li>
<li>Comprehensive observability</li>
<li>Production-ready RAG implementation</li>
<li>Enterprise DevOps practices</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-architecture"><a class="header" href="#opensource-llm-rag-stack-architecture">Opensource-LLM-RAG-Stack Architecture</a></h1>
<h2 id="system-architecture-2"><a class="header" href="#system-architecture-2">System Architecture</a></h2>
<p><img src="opensource-llm-rag-stack/../images/RAG-LLM-stack.png" alt="OpenSource RAG LLM Stack Architecture" /></p>
<p>This diagram illustrates the complete architecture of the OpenSource RAG LLM Stack, showing the interaction between all components for retrieval-augmented generation, chat history management, and comprehensive monitoring.</p>
<h2 id="rag-flow"><a class="header" href="#rag-flow">RAG Flow</a></h2>
<p><strong>RAG Flow:</strong> User ‚Üí Open WebUI ‚Üí Chroma (retrieve) ‚Üí Open WebUI ‚Üí Ollama (generate) ‚Üí Open WebUI ‚Üí User</p>
<h2 id="core-components"><a class="header" href="#core-components">Core Components</a></h2>
<h3 id="open-webui"><a class="header" href="#open-webui">Open WebUI</a></h3>
<ul>
<li><strong>Purpose</strong>: User interface for chat and document management</li>
<li><strong>Port</strong>: 3000</li>
<li><strong>Features</strong>:
<ul>
<li>Chat interface</li>
<li>Document upload and processing</li>
<li>RAG integration</li>
<li>Chat history management</li>
</ul>
</li>
</ul>
<h3 id="ollama"><a class="header" href="#ollama">Ollama</a></h3>
<ul>
<li><strong>Purpose</strong>: LLM inference engine</li>
<li><strong>Port</strong>: 11434</li>
<li><strong>Features</strong>:
<ul>
<li>Model management</li>
<li>Text generation</li>
<li>Embedding generation</li>
<li>Containerized deployment</li>
</ul>
</li>
</ul>
<h3 id="chroma"><a class="header" href="#chroma">Chroma</a></h3>
<ul>
<li><strong>Purpose</strong>: Vector database for embeddings</li>
<li><strong>Port</strong>: 8000</li>
<li><strong>Features</strong>:
<ul>
<li>Semantic search</li>
<li>Embedding storage</li>
<li>Collection management</li>
<li>Similarity search</li>
</ul>
</li>
</ul>
<h3 id="postgresql"><a class="header" href="#postgresql">PostgreSQL</a></h3>
<ul>
<li><strong>Purpose</strong>: Relational database for chat history and metadata</li>
<li><strong>Port</strong>: 5432</li>
<li><strong>Features</strong>:
<ul>
<li>Chat session storage</li>
<li>Message history</li>
<li>Document metadata</li>
<li>Full-text search</li>
</ul>
</li>
</ul>
<h2 id="monitoring-stack"><a class="header" href="#monitoring-stack">Monitoring Stack</a></h2>
<h3 id="prometheus"><a class="header" href="#prometheus">Prometheus</a></h3>
<ul>
<li><strong>Purpose</strong>: Metrics collection and storage</li>
<li><strong>Port</strong>: 9090</li>
<li><strong>Features</strong>:
<ul>
<li>Time-series database</li>
<li>Service health monitoring</li>
<li>Performance metrics</li>
<li>Alert rule evaluation</li>
</ul>
</li>
</ul>
<h3 id="grafana"><a class="header" href="#grafana">Grafana</a></h3>
<ul>
<li><strong>Purpose</strong>: Visualization and dashboards</li>
<li><strong>Port</strong>: 3001</li>
<li><strong>Features</strong>:
<ul>
<li>Real-time dashboards</li>
<li>Service health visualization</li>
<li>Performance analytics</li>
<li>Custom dashboard creation</li>
</ul>
</li>
</ul>
<h2 id="data-flow-2"><a class="header" href="#data-flow-2">Data Flow</a></h2>
<h3 id="document-processing-flow"><a class="header" href="#document-processing-flow">Document Processing Flow</a></h3>
<ol>
<li>User uploads document via Open WebUI</li>
<li>Document is chunked into smaller pieces</li>
<li>Chunks are converted to embeddings via Ollama</li>
<li>Embeddings are stored in Chroma vector database</li>
<li>Metadata is stored in PostgreSQL</li>
</ol>
<h3 id="query-flow-rag"><a class="header" href="#query-flow-rag">Query Flow (RAG)</a></h3>
<ol>
<li>User asks question in Open WebUI</li>
<li>Question is converted to embedding</li>
<li>Chroma performs similarity search</li>
<li>Relevant document chunks are retrieved</li>
<li>Chunks are added to prompt context</li>
<li>Ollama generates response using context</li>
<li>Response is displayed to user</li>
<li>Conversation is saved to PostgreSQL</li>
</ol>
<h2 id="infrastructure-as-code-1"><a class="header" href="#infrastructure-as-code-1">Infrastructure as Code</a></h2>
<p>The entire stack is defined in Docker Compose:</p>
<pre><code class="language-yaml">services:
  ollama:
    image: ollama/ollama:latest
    ports: ["11434:11434"]
    volumes:
      - ollama-data:/root/.ollama

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports: ["3000:8080"]
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434
      - VECTOR_DB=chroma
      - DATABASE_URL=postgresql://user:password@postgres:5432/chatdb

  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    ports: ["8000:8000"]

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: chatdb

  prometheus:
    image: prom/prometheus:latest
    ports: ["9090:9090"]

  grafana:
    image: grafana/grafana-oss:latest
    ports: ["3001:3000"]
</code></pre>
<h2 id="data-persistence"><a class="header" href="#data-persistence">Data Persistence</a></h2>
<p>All data is persisted in Docker volumes:</p>
<ul>
<li><code>ollama-data</code>: LLM models and Ollama configurations</li>
<li><code>openwebui-data</code>: WebUI configurations and user data</li>
<li><code>chroma-data</code>: Vector embeddings and collections</li>
<li><code>pgdata</code>: PostgreSQL database files</li>
<li><code>grafana-data</code>: Dashboard configurations and user settings</li>
<li><code>prometheus-data</code>: Metrics time-series data</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-setup"><a class="header" href="#opensource-llm-rag-stack-setup">Opensource-LLM-RAG-Stack Setup</a></h1>
<h2 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h2>
<h3 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h3>
<ul>
<li>Docker &amp; Docker Compose</li>
<li>8GB+ RAM (for LLM models)</li>
</ul>
<h3 id="complete-self-contained-setup"><a class="header" href="#complete-self-contained-setup">Complete Self-Contained Setup</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone &lt;your-repo-url&gt;
cd Opensource-LLM-RAG-Stack

# Quick start (includes model setup)
./start.sh

# Or manual setup:
# Start all services (includes Ollama)
docker-compose up -d

# Set up Ollama with a model
./scripts/setup-ollama.sh

# Check service status
docker-compose ps
</code></pre>
<h3 id="alternative-use-local-ollama-installation"><a class="header" href="#alternative-use-local-ollama-installation">Alternative: Use Local Ollama Installation</a></h3>
<pre><code class="language-bash"># Prerequisites: Install Ollama locally (https://ollama.ai)
# Start Ollama on your host machine
ollama serve

# Start the RAG stack (connects to local Ollama)
docker-compose -f local-ollama-docker-compose.yml up -d

# Check service status
docker-compose -f local-ollama-docker-compose.yml ps
</code></pre>
<h2 id="access-services"><a class="header" href="#access-services">Access Services</a></h2>
<ul>
<li><strong>Open WebUI</strong>: http://localhost:3000 (AI Chat Interface)</li>
<li><strong>Grafana</strong>: http://localhost:3001 (admin/admin123)</li>
<li><strong>Prometheus</strong>: http://localhost:9090 (Metrics)</li>
<li><strong>Chroma API</strong>: http://localhost:8000 (Vector Database)</li>
<li><strong>PostgreSQL</strong>: localhost:5432 (Database)</li>
<li><strong>Ollama API</strong>: http://localhost:11434 (LLM Service)</li>
</ul>
<h2 id="ollama-model-management"><a class="header" href="#ollama-model-management">Ollama Model Management</a></h2>
<h3 id="list-available-models"><a class="header" href="#list-available-models">List Available Models</a></h3>
<pre><code class="language-bash">docker exec -it ollama ollama list
</code></pre>
<h3 id="pull-a-new-model"><a class="header" href="#pull-a-new-model">Pull a New Model</a></h3>
<pre><code class="language-bash">docker exec -it ollama ollama pull llama3.2:3b
</code></pre>
<h3 id="remove-a-model"><a class="header" href="#remove-a-model">Remove a Model</a></h3>
<pre><code class="language-bash">docker exec -it ollama ollama rm llama3.2:3b
</code></pre>
<h3 id="run-setup-script"><a class="header" href="#run-setup-script">Run Setup Script</a></h3>
<pre><code class="language-bash"># Guided model installation
./scripts/setup-ollama.sh
</code></pre>
<h2 id="recommended-models"><a class="header" href="#recommended-models">Recommended Models</a></h2>
<ul>
<li><strong>llama3.2:3b</strong> (3B params, ~2GB) - Best balance of speed and quality</li>
<li><strong>llama3.2:1b</strong> (1B params, ~1GB) - Fastest, good for basic tasks</li>
<li><strong>mistral:7b</strong> (7B params, ~4GB) - High quality, slower</li>
<li><strong>codellama:7b</strong> (7B params, ~4GB) - Specialized for coding tasks</li>
<li><strong>gemma:2b</strong> (2B params, ~1.5GB) - Google's efficient model</li>
</ul>
<h2 id="database-schema"><a class="header" href="#database-schema">Database Schema</a></h2>
<p>The database is initialized with an optimized schema for RAG operations:</p>
<pre><code class="language-sql">-- Chat Sessions Management
CREATE TABLE chat_sessions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id VARCHAR(255) NOT NULL,
    session_name VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Message Storage with Full-Text Search
CREATE TABLE chat_messages (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    session_id UUID REFERENCES chat_sessions(id),
    role VARCHAR(50) CHECK (role IN ('user', 'assistant', 'system')),
    content TEXT NOT NULL,
    token_count INTEGER DEFAULT 0
);

-- RAG Document Storage
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    title VARCHAR(500),
    content TEXT NOT NULL,
    source VARCHAR(500),
    embedding_id VARCHAR(255), -- Chroma reference
    metadata JSONB DEFAULT '{}'::jsonb
);

-- Performance Indexes
CREATE INDEX idx_documents_content_gin ON documents 
USING gin(to_tsvector('english', content));
</code></pre>
<h2 id="service-management"><a class="header" href="#service-management">Service Management</a></h2>
<h3 id="view-logs"><a class="header" href="#view-logs">View Logs</a></h3>
<pre><code class="language-bash">docker-compose logs [service-name]
</code></pre>
<h3 id="restart-services"><a class="header" href="#restart-services">Restart Services</a></h3>
<pre><code class="language-bash">docker-compose restart [service-name]
</code></pre>
<h3 id="clean-restart"><a class="header" href="#clean-restart">Clean Restart</a></h3>
<pre><code class="language-bash">docker-compose down
docker-compose up -d
</code></pre>
<h3 id="for-local-ollama-setup"><a class="header" href="#for-local-ollama-setup">For Local Ollama Setup</a></h3>
<pre><code class="language-bash">docker-compose -f local-ollama-docker-compose.yml [command]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-rag-implementation-guide"><a class="header" href="#opensource-llm-rag-stack-rag-implementation-guide">Opensource-LLM-RAG-Stack RAG Implementation Guide</a></h1>
<h2 id="rag-implementation"><a class="header" href="#rag-implementation">RAG Implementation</a></h2>
<h3 id="1-document-upload--processing"><a class="header" href="#1-document-upload--processing">1. Document Upload &amp; Processing</a></h3>
<pre><code class="language-bash"># Access Open WebUI
open http://localhost:3000

# Navigate to Knowledge section
# Upload documents (PDF, TXT, etc.)
# System automatically:
# - Chunks documents
# - Generates embeddings
# - Stores in Chroma vector database
</code></pre>
<h3 id="2-verify-vector-storage"><a class="header" href="#2-verify-vector-storage">2. Verify Vector Storage</a></h3>
<pre><code class="language-bash"># Check Chroma collections
curl -s http://localhost:8000/api/v2/tenants/default/databases/default/collections | jq '.'

# Verify heartbeat
curl -s -o /dev/null -w "%{http_code}\n" http://localhost:8000/api/v2/heartbeat
</code></pre>
<h3 id="3-query-with-rag"><a class="header" href="#3-query-with-rag">3. Query with RAG</a></h3>
<ul>
<li>Ask questions in Open WebUI that reference uploaded content</li>
<li>System retrieves relevant chunks from Chroma</li>
<li>Augments prompts with retrieved context</li>
<li>Generates responses using Ollama LLM</li>
</ul>
<h2 id="rag-workflow"><a class="header" href="#rag-workflow">RAG Workflow</a></h2>
<h3 id="step-1-document-ingestion"><a class="header" href="#step-1-document-ingestion">Step 1: Document Ingestion</a></h3>
<ol>
<li>User uploads document via Open WebUI</li>
<li>Document is parsed and chunked</li>
<li>Each chunk is processed for embedding generation</li>
</ol>
<h3 id="step-2-embedding-generation"><a class="header" href="#step-2-embedding-generation">Step 2: Embedding Generation</a></h3>
<ol>
<li>Chunks are sent to Ollama for embedding</li>
<li>Embeddings are generated using the selected model</li>
<li>Embeddings are normalized for similarity search</li>
</ol>
<h3 id="step-3-vector-storage"><a class="header" href="#step-3-vector-storage">Step 3: Vector Storage</a></h3>
<ol>
<li>Embeddings are stored in Chroma with metadata</li>
<li>Document metadata is stored in PostgreSQL</li>
<li>Indexes are created for fast retrieval</li>
</ol>
<h3 id="step-4-query-processing"><a class="header" href="#step-4-query-processing">Step 4: Query Processing</a></h3>
<ol>
<li>User query is converted to embedding</li>
<li>Chroma performs similarity search</li>
<li>Top-K relevant chunks are retrieved</li>
<li>Chunks are ranked by relevance score</li>
</ol>
<h3 id="step-5-context-augmentation"><a class="header" href="#step-5-context-augmentation">Step 5: Context Augmentation</a></h3>
<ol>
<li>Retrieved chunks are formatted as context</li>
<li>Context is prepended to user query</li>
<li>Augmented prompt is sent to Ollama</li>
</ol>
<h3 id="step-6-response-generation"><a class="header" href="#step-6-response-generation">Step 6: Response Generation</a></h3>
<ol>
<li>Ollama generates response using context</li>
<li>Response is displayed to user</li>
<li>Conversation is saved to PostgreSQL</li>
</ol>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="rag-not-working---document-upload-issues"><a class="header" href="#rag-not-working---document-upload-issues">RAG Not Working - Document Upload Issues</a></h3>
<pre><code class="language-bash"># Check Chroma connection
curl -s -o /dev/null -w "%{http_code}\n" http://localhost:8000/api/v2/heartbeat

# Create tenant/database if needed
curl -X POST http://localhost:8000/api/v2/tenants \
  -H "Content-Type: application/json" \
  -d '{"name": "default"}'

curl -X POST http://localhost:8000/api/v2/tenants/default/databases \
  -H "Content-Type: application/json" \
  -d '{"name": "default"}'
</code></pre>
<h3 id="database-connection-issues"><a class="header" href="#database-connection-issues">Database Connection Issues</a></h3>
<pre><code class="language-bash"># Check PostgreSQL status
docker-compose logs postgres

# Verify database initialization
docker exec -it postgres psql -U user -d chatdb -c "\dt"
</code></pre>
<h3 id="embedding-generation-issues"><a class="header" href="#embedding-generation-issues">Embedding Generation Issues</a></h3>
<pre><code class="language-bash"># Check Ollama status
curl http://localhost:11434/api/tags

# Verify model is loaded
docker exec -it ollama ollama list

# Test embedding generation
curl http://localhost:11434/api/embeddings \
  -d '{"model": "llama3.2:3b", "prompt": "test"}'
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="document-chunking"><a class="header" href="#document-chunking">Document Chunking</a></h3>
<ul>
<li>Optimal chunk size: 500-1000 tokens</li>
<li>Overlap between chunks: 100-200 tokens</li>
<li>Preserve context boundaries (paragraphs, sections)</li>
</ul>
<h3 id="embedding-models"><a class="header" href="#embedding-models">Embedding Models</a></h3>
<ul>
<li>Use consistent embedding model for all documents</li>
<li>Match embedding model with generation model when possible</li>
<li>Consider model size vs. quality trade-offs</li>
</ul>
<h3 id="retrieval-strategy"><a class="header" href="#retrieval-strategy">Retrieval Strategy</a></h3>
<ul>
<li>Top-K retrieval: 3-5 most relevant chunks</li>
<li>Re-ranking: Consider implementing re-ranking for better results</li>
<li>Metadata filtering: Use metadata for precise retrieval</li>
</ul>
<h3 id="context-management"><a class="header" href="#context-management">Context Management</a></h3>
<ul>
<li>Limit context window to model's maximum</li>
<li>Prioritize most relevant chunks</li>
<li>Include source citations in responses</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-monitoring"><a class="header" href="#opensource-llm-rag-stack-monitoring">Opensource-LLM-RAG-Stack Monitoring</a></h1>
<h2 id="monitoring--observability"><a class="header" href="#monitoring--observability">Monitoring &amp; Observability</a></h2>
<h3 id="prometheus-metrics"><a class="header" href="#prometheus-metrics">Prometheus Metrics</a></h3>
<p>Prometheus collects metrics from all services:</p>
<ul>
<li><strong>Service Health</strong>: <code>up{job=~"prometheus|postgres_exporter"}</code></li>
<li><strong>Database Performance</strong>: PostgreSQL exporter metrics</li>
<li><strong>Request Rates</strong>: HTTP request monitoring</li>
<li><strong>Resource Usage</strong>: Container and system metrics</li>
</ul>
<h3 id="grafana-dashboards"><a class="header" href="#grafana-dashboards">Grafana Dashboards</a></h3>
<p>Pre-configured dashboards include:</p>
<ul>
<li><strong>RAG Stack Overview</strong>: Service health and performance</li>
<li><strong>Database Metrics</strong>: PostgreSQL performance monitoring</li>
<li><strong>System Resources</strong>: CPU, memory, and disk usage</li>
<li><strong>Request Analytics</strong>: API call patterns and response times</li>
</ul>
<h2 id="rag-stack-monitoring-dashboard"><a class="header" href="#rag-stack-monitoring-dashboard">RAG Stack Monitoring Dashboard</a></h2>
<p><img src="opensource-llm-rag-stack/../images/rag-dashboard.png" alt="RAG Stack Monitoring Dashboard" /></p>
<p>The dashboard provides real-time insights into:</p>
<ul>
<li><strong>Service Health Status</strong>: Live monitoring of all stack components</li>
<li><strong>Active Services Count</strong>: Overview of running services</li>
<li><strong>Request Rate Monitoring</strong>: API performance metrics</li>
<li><strong>Database Performance</strong>: PostgreSQL metrics and health</li>
</ul>
<h2 id="auto-provisioning"><a class="header" href="#auto-provisioning">Auto-Provisioning</a></h2>
<p>Grafana automatically configures:</p>
<pre><code class="language-yaml"># Datasources
datasources:
  - name: Prometheus
    type: prometheus
    url: http://prometheus:9090
    isDefault: true

# Dashboards auto-loaded from:
# monitoring/grafana/dashboards/
</code></pre>
<h2 id="production-deployment-1"><a class="header" href="#production-deployment-1">Production Deployment</a></h2>
<h3 id="environment-configuration"><a class="header" href="#environment-configuration">Environment Configuration</a></h3>
<pre><code class="language-bash"># Production environment variables
export POSTGRES_PASSWORD=secure_password
export GRAFANA_ADMIN_PASSWORD=secure_admin_password
export OLLAMA_API_BASE_URL=https://your-ollama-instance.com
</code></pre>
<h3 id="scaling-considerations"><a class="header" href="#scaling-considerations">Scaling Considerations</a></h3>
<ul>
<li><strong>Horizontal Scaling</strong>: Multiple Ollama instances behind load balancer</li>
<li><strong>Database Scaling</strong>: PostgreSQL read replicas for query performance</li>
<li><strong>Vector DB Scaling</strong>: Chroma clustering for high availability</li>
<li><strong>Monitoring</strong>: Prometheus federation for multi-instance monitoring</li>
</ul>
<h3 id="security-best-practices-1"><a class="header" href="#security-best-practices-1">Security Best Practices</a></h3>
<ul>
<li>Change default passwords in production</li>
<li>Use Docker secrets for sensitive data</li>
<li>Configure network security policies</li>
<li>Enable SSL/TLS for all services</li>
<li>Implement proper backup strategies</li>
</ul>
<h2 id="enterprise-features"><a class="header" href="#enterprise-features">Enterprise Features</a></h2>
<h3 id="devops-best-practices"><a class="header" href="#devops-best-practices">DevOps Best Practices</a></h3>
<ul>
<li><strong>Infrastructure as Code</strong>: Docker Compose for reproducible deployments</li>
<li><strong>Monitoring</strong>: Comprehensive observability with Prometheus and Grafana</li>
<li><strong>Data Management</strong>: Optimized PostgreSQL schema with full-text search</li>
<li><strong>Security</strong>: Network isolation and environment-based configuration</li>
<li><strong>Scalability</strong>: Microservices architecture for horizontal scaling</li>
</ul>
<h3 id="aiml-capabilities"><a class="header" href="#aiml-capabilities">AI/ML Capabilities</a></h3>
<ul>
<li><strong>Vector Search</strong>: Chroma for semantic similarity search</li>
<li><strong>Containerized LLM</strong>: Ollama in Docker for reproducible model inference</li>
<li><strong>RAG Pipeline</strong>: Complete retrieval-augmented generation workflow</li>
<li><strong>Document Processing</strong>: Automatic chunking and embedding generation</li>
<li><strong>Chat History</strong>: Persistent conversation management</li>
<li><strong>Model Management</strong>: Easy model switching and versioning with Docker volumes</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-technical-implementation"><a class="header" href="#opensource-llm-rag-stack-technical-implementation">Opensource-LLM-RAG-Stack Technical Implementation</a></h1>
<h2 id="docker-compose-architecture"><a class="header" href="#docker-compose-architecture">Docker Compose Architecture</a></h2>
<h3 id="service-configuration"><a class="header" href="#service-configuration">Service Configuration</a></h3>
<pre><code class="language-yaml">version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
    networks:
      - rag-network

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434
      - VECTOR_DB=chroma
      - DATABASE_URL=postgresql://user:password@postgres:5432/chatdb
      - CHROMA_SERVER_HOST=http://chroma:8000
    depends_on:
      - ollama
      - chroma
      - postgres
    networks:
      - rag-network

  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chroma
    ports:
      - "8000:8000"
    volumes:
      - chroma-data:/chroma/chroma
    environment:
      - CHROMA_DB_IMPL=duckdb+parquet
      - IS_PERSISTENT=TRUE
    networks:
      - rag-network

  postgres:
    image: postgres:15-alpine
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: chatdb
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - rag-network

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    networks:
      - rag-network

  grafana:
    image: grafana/grafana-oss:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - rag-network

volumes:
  ollama-data:
  openwebui-data:
  chroma-data:
  pgdata:
  grafana-data:
  prometheus-data:

networks:
  rag-network:
    driver: bridge
</code></pre>
<h2 id="database-schema-implementation"><a class="header" href="#database-schema-implementation">Database Schema Implementation</a></h2>
<h3 id="postgresql-schema"><a class="header" href="#postgresql-schema">PostgreSQL Schema</a></h3>
<pre><code class="language-sql">-- Enable UUID extension
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Chat Sessions Management
CREATE TABLE chat_sessions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id VARCHAR(255) NOT NULL,
    session_name VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Message Storage with Full-Text Search
CREATE TABLE chat_messages (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    session_id UUID REFERENCES chat_sessions(id) ON DELETE CASCADE,
    role VARCHAR(50) CHECK (role IN ('user', 'assistant', 'system')),
    content TEXT NOT NULL,
    token_count INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- RAG Document Storage
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    title VARCHAR(500),
    content TEXT NOT NULL,
    source VARCHAR(500),
    embedding_id VARCHAR(255), -- Chroma reference
    metadata JSONB DEFAULT '{}'::jsonb,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Performance Indexes
CREATE INDEX idx_chat_messages_session_id ON chat_messages(session_id);
CREATE INDEX idx_chat_messages_created_at ON chat_messages(created_at);
CREATE INDEX idx_documents_content_gin ON documents 
    USING gin(to_tsvector('english', content));
CREATE INDEX idx_documents_metadata_gin ON documents USING gin(metadata);

-- Full-text search function
CREATE OR REPLACE FUNCTION search_documents(search_query TEXT)
RETURNS TABLE(id UUID, title VARCHAR, content TEXT, rank REAL) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        d.id,
        d.title,
        d.content,
        ts_rank(to_tsvector('english', d.content), plainto_tsquery('english', search_query)) as rank
    FROM documents d
    WHERE to_tsvector('english', d.content) @@ plainto_tsquery('english', search_query)
    ORDER BY rank DESC
    LIMIT 10;
END;
$$ LANGUAGE plpgsql;
</code></pre>
<h2 id="rag-implementation-1"><a class="header" href="#rag-implementation-1">RAG Implementation</a></h2>
<h3 id="document-processing-pipeline"><a class="header" href="#document-processing-pipeline">Document Processing Pipeline</a></h3>
<pre><code class="language-python">import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import ollama

class RAGPipeline:
    def __init__(self):
        self.chroma_client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory="./chroma_db"
        ))
        self.collection = self.chroma_client.get_or_create_collection("documents")
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.ollama_client = ollama.Client(host='http://ollama:11434')
    
    def process_document(self, document_text, metadata=None):
        """Process and store document in vector database"""
        # Chunk document
        chunks = self.chunk_document(document_text, chunk_size=500, overlap=100)
        
        # Generate embeddings
        embeddings = self.embedding_model.encode(chunks)
        
        # Store in Chroma
        ids = [f"doc_{i}" for i in range(len(chunks))]
        self.collection.add(
            embeddings=embeddings.tolist(),
            documents=chunks,
            ids=ids,
            metadatas=[metadata] * len(chunks) if metadata else None
        )
        
        return len(chunks)
    
    def chunk_document(self, text, chunk_size=500, overlap=100):
        """Split document into overlapping chunks"""
        chunks = []
        words = text.split()
        
        for i in range(0, len(words), chunk_size - overlap):
            chunk = ' '.join(words[i:i + chunk_size])
            chunks.append(chunk)
        
        return chunks
    
    def retrieve_relevant_chunks(self, query, top_k=5):
        """Retrieve relevant document chunks for query"""
        # Generate query embedding
        query_embedding = self.embedding_model.encode([query])[0]
        
        # Search in Chroma
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=top_k
        )
        
        return results['documents'][0]
    
    def generate_response(self, query, context_chunks):
        """Generate response using RAG"""
        # Build context from retrieved chunks
        context = "\n\n".join(context_chunks)
        
        # Create augmented prompt
        prompt = f"""Context:
{context}

Question: {query}

Answer based on the context provided:"""
        
        # Generate response using Ollama
        response = self.ollama_client.generate(
            model='llama3.2:3b',
            prompt=prompt
        )
        
        return response['response']
</code></pre>
<h2 id="monitoring-implementation"><a class="header" href="#monitoring-implementation">Monitoring Implementation</a></h2>
<h3 id="prometheus-configuration"><a class="header" href="#prometheus-configuration">Prometheus Configuration</a></h3>
<pre><code class="language-yaml">global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'rag-stack'
    static_configs:
      - targets: ['open-webui:8080', 'chroma:8000', 'ollama:11434']
</code></pre>
<h3 id="custom-metrics-collection"><a class="header" href="#custom-metrics-collection">Custom Metrics Collection</a></h3>
<pre><code class="language-python">from prometheus_client import Counter, Histogram, Gauge
import time

# Define metrics
request_count = Counter('rag_requests_total', 'Total RAG requests')
request_duration = Histogram('rag_request_duration_seconds', 'RAG request duration')
active_sessions = Gauge('rag_active_sessions', 'Active chat sessions')
document_count = Gauge('rag_documents_total', 'Total documents in vector DB')

def track_rag_request(func):
    """Decorator to track RAG requests"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        request_count.inc()
        
        try:
            result = func(*args, **kwargs)
            request_duration.observe(time.time() - start_time)
            return result
        except Exception as e:
            request_count.labels(status='error').inc()
            raise
    
    return wrapper
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-security--best-practices"><a class="header" href="#opensource-llm-rag-stack-security--best-practices">Opensource-LLM-RAG-Stack Security &amp; Best Practices</a></h1>
<h2 id="container-security"><a class="header" href="#container-security">Container Security</a></h2>
<h3 id="image-security"><a class="header" href="#image-security">Image Security</a></h3>
<ul>
<li><strong>Official Images</strong>: Use official, maintained images</li>
<li><strong>Version Pinning</strong>: Pin specific image versions</li>
<li><strong>Regular Updates</strong>: Keep images updated</li>
<li><strong>Vulnerability Scanning</strong>: Scan images for vulnerabilities</li>
</ul>
<h3 id="network-security-1"><a class="header" href="#network-security-1">Network Security</a></h3>
<pre><code class="language-yaml">networks:
  rag-network:
    driver: bridge
    internal: false  # Set to true for isolated network

# Service-specific network configuration
services:
  postgres:
    networks:
      - rag-network
    # No external ports exposed
</code></pre>
<h2 id="data-security"><a class="header" href="#data-security">Data Security</a></h2>
<h3 id="database-security"><a class="header" href="#database-security">Database Security</a></h3>
<pre><code class="language-sql">-- Create read-only user
CREATE USER readonly_user WITH PASSWORD 'secure_password';
GRANT CONNECT ON DATABASE chatdb TO readonly_user;
GRANT USAGE ON SCHEMA public TO readonly_user;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly_user;

-- Encrypt sensitive data
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- Encrypt password column
ALTER TABLE users ADD COLUMN password_encrypted BYTEA;
</code></pre>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<pre><code class="language-yaml"># Use Docker secrets for sensitive data
services:
  postgres:
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
    secrets:
      - postgres_password

secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
</code></pre>
<h2 id="access-control"><a class="header" href="#access-control">Access Control</a></h2>
<h3 id="api-security"><a class="header" href="#api-security">API Security</a></h3>
<pre><code class="language-python">from functools import wraps
from flask import request, jsonify
import jwt

def require_auth(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        token = request.headers.get('Authorization')
        if not token:
            return jsonify({'error': 'No token provided'}), 401
        
        try:
            data = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])
        except:
            return jsonify({'error': 'Invalid token'}), 401
        
        return f(*args, **kwargs)
    return decorated_function
</code></pre>
<h3 id="rate-limiting"><a class="header" href="#rate-limiting">Rate Limiting</a></h3>
<pre><code class="language-python">from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app,
    key_func=get_remote_address,
    default_limits=["200 per day", "50 per hour"]
)

@app.route('/api/chat')
@limiter.limit("10 per minute")
@require_auth
def chat():
    # Chat endpoint with rate limiting
    pass
</code></pre>
<h2 id="security-best-practices-2"><a class="header" href="#security-best-practices-2">Security Best Practices</a></h2>
<h3 id="1-secrets-management"><a class="header" href="#1-secrets-management">1. <strong>Secrets Management</strong></a></h3>
<ul>
<li>Use Docker secrets or environment files</li>
<li>Never commit secrets to Git</li>
<li>Rotate secrets regularly</li>
<li>Use different secrets per environment</li>
</ul>
<h3 id="2-network-isolation"><a class="header" href="#2-network-isolation">2. <strong>Network Isolation</strong></a></h3>
<ul>
<li>Isolate services in Docker networks</li>
<li>Limit exposed ports</li>
<li>Use reverse proxy for external access</li>
<li>Implement firewall rules</li>
</ul>
<h3 id="3-data-encryption"><a class="header" href="#3-data-encryption">3. <strong>Data Encryption</strong></a></h3>
<ul>
<li>Encrypt data at rest (PostgreSQL)</li>
<li>Encrypt data in transit (TLS/SSL)</li>
<li>Encrypt sensitive fields in database</li>
<li>Use secure key management</li>
</ul>
<h3 id="4-access-control"><a class="header" href="#4-access-control">4. <strong>Access Control</strong></a></h3>
<ul>
<li>Implement authentication</li>
<li>Use role-based access control (RBAC)</li>
<li>Enforce least privilege principle</li>
<li>Audit access logs</li>
</ul>
<h3 id="5-vulnerability-management"><a class="header" href="#5-vulnerability-management">5. <strong>Vulnerability Management</strong></a></h3>
<ul>
<li>Regular security updates</li>
<li>Scan for vulnerabilities</li>
<li>Patch promptly</li>
<li>Monitor security advisories</li>
</ul>
<h2 id="production-security-checklist"><a class="header" href="#production-security-checklist">Production Security Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Change all default passwords</li>
<li><input disabled="" type="checkbox"/>
Enable TLS/SSL for all services</li>
<li><input disabled="" type="checkbox"/>
Configure firewall rules</li>
<li><input disabled="" type="checkbox"/>
Set up authentication</li>
<li><input disabled="" type="checkbox"/>
Enable audit logging</li>
<li><input disabled="" type="checkbox"/>
Configure backup encryption</li>
<li><input disabled="" type="checkbox"/>
Implement rate limiting</li>
<li><input disabled="" type="checkbox"/>
Set up intrusion detection</li>
<li><input disabled="" type="checkbox"/>
Regular security audits</li>
<li><input disabled="" type="checkbox"/>
Incident response plan</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-scaling--performance"><a class="header" href="#opensource-llm-rag-stack-scaling--performance">Opensource-LLM-RAG-Stack Scaling &amp; Performance</a></h1>
<h2 id="horizontal-scaling"><a class="header" href="#horizontal-scaling">Horizontal Scaling</a></h2>
<h3 id="load-balancing"><a class="header" href="#load-balancing">Load Balancing</a></h3>
<pre><code class="language-yaml"># Multiple Ollama instances behind load balancer
services:
  ollama-1:
    image: ollama/ollama:latest
    deploy:
      replicas: 3
  
  nginx:
    image: nginx:alpine
    ports:
      - "11434:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
</code></pre>
<h3 id="database-scaling"><a class="header" href="#database-scaling">Database Scaling</a></h3>
<pre><code class="language-yaml"># PostgreSQL with read replicas
services:
  postgres-primary:
    image: postgres:15-alpine
    environment:
      POSTGRES_REPLICATION_MODE: master
  
  postgres-replica:
    image: postgres:15-alpine
    environment:
      POSTGRES_REPLICATION_MODE: slave
    depends_on:
      - postgres-primary
</code></pre>
<h2 id="vector-database-scaling"><a class="header" href="#vector-database-scaling">Vector Database Scaling</a></h2>
<h3 id="chroma-clustering"><a class="header" href="#chroma-clustering">Chroma Clustering</a></h3>
<pre><code class="language-python"># Distributed Chroma setup
from chromadb.config import Settings

# Primary Chroma instance
primary_client = chromadb.Client(Settings(
    chroma_db_impl="duckdb+parquet",
    persist_directory="/chroma/primary"
))

# Replica instances for read scaling
replica_clients = [
    chromadb.Client(Settings(
        chroma_db_impl="duckdb+parquet",
        persist_directory=f"/chroma/replica-{i}"
    )) for i in range(3)
]
</code></pre>
<h2 id="performance-optimization-2"><a class="header" href="#performance-optimization-2">Performance Optimization</a></h2>
<h3 id="caching-strategy-1"><a class="header" href="#caching-strategy-1">Caching Strategy</a></h3>
<pre><code class="language-python">from functools import lru_cache
import redis

redis_client = redis.Redis(host='redis', port=6379, db=0)

@lru_cache(maxsize=1000)
def get_cached_embedding(text):
    """Cache embeddings to avoid recomputation"""
    cache_key = f"embedding:{hash(text)}"
    cached = redis_client.get(cache_key)
    
    if cached:
        return pickle.loads(cached)
    
    embedding = embedding_model.encode(text)
    redis_client.setex(cache_key, 3600, pickle.dumps(embedding))
    return embedding
</code></pre>
<h3 id="query-optimization"><a class="header" href="#query-optimization">Query Optimization</a></h3>
<pre><code class="language-python"># Optimize RAG retrieval
def optimized_retrieve(query, top_k=5, rerank=True):
    # Initial retrieval
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k * 2  # Retrieve more for reranking
    )
    
    if rerank:
        # Rerank using cross-encoder
        reranked = rerank_results(query, results)
        return reranked[:top_k]
    
    return results[:top_k]
</code></pre>
<h2 id="resource-management"><a class="header" href="#resource-management">Resource Management</a></h2>
<h3 id="resource-limits"><a class="header" href="#resource-limits">Resource Limits</a></h3>
<pre><code class="language-yaml">services:
  ollama:
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
  
  postgres:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
</code></pre>
<h3 id="auto-scaling"><a class="header" href="#auto-scaling">Auto-Scaling</a></h3>
<pre><code class="language-yaml"># Docker Swarm auto-scaling
services:
  open-webui:
    deploy:
      replicas: 2
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
</code></pre>
<h2 id="monitoring-scaling-metrics"><a class="header" href="#monitoring-scaling-metrics">Monitoring Scaling Metrics</a></h2>
<h3 id="key-metrics-1"><a class="header" href="#key-metrics-1">Key Metrics</a></h3>
<ul>
<li><strong>Request Rate</strong>: Requests per second</li>
<li><strong>Response Time</strong>: P50, P95, P99 latencies</li>
<li><strong>Error Rate</strong>: Percentage of failed requests</li>
<li><strong>Resource Usage</strong>: CPU, memory, disk</li>
<li><strong>Database Connections</strong>: Active connections</li>
<li><strong>Vector DB Size</strong>: Number of documents</li>
</ul>
<h3 id="scaling-triggers"><a class="header" href="#scaling-triggers">Scaling Triggers</a></h3>
<pre><code class="language-yaml"># Auto-scaling based on metrics
scaling:
  triggers:
    - metric: cpu_usage
      threshold: 70
      action: scale_up
    - metric: memory_usage
      threshold: 80
      action: scale_up
    - metric: request_latency
      threshold: 1000ms
      action: scale_up
</code></pre>
<h2 id="cost-optimization"><a class="header" href="#cost-optimization">Cost Optimization</a></h2>
<h3 id="resource-right-sizing"><a class="header" href="#resource-right-sizing">Resource Right-Sizing</a></h3>
<ul>
<li><strong>Ollama</strong>: Adjust based on model size</li>
<li><strong>PostgreSQL</strong>: Optimize connection pool</li>
<li><strong>Chroma</strong>: Tune index parameters</li>
<li><strong>Monitoring</strong>: Use efficient exporters</li>
</ul>
<h3 id="caching-strategy-2"><a class="header" href="#caching-strategy-2">Caching Strategy</a></h3>
<ul>
<li><strong>Embedding Cache</strong>: Cache computed embeddings</li>
<li><strong>Query Cache</strong>: Cache frequent queries</li>
<li><strong>Response Cache</strong>: Cache LLM responses</li>
<li><strong>CDN</strong>: Use CDN for static assets</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-troubleshooting"><a class="header" href="#opensource-llm-rag-stack-troubleshooting">Opensource-LLM-RAG-Stack Troubleshooting</a></h1>
<h2 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h2>
<h3 id="ollama-not-starting"><a class="header" href="#ollama-not-starting">Ollama Not Starting</a></h3>
<pre><code class="language-bash"># Check Ollama logs
docker logs ollama

# Verify Ollama is running
curl http://localhost:11434/api/tags

# Restart Ollama
docker restart ollama

# Check available models
docker exec -it ollama ollama list
</code></pre>
<p><strong>Solutions:</strong></p>
<ul>
<li>Ensure sufficient memory (8GB+ recommended)</li>
<li>Check disk space for model storage</li>
<li>Verify network connectivity</li>
<li>Review Ollama logs for errors</li>
</ul>
<h3 id="chroma-connection-issues"><a class="header" href="#chroma-connection-issues">Chroma Connection Issues</a></h3>
<pre><code class="language-bash"># Check Chroma health
curl http://localhost:8000/api/v2/heartbeat

# Verify Chroma collections
curl http://localhost:8000/api/v2/tenants/default/databases/default/collections

# Check Chroma logs
docker logs chroma
</code></pre>
<p><strong>Solutions:</strong></p>
<ul>
<li>Verify Chroma container is running</li>
<li>Check network connectivity</li>
<li>Ensure proper volume mounts</li>
<li>Review Chroma configuration</li>
</ul>
<h3 id="postgresql-connection-errors"><a class="header" href="#postgresql-connection-errors">PostgreSQL Connection Errors</a></h3>
<pre><code class="language-bash"># Check PostgreSQL status
docker exec -it postgres pg_isready

# Test connection
docker exec -it postgres psql -U user -d chatdb -c "SELECT version();"

# Check PostgreSQL logs
docker logs postgres
</code></pre>
<p><strong>Solutions:</strong></p>
<ul>
<li>Verify database credentials</li>
<li>Check connection string format</li>
<li>Ensure database is initialized</li>
<li>Review PostgreSQL logs</li>
</ul>
<h3 id="rag-not-working"><a class="header" href="#rag-not-working">RAG Not Working</a></h3>
<pre><code class="language-bash"># Test document upload
curl -X POST http://localhost:3000/api/documents \
  -H "Content-Type: application/json" \
  -d '{"title": "Test", "content": "Test content"}'

# Verify embeddings
curl http://localhost:8000/api/v2/collections

# Test query
curl -X POST http://localhost:3000/api/query \
  -H "Content-Type: application/json" \
  -d '{"query": "test query"}'
</code></pre>
<p><strong>Solutions:</strong></p>
<ul>
<li>Verify document processing pipeline</li>
<li>Check embedding generation</li>
<li>Ensure Chroma has documents</li>
<li>Review RAG implementation logs</li>
</ul>
<h2 id="performance-issues"><a class="header" href="#performance-issues">Performance Issues</a></h2>
<h3 id="slow-query-response"><a class="header" href="#slow-query-response">Slow Query Response</a></h3>
<pre><code class="language-bash"># Check service response times
time curl http://localhost:3000/api/health

# Monitor resource usage
docker stats

# Check database performance
docker exec -it postgres psql -U user -d chatdb -c "EXPLAIN ANALYZE SELECT * FROM documents;"
</code></pre>
<p><strong>Solutions:</strong></p>
<ul>
<li>Optimize database queries</li>
<li>Add appropriate indexes</li>
<li>Increase resource allocation</li>
<li>Implement caching</li>
</ul>
<h3 id="high-memory-usage"><a class="header" href="#high-memory-usage">High Memory Usage</a></h3>
<pre><code class="language-bash"># Check memory usage
docker stats --no-stream

# Check Ollama memory
docker exec -it ollama ollama ps

# Monitor memory per service
docker stats ollama postgres chroma
</code></pre>
<p><strong>Solutions:</strong></p>
<ul>
<li>Reduce model size</li>
<li>Limit concurrent requests</li>
<li>Optimize batch sizes</li>
<li>Add memory limits</li>
</ul>
<h2 id="debugging-commands"><a class="header" href="#debugging-commands">Debugging Commands</a></h2>
<h3 id="service-health-checks"><a class="header" href="#service-health-checks">Service Health Checks</a></h3>
<pre><code class="language-bash"># Check all services
docker-compose ps

# Check service logs
docker-compose logs [service-name]

# Follow logs
docker-compose logs -f [service-name]

# Restart service
docker-compose restart [service-name]
</code></pre>
<h3 id="database-debugging"><a class="header" href="#database-debugging">Database Debugging</a></h3>
<pre><code class="language-bash"># Connect to PostgreSQL
docker exec -it postgres psql -U user -d chatdb

# Check table sizes
SELECT pg_size_pretty(pg_total_relation_size('documents'));

# Check active connections
SELECT count(*) FROM pg_stat_activity;

# Analyze query performance
EXPLAIN ANALYZE SELECT * FROM documents WHERE content LIKE '%test%';
</code></pre>
<h3 id="vector-db-debugging"><a class="header" href="#vector-db-debugging">Vector DB Debugging</a></h3>
<pre><code class="language-bash"># Check Chroma collections
curl http://localhost:8000/api/v2/collections | jq

# Get collection stats
curl http://localhost:8000/api/v2/collections/{collection_id} | jq

# Query test
curl -X POST http://localhost:8000/api/v2/collections/{collection_id}/query \
  -H "Content-Type: application/json" \
  -d '{"query_texts": ["test"], "n_results": 5}'
</code></pre>
<h2 id="recovery-procedures"><a class="header" href="#recovery-procedures">Recovery Procedures</a></h2>
<h3 id="data-backup"><a class="header" href="#data-backup">Data Backup</a></h3>
<pre><code class="language-bash"># Backup PostgreSQL
docker exec postgres pg_dump -U user chatdb &gt; backup.sql

# Backup Chroma data
docker exec chroma tar -czf /tmp/chroma-backup.tar.gz /chroma/chroma

# Backup volumes
docker run --rm -v rag-stack_pgdata:/data -v $(pwd):/backup \
  alpine tar -czf /backup/pgdata-backup.tar.gz /data
</code></pre>
<h3 id="data-restore"><a class="header" href="#data-restore">Data Restore</a></h3>
<pre><code class="language-bash"># Restore PostgreSQL
docker exec -i postgres psql -U user chatdb &lt; backup.sql

# Restore Chroma
docker exec chroma tar -xzf /tmp/chroma-backup.tar.gz -C /

# Restore volumes
docker run --rm -v rag-stack_pgdata:/data -v $(pwd):/backup \
  alpine tar -xzf /backup/pgdata-backup.tar.gz -C /
</code></pre>
<h2 id="monitoring--logging"><a class="header" href="#monitoring--logging">Monitoring &amp; Logging</a></h2>
<h3 id="view-all-logs"><a class="header" href="#view-all-logs">View All Logs</a></h3>
<pre><code class="language-bash"># All services
docker-compose logs

# Specific service
docker-compose logs ollama

# Last 100 lines
docker-compose logs --tail=100

# Follow logs
docker-compose logs -f
</code></pre>
<h3 id="check-metrics"><a class="header" href="#check-metrics">Check Metrics</a></h3>
<pre><code class="language-bash"># Prometheus metrics
curl http://localhost:9090/api/v1/query?query=up

# Grafana dashboards
open http://localhost:3001

# Service health
curl http://localhost:3000/health
curl http://localhost:8000/api/v2/heartbeat
curl http://localhost:11434/api/tags
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opensource-llm-rag-stack-technical-qa"><a class="header" href="#opensource-llm-rag-stack-technical-qa">Opensource-LLM-RAG-Stack Technical Q&amp;A</a></h1>
<h2 id="architecture--design-questions-2"><a class="header" href="#architecture--design-questions-2">Architecture &amp; Design Questions</a></h2>
<h3 id="q1-walk-me-through-the-rag-stack-architecture"><a class="header" href="#q1-walk-me-through-the-rag-stack-architecture">Q1: "Walk me through the RAG stack architecture."</a></h3>
<p><strong>Answer:</strong>
"The RAG stack is a containerized microservices architecture:</p>
<ul>
<li><strong>Open WebUI</strong>: User interface for chat and document management</li>
<li><strong>Ollama</strong>: LLM inference engine for text generation</li>
<li><strong>Chroma</strong>: Vector database for semantic search</li>
<li><strong>PostgreSQL</strong>: Relational database for chat history</li>
<li><strong>Prometheus</strong>: Metrics collection</li>
<li><strong>Grafana</strong>: Visualization and dashboards</li>
</ul>
<p>The architecture enables retrieval-augmented generation by combining vector search with LLM inference."</p>
<h3 id="q2-why-did-you-choose-chroma-over-other-vector-databases"><a class="header" href="#q2-why-did-you-choose-chroma-over-other-vector-databases">Q2: "Why did you choose Chroma over other vector databases?"</a></h3>
<p><strong>Answer:</strong>
"Chroma was chosen for several reasons:</p>
<ol>
<li><strong>Simplicity</strong>: Easy to set up and use</li>
<li><strong>Open Source</strong>: Free and community-driven</li>
<li><strong>Docker Support</strong>: Containerized deployment</li>
<li><strong>Performance</strong>: Efficient for small to medium datasets</li>
<li><strong>Integration</strong>: Works well with Python ecosystem</li>
</ol>
<p>For this use case, Chroma provides the right balance of features and simplicity."</p>
<h3 id="q3-how-does-the-rag-pipeline-work"><a class="header" href="#q3-how-does-the-rag-pipeline-work">Q3: "How does the RAG pipeline work?"</a></h3>
<p><strong>Answer:</strong>
"RAG pipeline steps:</p>
<ol>
<li><strong>Document Ingestion</strong>: Upload and chunk documents</li>
<li><strong>Embedding Generation</strong>: Create vector embeddings</li>
<li><strong>Vector Storage</strong>: Store in Chroma database</li>
<li><strong>Query Processing</strong>: Convert user query to embedding</li>
<li><strong>Retrieval</strong>: Find relevant document chunks</li>
<li><strong>Context Augmentation</strong>: Add chunks to prompt</li>
<li><strong>Generation</strong>: LLM generates response with context</li>
</ol>
<p>This enables the LLM to answer questions based on uploaded documents."</p>
<h2 id="technical-implementation-questions-1"><a class="header" href="#technical-implementation-questions-1">Technical Implementation Questions</a></h2>
<h3 id="q4-how-do-you-handle-document-chunking"><a class="header" href="#q4-how-do-you-handle-document-chunking">Q4: "How do you handle document chunking?"</a></h3>
<p><strong>Answer:</strong>
"Document chunking strategy:</p>
<ol>
<li><strong>Size</strong>: 500-1000 tokens per chunk</li>
<li><strong>Overlap</strong>: 100-200 tokens between chunks</li>
<li><strong>Boundaries</strong>: Preserve sentence/paragraph boundaries</li>
<li><strong>Metadata</strong>: Store source and position metadata</li>
<li><strong>Indexing</strong>: Create full-text search indexes</li>
</ol>
<p>This ensures relevant context is retrieved while maintaining coherence."</p>
<h3 id="q5-how-would-you-scale-this-to-handle-more-documents"><a class="header" href="#q5-how-would-you-scale-this-to-handle-more-documents">Q5: "How would you scale this to handle more documents?"</a></h3>
<p><strong>Answer:</strong>
"Scaling strategies:</p>
<ol>
<li><strong>Horizontal Scaling</strong>: Multiple Chroma instances</li>
<li><strong>Sharding</strong>: Partition documents by category</li>
<li><strong>Caching</strong>: Cache frequent queries</li>
<li><strong>Indexing</strong>: Optimize vector indexes</li>
<li><strong>Load Balancing</strong>: Distribute queries across instances</li>
<li><strong>Database Optimization</strong>: PostgreSQL read replicas</li>
</ol>
<p>The architecture supports horizontal scaling for increased capacity."</p>
<h2 id="performance-questions-1"><a class="header" href="#performance-questions-1">Performance Questions</a></h2>
<h3 id="q6-how-do-you-optimize-rag-performance"><a class="header" href="#q6-how-do-you-optimize-rag-performance">Q6: "How do you optimize RAG performance?"</a></h3>
<p><strong>Answer:</strong>
"Performance optimizations:</p>
<ol>
<li><strong>Embedding Cache</strong>: Cache computed embeddings</li>
<li><strong>Query Optimization</strong>: Efficient vector search</li>
<li><strong>Reranking</strong>: Use cross-encoder for better results</li>
<li><strong>Batch Processing</strong>: Process documents in batches</li>
<li><strong>Connection Pooling</strong>: Optimize database connections</li>
<li><strong>Caching</strong>: Cache frequent queries and responses</li>
</ol>
<p>These optimizations reduce latency and improve user experience."</p>
<h3 id="q7-what-are-the-bottlenecks-in-your-rag-system"><a class="header" href="#q7-what-are-the-bottlenecks-in-your-rag-system">Q7: "What are the bottlenecks in your RAG system?"</a></h3>
<p><strong>Answer:</strong>
"Potential bottlenecks:</p>
<ol>
<li><strong>Embedding Generation</strong>: Can be slow for large documents</li>
<li><strong>Vector Search</strong>: Query time increases with database size</li>
<li><strong>LLM Inference</strong>: Model generation time</li>
<li><strong>Database Queries</strong>: PostgreSQL query performance</li>
<li><strong>Network Latency</strong>: Inter-service communication</li>
</ol>
<p>Mitigation strategies include caching, optimization, and scaling."</p>
<h2 id="monitoring-questions-1"><a class="header" href="#monitoring-questions-1">Monitoring Questions</a></h2>
<h3 id="q8-how-do-you-monitor-the-rag-stack"><a class="header" href="#q8-how-do-you-monitor-the-rag-stack">Q8: "How do you monitor the RAG stack?"</a></h3>
<p><strong>Answer:</strong>
"Comprehensive monitoring:</p>
<ol>
<li><strong>Prometheus</strong>: Collect metrics from all services</li>
<li><strong>Grafana</strong>: Visualize metrics and create dashboards</li>
<li><strong>Logs</strong>: Centralized logging for all services</li>
<li><strong>Health Checks</strong>: Service availability monitoring</li>
<li><strong>Custom Metrics</strong>: Track RAG-specific metrics</li>
</ol>
<p>Key metrics include request rate, latency, error rate, and resource usage."</p>
<h3 id="q9-what-metrics-do-you-track"><a class="header" href="#q9-what-metrics-do-you-track">Q9: "What metrics do you track?"</a></h3>
<p><strong>Answer:</strong>
"Key metrics:</p>
<ol>
<li><strong>Request Metrics</strong>: Total requests, success rate</li>
<li><strong>Latency</strong>: P50, P95, P99 response times</li>
<li><strong>Error Rate</strong>: Percentage of failed requests</li>
<li><strong>Resource Usage</strong>: CPU, memory, disk per service</li>
<li><strong>Database Metrics</strong>: Query performance, connections</li>
<li><strong>Vector DB</strong>: Document count, query performance</li>
<li><strong>LLM Metrics</strong>: Token usage, generation time</li>
</ol>
<p>These metrics provide visibility into system health and performance."</p>
<h2 id="security-questions"><a class="header" href="#security-questions">Security Questions</a></h2>
<h3 id="q10-how-do-you-secure-the-rag-stack"><a class="header" href="#q10-how-do-you-secure-the-rag-stack">Q10: "How do you secure the RAG stack?"</a></h3>
<p><strong>Answer:</strong>
"Security measures:</p>
<ol>
<li><strong>Network Isolation</strong>: Docker networks for service isolation</li>
<li><strong>Authentication</strong>: User authentication for API access</li>
<li><strong>Encryption</strong>: Data encryption at rest and in transit</li>
<li><strong>Secrets Management</strong>: Secure handling of credentials</li>
<li><strong>Access Control</strong>: Role-based access control</li>
<li><strong>Audit Logging</strong>: Track all access and changes</li>
</ol>
<p>Security is implemented at multiple layers for defense in depth."</p>
<h3 id="q11-how-do-you-handle-sensitive-documents"><a class="header" href="#q11-how-do-you-handle-sensitive-documents">Q11: "How do you handle sensitive documents?"</a></h3>
<p><strong>Answer:</strong>
"Sensitive document handling:</p>
<ol>
<li><strong>Access Control</strong>: Restrict document access by user/role</li>
<li><strong>Encryption</strong>: Encrypt sensitive documents</li>
<li><strong>Audit Trail</strong>: Log all document access</li>
<li><strong>Data Retention</strong>: Implement retention policies</li>
<li><strong>Compliance</strong>: Follow data protection regulations</li>
<li><strong>Secure Deletion</strong>: Properly delete sensitive data</li>
</ol>
<p>Multiple safeguards protect sensitive information."</p>
<h2 id="advanced-questions-2"><a class="header" href="#advanced-questions-2">Advanced Questions</a></h2>
<h3 id="q12-how-would-you-improve-the-rag-system"><a class="header" href="#q12-how-would-you-improve-the-rag-system">Q12: "How would you improve the RAG system?"</a></h3>
<p><strong>Answer:</strong>
"Improvement strategies:</p>
<ol>
<li><strong>Better Embeddings</strong>: Use larger embedding models</li>
<li><strong>Reranking</strong>: Implement cross-encoder reranking</li>
<li><strong>Hybrid Search</strong>: Combine vector and keyword search</li>
<li><strong>Query Expansion</strong>: Expand queries for better retrieval</li>
<li><strong>Fine-tuning</strong>: Fine-tune LLM for domain-specific tasks</li>
<li><strong>Evaluation</strong>: Implement RAG evaluation metrics</li>
<li><strong>A/B Testing</strong>: Test different configurations</li>
</ol>
<p>Continuous improvement based on user feedback and metrics."</p>
<h3 id="q13-how-do-you-handle-large-document-uploads"><a class="header" href="#q13-how-do-you-handle-large-document-uploads">Q13: "How do you handle large document uploads?"</a></h3>
<p><strong>Answer:</strong>
"Large document handling:</p>
<ol>
<li><strong>Chunking</strong>: Split large documents into smaller chunks</li>
<li><strong>Streaming</strong>: Stream document processing</li>
<li><strong>Async Processing</strong>: Process documents asynchronously</li>
<li><strong>Progress Tracking</strong>: Show upload progress</li>
<li><strong>Error Handling</strong>: Handle upload failures gracefully</li>
<li><strong>Size Limits</strong>: Set reasonable size limits</li>
</ol>
<p>Would implement chunked uploads for files &gt; 10MB."</p>
<h3 id="q14-what-happens-if-chroma-database-becomes-unavailable"><a class="header" href="#q14-what-happens-if-chroma-database-becomes-unavailable">Q14: "What happens if Chroma database becomes unavailable?"</a></h3>
<p><strong>Answer:</strong>
"Chroma availability strategy:</p>
<ol>
<li><strong>Health Checks</strong>: Monitor Chroma health</li>
<li><strong>Backup</strong>: Regular backups of vector database</li>
<li><strong>Replication</strong>: Consider Chroma replication</li>
<li><strong>Fallback</strong>: Graceful degradation if unavailable</li>
<li><strong>Recovery</strong>: Automated recovery procedures</li>
<li><strong>Monitoring</strong>: Alert on service unavailability</li>
</ol>
<p>Would implement health checks and automated recovery."</p>
<h3 id="q15-how-do-you-optimize-llm-token-usage-and-costs"><a class="header" href="#q15-how-do-you-optimize-llm-token-usage-and-costs">Q15: "How do you optimize LLM token usage and costs?"</a></h3>
<p><strong>Answer:</strong>
"Token optimization:</p>
<ol>
<li><strong>Context Window</strong>: Limit context window size</li>
<li><strong>Chunk Selection</strong>: Retrieve only relevant chunks</li>
<li><strong>Prompt Optimization</strong>: Minimize prompt size</li>
<li><strong>Caching</strong>: Cache common queries and responses</li>
<li><strong>Model Selection</strong>: Use appropriate model size</li>
<li><strong>Batch Processing</strong>: Batch similar queries</li>
</ol>
<p>These strategies reduce token usage and associated costs."</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-1"><a class="header" href="#kubernetes-gitops-platform-1">Kubernetes GitOps Platform</a></h1>
<p>A production-ready AWS EKS cluster with complete GitOps platform toolkit, automated deployment, monitoring, and observability.</p>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>The Kubernetes GitOps Platform is a comprehensive infrastructure and platform solution that combines two repositories:</p>
<ul>
<li><strong>k8s-infrastructure-as-code</strong>: Complete AWS EKS infrastructure provisioning with Terraform</li>
<li><strong>k8s-platform-toolkit</strong>: Platform services including monitoring, logging, testing, and demo applications</li>
</ul>
<p>This project demonstrates enterprise-grade Kubernetes platform operations, GitOps automation, and SRE best practices.</p>
<p><img src="kubernetes-gitops-platform/../images/architecture.png" alt="Architecture Diagram" /></p>
<h2 id="key-features-3"><a class="header" href="#key-features-3">Key Features</a></h2>
<ul>
<li><strong>Complete Infrastructure as Code</strong>: Provision entire AWS EKS cluster and all platform services with a single command</li>
<li><strong>GitOps Automation</strong>: ArgoCD automatically deploys and manages all platform applications from Git repositories</li>
<li><strong>Production-Ready Platform</strong>: Comprehensive observability stack with monitoring, logging, and testing tools</li>
<li><strong>High Availability</strong>: Multi-AZ deployment with auto-scaling worker nodes and Horizontal Pod Autoscaler (HPA)</li>
<li><strong>Zero-Downtime Deployments</strong>: Kubernetes rolling updates ensure continuous service availability</li>
<li><strong>Complete Observability</strong>: Prometheus, Grafana, Loki, and Promtail for metrics, logs, and dashboards</li>
<li><strong>Performance Testing</strong>: k6 integration for smoke, load, stress, and spike testing with Prometheus metrics</li>
<li><strong>SRE-Ready</strong>: Availability testing, sanity checks, and performance validation built-in</li>
</ul>
<h2 id="project-highlights-3"><a class="header" href="#project-highlights-3">Project Highlights</a></h2>
<p>This project demonstrates:</p>
<ul>
<li>Modern Kubernetes platform operations</li>
<li>GitOps with ArgoCD app-of-apps pattern</li>
<li>Infrastructure as Code with Terraform</li>
<li>Comprehensive observability and monitoring</li>
<li>SRE best practices and testing</li>
<li>High availability and auto-scaling</li>
<li>Production-ready deployment patterns</li>
</ul>
<h2 id="repository-structure-1"><a class="header" href="#repository-structure-1">Repository Structure</a></h2>
<h3 id="infrastructure-repository-k8s-infrastructure-as-code"><a class="header" href="#infrastructure-repository-k8s-infrastructure-as-code">Infrastructure Repository (<code>k8s-infrastructure-as-code</code>)</a></h3>
<ul>
<li>Terraform configurations for AWS EKS</li>
<li>VPC, networking, and security groups</li>
<li>IAM roles and policies</li>
<li>ArgoCD installation</li>
<li>Helm charts for applications</li>
<li>Makefile automation</li>
</ul>
<h3 id="platform-toolkit-repository-k8s-platform-toolkit"><a class="header" href="#platform-toolkit-repository-k8s-platform-toolkit">Platform Toolkit Repository (<code>k8s-platform-toolkit</code>)</a></h3>
<ul>
<li>Monitoring stack (Prometheus, Grafana)</li>
<li>Logging stack (Loki, Promtail)</li>
<li>Testing applications (Sanity Test, Availability Test)</li>
<li>Demo microservices (Online Boutique)</li>
<li>Chaos engineering experiments</li>
<li>ArgoCD application definitions</li>
</ul>
<h2 id="technology-stack-1"><a class="header" href="#technology-stack-1">Technology Stack</a></h2>
<ul>
<li><strong>Infrastructure</strong>: Terraform, AWS EKS, VPC, IAM</li>
<li><strong>Container Orchestration</strong>: Kubernetes</li>
<li><strong>GitOps</strong>: ArgoCD</li>
<li><strong>Monitoring</strong>: Prometheus, Grafana, kube-state-metrics, node-exporter</li>
<li><strong>Logging</strong>: Loki, Promtail</li>
<li><strong>Package Management</strong>: Helm</li>
<li><strong>Automation</strong>: Makefile, Docker</li>
<li><strong>Testing</strong>: Custom Python applications, Locust</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-architecture"><a class="header" href="#kubernetes-gitops-platform-architecture">Kubernetes GitOps Platform Architecture</a></h1>
<h2 id="system-architecture-3"><a class="header" href="#system-architecture-3">System Architecture</a></h2>
<p><img src="kubernetes-gitops-platform/../images/architecture.png" alt="Architecture Diagram" /></p>
<p>The Kubernetes GitOps Platform follows a two-repository architecture pattern:</p>
<h3 id="infrastructure-layer-k8s-infrastructure-as-code"><a class="header" href="#infrastructure-layer-k8s-infrastructure-as-code">Infrastructure Layer (k8s-infrastructure-as-code)</a></h3>
<p><strong>Components:</strong></p>
<ul>
<li><strong>AWS VPC</strong>: Multi-AZ network with public and private subnets</li>
<li><strong>EKS Cluster</strong>: Managed Kubernetes control plane</li>
<li><strong>Worker Nodes</strong>: Auto-scaling node groups in private subnets</li>
<li><strong>Application Load Balancer</strong>: External access to services</li>
<li><strong>Security Groups</strong>: Network security and access control</li>
<li><strong>IAM Roles</strong>: Service accounts and permissions</li>
</ul>
<h3 id="platform-services-layer-k8s-platform-toolkit"><a class="header" href="#platform-services-layer-k8s-platform-toolkit">Platform Services Layer (k8s-platform-toolkit)</a></h3>
<p><strong>Components:</strong></p>
<ul>
<li><strong>ArgoCD</strong>: GitOps continuous delivery</li>
<li><strong>Monitoring Stack</strong>: Prometheus, Grafana, kube-state-metrics, node-exporter</li>
<li><strong>Logging Stack</strong>: Loki, Promtail</li>
<li><strong>Testing Tools</strong>: Sanity Test, Availability Test</li>
<li><strong>Demo Applications</strong>: Online Boutique microservices</li>
<li><strong>Chaos Engineering</strong>: Resilience testing tools</li>
</ul>
<h2 id="gitops-workflow"><a class="header" href="#gitops-workflow">GitOps Workflow</a></h2>
<p><img src="kubernetes-gitops-platform/../images/eks-gitops.png" alt="EKS GitOps Workflow" /></p>
<h3 id="workflow-steps"><a class="header" href="#workflow-steps">Workflow Steps</a></h3>
<ol>
<li>
<p><strong>Infrastructure Deployment</strong></p>
<ul>
<li>Terraform provisions AWS EKS cluster</li>
<li>ArgoCD is installed via Helm</li>
<li>App-of-apps pattern is configured</li>
</ul>
</li>
<li>
<p><strong>Platform Toolkit Deployment</strong></p>
<ul>
<li>ArgoCD references k8s-platform-toolkit repository</li>
<li>App-of-apps pattern deploys all platform applications</li>
<li>Applications sync automatically from Git</li>
</ul>
</li>
<li>
<p><strong>Continuous Deployment</strong></p>
<ul>
<li>Changes pushed to Git repositories</li>
<li>ArgoCD detects changes automatically</li>
<li>Applications sync with zero-downtime rolling updates</li>
</ul>
</li>
</ol>
<h2 id="app-of-apps-pattern"><a class="header" href="#app-of-apps-pattern">App-of-Apps Pattern</a></h2>
<p>The platform uses ArgoCD's app-of-apps pattern for hierarchical application management:</p>
<pre><code>k8s-platform-toolkit (Root App)
‚îú‚îÄ‚îÄ monitoring-stack
‚îÇ   ‚îú‚îÄ‚îÄ Prometheus
‚îÇ   ‚îú‚îÄ‚îÄ Grafana
‚îÇ   ‚îú‚îÄ‚îÄ kube-state-metrics
‚îÇ   ‚îî‚îÄ‚îÄ node-exporter
‚îú‚îÄ‚îÄ loki-stack
‚îÇ   ‚îî‚îÄ‚îÄ Loki
‚îú‚îÄ‚îÄ promtail
‚îú‚îÄ‚îÄ online-boutique
‚îÇ   ‚îî‚îÄ‚îÄ 11 microservices
‚îú‚îÄ‚îÄ sanity-test
‚îî‚îÄ‚îÄ availability-test
</code></pre>
<h3 id="sync-waves"><a class="header" href="#sync-waves">Sync Waves</a></h3>
<p>Applications deploy in ordered waves:</p>
<ul>
<li><strong>Wave 1</strong>: Testing infrastructure (Sanity Test, Availability Test)</li>
<li><strong>Wave 2-4</strong>: Monitoring stack components</li>
<li><strong>Wave 5</strong>: Promtail (depends on Loki)</li>
<li><strong>Wave 99</strong>: Chaos experiments (manual sync)</li>
</ul>
<h2 id="network-architecture"><a class="header" href="#network-architecture">Network Architecture</a></h2>
<h3 id="vpc-structure"><a class="header" href="#vpc-structure">VPC Structure</a></h3>
<ul>
<li><strong>Public Subnets</strong>: Internet Gateway access, NAT Gateway</li>
<li><strong>Private Subnets</strong>: Worker nodes, internal services</li>
<li><strong>Multi-AZ</strong>: High availability across availability zones</li>
<li><strong>Security Groups</strong>: Network-level access control</li>
</ul>
<h3 id="service-access"><a class="header" href="#service-access">Service Access</a></h3>
<ul>
<li><strong>LoadBalancer Services</strong>: External access via AWS ALB</li>
<li><strong>ClusterIP Services</strong>: Internal cluster communication</li>
<li><strong>Ingress</strong>: Optional ingress controller for HTTP routing</li>
</ul>
<h2 id="high-availability-design"><a class="header" href="#high-availability-design">High Availability Design</a></h2>
<h3 id="cluster-level"><a class="header" href="#cluster-level">Cluster Level</a></h3>
<ul>
<li><strong>Multi-AZ Deployment</strong>: Control plane and nodes across zones</li>
<li><strong>Auto Scaling Groups</strong>: Worker node auto-scaling</li>
<li><strong>Health Checks</strong>: Node and pod health monitoring</li>
</ul>
<h3 id="application-level"><a class="header" href="#application-level">Application Level</a></h3>
<ul>
<li><strong>Replica Sets</strong>: Multiple pod instances</li>
<li><strong>Horizontal Pod Autoscaler</strong>: Automatic pod scaling</li>
<li><strong>Rolling Updates</strong>: Zero-downtime deployments</li>
<li><strong>Readiness Probes</strong>: Health check validation</li>
</ul>
<h2 id="data-flow-3"><a class="header" href="#data-flow-3">Data Flow</a></h2>
<h3 id="metrics-flow"><a class="header" href="#metrics-flow">Metrics Flow</a></h3>
<pre><code>Pods ‚Üí Prometheus ‚Üí Grafana ‚Üí Dashboards
Nodes ‚Üí node-exporter ‚Üí Prometheus
K8s Objects ‚Üí kube-state-metrics ‚Üí Prometheus
</code></pre>
<h3 id="logs-flow"><a class="header" href="#logs-flow">Logs Flow</a></h3>
<pre><code>Pods ‚Üí Promtail ‚Üí Loki ‚Üí Grafana
</code></pre>
<h3 id="gitops-flow"><a class="header" href="#gitops-flow">GitOps Flow</a></h3>
<pre><code>Git Repository ‚Üí ArgoCD ‚Üí Kubernetes API ‚Üí Pods
</code></pre>
<h2 id="security-architecture"><a class="header" href="#security-architecture">Security Architecture</a></h2>
<h3 id="network-security-2"><a class="header" href="#network-security-2">Network Security</a></h3>
<ul>
<li><strong>Private Subnets</strong>: Worker nodes isolated from internet</li>
<li><strong>Security Groups</strong>: Restrictive network policies</li>
<li><strong>VPC Flow Logs</strong>: Network traffic monitoring</li>
</ul>
<h3 id="access-control-1"><a class="header" href="#access-control-1">Access Control</a></h3>
<ul>
<li><strong>IAM Roles</strong>: AWS resource access</li>
<li><strong>RBAC</strong>: Kubernetes role-based access</li>
<li><strong>Service Accounts</strong>: Pod-level permissions</li>
</ul>
<h3 id="secrets-management-1"><a class="header" href="#secrets-management-1">Secrets Management</a></h3>
<ul>
<li><strong>Kubernetes Secrets</strong>: Application secrets</li>
<li><strong>AWS Secrets Manager</strong>: Integration capability</li>
<li><strong>ArgoCD Secrets</strong>: Git repository credentials</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-technical-implementation"><a class="header" href="#kubernetes-gitops-platform-technical-implementation">Kubernetes GitOps Platform Technical Implementation</a></h1>
<h2 id="infrastructure-as-code-terraform-1"><a class="header" href="#infrastructure-as-code-terraform-1">Infrastructure as Code (Terraform)</a></h2>
<h3 id="vpc-configuration"><a class="header" href="#vpc-configuration">VPC Configuration</a></h3>
<pre><code class="language-hcl">module "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "~&gt; 5.0"

  name = "eks-vpc"
  cidr = "10.0.0.0/16"

  azs             = ["us-east-1a", "us-east-1b", "us-east-1c"]
  private_subnets = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]

  enable_nat_gateway = true
  enable_vpn_gateway = false

  tags = {
    Terraform   = "true"
    Environment = "production"
  }
}
</code></pre>
<h3 id="eks-cluster-configuration"><a class="header" href="#eks-cluster-configuration">EKS Cluster Configuration</a></h3>
<pre><code class="language-hcl">module "eks" {
  source  = "terraform-aws-modules/eks/aws"
  version = "~&gt; 19.0"

  cluster_name    = "production-eks"
  cluster_version = "1.28"

  vpc_id                         = module.vpc.vpc_id
  subnet_ids                     = module.vpc.private_subnets
  cluster_endpoint_public_access = true

  # Managed Node Groups
  eks_managed_node_groups = {
    application = {
      name = "application-nodes"
      instance_types = ["t3.small"]
      min_size     = 1
      max_size     = 5
      desired_size = 3
    }
    
    platform = {
      name = "platform-nodes"
      instance_types = ["t3.medium"]
      min_size     = 1
      max_size     = 5
      desired_size = 2
    }
  }
}
</code></pre>
<h3 id="argocd-installation"><a class="header" href="#argocd-installation">ArgoCD Installation</a></h3>
<pre><code class="language-hcl">resource "helm_release" "argocd" {
  name       = "argocd"
  repository = "https://argoproj.github.io/argo-helm"
  chart      = "argo-cd"
  version    = "5.51.6"
  namespace  = "argocd"

  values = [
    file("${path.module}/argocd/values.yaml")
  ]

  depends_on = [module.eks]
}
</code></pre>
<h2 id="gitops-implementation"><a class="header" href="#gitops-implementation">GitOps Implementation</a></h2>
<h3 id="app-of-apps-pattern-1"><a class="header" href="#app-of-apps-pattern-1">App-of-Apps Pattern</a></h3>
<pre><code class="language-yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: k8s-platform-toolkit
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/Lforlinux/k8s-platform-toolkit.git
    targetRevision: HEAD
    path: argocd/apps
    directory:
      recurse: true
  destination:
    server: https://kubernetes.default.svc
    namespace: argocd
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
</code></pre>
<h3 id="sync-waves-configuration"><a class="header" href="#sync-waves-configuration">Sync Waves Configuration</a></h3>
<pre><code class="language-yaml"># Wave 1: Testing Infrastructure
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: sanity-test
  annotations:
    argocd.argoproj.io/sync-wave: "1"
---
# Wave 2-4: Monitoring Stack
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: monitoring-stack
  annotations:
    argocd.argoproj.io/sync-wave: "3"
---
# Wave 5: Logging (depends on Loki)
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: promtail
  annotations:
    argocd.argoproj.io/sync-wave: "5"
</code></pre>
<h2 id="monitoring-stack-implementation"><a class="header" href="#monitoring-stack-implementation">Monitoring Stack Implementation</a></h2>
<h3 id="prometheus-configuration-1"><a class="header" href="#prometheus-configuration-1">Prometheus Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    scrape_configs:
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
      
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
      
      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics:8080']
      
      - job_name: 'node-exporter'
        static_configs:
          - targets: ['node-exporter:9100']
</code></pre>
<h3 id="grafana-dashboard-configuration"><a class="header" href="#grafana-dashboard-configuration">Grafana Dashboard Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: monitoring
data:
  online-boutique.json: |
    {
      "dashboard": {
        "title": "Online Boutique Metrics",
        "panels": [
          {
            "title": "Request Rate",
            "targets": [
              {
                "expr": "rate(http_requests_total[5m])"
              }
            ]
          }
        ]
      }
    }
</code></pre>
<h2 id="logging-stack-implementation"><a class="header" href="#logging-stack-implementation">Logging Stack Implementation</a></h2>
<h3 id="loki-configuration"><a class="header" href="#loki-configuration">Loki Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: monitoring
data:
  loki.yaml: |
    auth_enabled: false
    server:
      http_listen_port: 3100
    ingester:
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
</code></pre>
<h3 id="promtail-configuration"><a class="header" href="#promtail-configuration">Promtail Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: monitoring
data:
  promtail.yml: |
    server:
      http_listen_port: 3101
    positions:
      filename: /tmp/positions.yaml
    clients:
      - url: http://loki:3100/loki/api/v1/push
    scrape_configs:
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: __host__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
</code></pre>
<h2 id="testing-applications"><a class="header" href="#testing-applications">Testing Applications</a></h2>
<h3 id="availability-test-implementation"><a class="header" href="#availability-test-implementation">Availability Test Implementation</a></h3>
<pre><code class="language-python">import requests
import time
from datetime import datetime

class AvailabilityTest:
    def __init__(self, frontend_url, cart_url):
        self.frontend_url = frontend_url
        self.cart_url = cart_url
        self.test_results = []
    
    def test_cart_workflow(self):
        """Test complete cart workflow"""
        try:
            # Test 1: Frontend accessibility
            response = requests.get(f"{self.frontend_url}/")
            assert response.status_code == 200
            
            # Test 2: Add to cart
            add_response = requests.post(
                f"{self.cart_url}/add",
                json={"product_id": "test-product", "quantity": 1}
            )
            assert add_response.status_code == 200
            
            # Test 3: Remove from cart
            remove_response = requests.post(
                f"{self.cart_url}/remove",
                json={"product_id": "test-product"}
            )
            assert remove_response.status_code == 200
            
            return {"status": "pass", "timestamp": datetime.now()}
        except Exception as e:
            return {"status": "fail", "error": str(e), "timestamp": datetime.now()}
</code></pre>
<h3 id="sanity-test-implementation"><a class="header" href="#sanity-test-implementation">Sanity Test Implementation</a></h3>
<pre><code class="language-python">class SanityTest:
    def __init__(self, services):
        self.services = services
        self.results = {}
    
    def test_all_services(self):
        """Test health of all microservices"""
        for service in self.services:
            try:
                response = requests.get(f"{service}/health", timeout=5)
                self.results[service] = {
                    "status": "healthy" if response.status_code == 200 else "unhealthy",
                    "response_time": response.elapsed.total_seconds()
                }
            except Exception as e:
                self.results[service] = {
                    "status": "error",
                    "error": str(e)
                }
        return self.results
</code></pre>
<h2 id="automation-with-makefile"><a class="header" href="#automation-with-makefile">Automation with Makefile</a></h2>
<h3 id="deployment-automation"><a class="header" href="#deployment-automation">Deployment Automation</a></h3>
<pre><code class="language-makefile">DOCKER_IMAGE ?= hashicorp/terraform:1.6
EXEC = docker run --rm -i \
    -e AWS_PROFILE=$(AWS_PROFILE) \
    -v $(HOME)/.aws:/root/.aws \
    -v $(PWD):/data \
    -w /data \
    $(DOCKER_IMAGE)

.PHONY: deploy
deploy:
    @$(EXEC) init -no-color
    @$(EXEC) apply -no-color
    @echo "=== ArgoCD Access Information ==="
    @echo "URL: $$($(EXEC) output -raw argocd_server_url)"
    @echo "Username: $$($(EXEC) output -raw argocd_username)"
    @echo "Password: $$($(EXEC) output -raw argocd_password)"
</code></pre>
<h2 id="horizontal-pod-autoscaler"><a class="header" href="#horizontal-pod-autoscaler">Horizontal Pod Autoscaler</a></h2>
<h3 id="hpa-configuration"><a class="header" href="#hpa-configuration">HPA Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nodejs-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nodejs-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
</code></pre>
<h2 id="helm-chart-structure"><a class="header" href="#helm-chart-structure">Helm Chart Structure</a></h2>
<h3 id="nodejs-application-chart"><a class="header" href="#nodejs-application-chart">NodeJS Application Chart</a></h3>
<pre><code class="language-yaml"># values.yaml
replicaCount: 2
image:
  repository: nodejs-app
  tag: latest
  pullPolicy: IfNotPresent

service:
  type: LoadBalancer
  port: 80

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-deployment"><a class="header" href="#kubernetes-gitops-platform-deployment">Kubernetes GitOps Platform Deployment</a></h1>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<h3 id="aws-account-setup"><a class="header" href="#aws-account-setup">AWS Account Setup</a></h3>
<ul>
<li>AWS account with programmatic access</li>
<li>IAM user with required policies:
<ul>
<li><code>AmazonEC2FullAccess</code></li>
<li><code>IAMFullAccess</code></li>
<li><code>AutoScalingFullAccess</code></li>
<li><code>AmazonEKSClusterPolicy</code></li>
<li><code>AmazonEKSWorkerNodePolicy</code></li>
<li><code>AmazonVPCFullAccess</code></li>
<li><code>AmazonEKSServicePolicy</code></li>
<li><code>AmazonEKS_CNI_Policy</code></li>
</ul>
</li>
</ul>
<h3 id="local-requirements"><a class="header" href="#local-requirements">Local Requirements</a></h3>
<ul>
<li>Docker installed and running</li>
<li>AWS CLI configured with credentials</li>
<li>Git for cloning repositories</li>
</ul>
<h2 id="quick-start-deployment"><a class="header" href="#quick-start-deployment">Quick Start Deployment</a></h2>
<h3 id="1-clone-infrastructure-repository"><a class="header" href="#1-clone-infrastructure-repository">1. Clone Infrastructure Repository</a></h3>
<pre><code class="language-bash">git clone https://github.com/Lforlinux/k8s-infrastructure-as-code.git
cd k8s-infrastructure-as-code
</code></pre>
<h3 id="2-configure-aws-credentials"><a class="header" href="#2-configure-aws-credentials">2. Configure AWS Credentials</a></h3>
<pre><code class="language-bash"># Option 1: AWS CLI configuration
aws configure

# Option 2: Environment variable
export AWS_PROFILE=your-profile
</code></pre>
<h3 id="3-deploy-entire-stack"><a class="header" href="#3-deploy-entire-stack">3. Deploy Entire Stack</a></h3>
<pre><code class="language-bash">make deploy
</code></pre>
<p>This single command:</p>
<ol>
<li>Initializes Terraform</li>
<li>Plans infrastructure changes</li>
<li>Applies infrastructure (VPC, EKS, ArgoCD)</li>
<li>Displays access information</li>
</ol>
<h3 id="4-review-deployment-output"><a class="header" href="#4-review-deployment-output">4. Review Deployment Output</a></h3>
<p>After deployment, you'll see:</p>
<ul>
<li>Kubernetes cluster access command</li>
<li>ArgoCD server URL</li>
<li>ArgoCD username and password</li>
</ul>
<h2 id="deployment-workflow"><a class="header" href="#deployment-workflow">Deployment Workflow</a></h2>
<h3 id="infrastructure-deployment"><a class="header" href="#infrastructure-deployment">Infrastructure Deployment</a></h3>
<pre><code>1. Terraform Init
   ‚Üì
2. Terraform Plan (Review changes)
   ‚Üì
3. Terraform Apply (Create resources)
   ‚Üì
4. EKS Cluster Created
   ‚Üì
5. ArgoCD Installed via Helm
   ‚Üì
6. App-of-Apps Pattern Configured
</code></pre>
<h3 id="platform-toolkit-deployment"><a class="header" href="#platform-toolkit-deployment">Platform Toolkit Deployment</a></h3>
<pre><code>1. ArgoCD Detects App-of-Apps
   ‚Üì
2. References k8s-platform-toolkit Repository
   ‚Üì
3. Deploys Applications in Sync Waves
   ‚Üì
4. Monitoring Stack (Wave 3)
   ‚Üì
5. Logging Stack (Wave 4-5)
   ‚Üì
6. Testing Applications (Wave 1)
   ‚Üì
7. Demo Applications (Wave 2)
</code></pre>
<h2 id="accessing-the-cluster"><a class="header" href="#accessing-the-cluster">Accessing the Cluster</a></h2>
<h3 id="kubernetes-access"><a class="header" href="#kubernetes-access">Kubernetes Access</a></h3>
<pre><code class="language-bash"># Get cluster name and region from Terraform
aws eks --region $(terraform output -raw region) \
  update-kubeconfig --name $(terraform output -raw cluster_name)

# Verify access
kubectl get nodes
</code></pre>
<h3 id="argocd-access"><a class="header" href="#argocd-access">ArgoCD Access</a></h3>
<pre><code class="language-bash"># Get ArgoCD LoadBalancer URL
kubectl get svc -n argocd argocd-server

# Get admin password
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d
</code></pre>
<h3 id="application-access"><a class="header" href="#application-access">Application Access</a></h3>
<pre><code class="language-bash"># List all LoadBalancer services
kubectl get svc --all-namespaces -o wide | grep LoadBalancer

# Access specific services
# Grafana: http://&lt;grafana-lb-url&gt;
# Prometheus: http://&lt;prometheus-lb-url&gt;
# Online Boutique: http://&lt;frontend-lb-url&gt;
</code></pre>
<h2 id="gitops-workflow-1"><a class="header" href="#gitops-workflow-1">GitOps Workflow</a></h2>
<h3 id="making-changes"><a class="header" href="#making-changes">Making Changes</a></h3>
<ol>
<li>
<p><strong>Update Application Code</strong></p>
<pre><code class="language-bash"># Make changes to application
vim k8s-platform-toolkit/application/online-boutique/online-boutique-manifest.yaml
</code></pre>
</li>
<li>
<p><strong>Commit and Push</strong></p>
<pre><code class="language-bash">git add .
git commit -m "Update application configuration"
git push origin main
</code></pre>
</li>
<li>
<p><strong>ArgoCD Auto-Sync</strong></p>
<ul>
<li>ArgoCD detects Git changes</li>
<li>Automatically syncs applications</li>
<li>Performs rolling updates</li>
</ul>
</li>
<li>
<p><strong>Monitor Deployment</strong></p>
<pre><code class="language-bash"># Watch ArgoCD applications
kubectl get applications -n argocd -w

# Check sync status
argocd app get &lt;app-name&gt;
</code></pre>
</li>
</ol>
<h2 id="zero-downtime-deployments"><a class="header" href="#zero-downtime-deployments">Zero-Downtime Deployments</a></h2>
<h3 id="rolling-update-strategy"><a class="header" href="#rolling-update-strategy">Rolling Update Strategy</a></h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodejs-app
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    spec:
      containers:
      - name: app
        image: nodejs-app:v2.0.0
</code></pre>
<h3 id="deployment-process-2"><a class="header" href="#deployment-process-2">Deployment Process</a></h3>
<ol>
<li>New pods created with new image</li>
<li>Readiness probes verify health</li>
<li>Old pods terminated after new pods ready</li>
<li>Service continues serving traffic throughout</li>
</ol>
<h2 id="application-lifecycle"><a class="header" href="#application-lifecycle">Application Lifecycle</a></h2>
<h3 id="adding-new-application"><a class="header" href="#adding-new-application">Adding New Application</a></h3>
<ol>
<li>
<p><strong>Create Application Manifests</strong></p>
<pre><code class="language-bash"># In k8s-platform-toolkit repository
mkdir -p application/my-app
# Create deployment.yaml, service.yaml, etc.
</code></pre>
</li>
<li>
<p><strong>Create ArgoCD Application Definition</strong></p>
<pre><code class="language-yaml"># argocd/apps/my-app.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: my-app
spec:
  source:
    repoURL: https://github.com/Lforlinux/k8s-platform-toolkit.git
    path: application/my-app
  destination:
    server: https://kubernetes.default.svc
    namespace: my-app
</code></pre>
</li>
<li>
<p><strong>Commit and Push</strong></p>
<pre><code class="language-bash">git add .
git commit -m "Add new application"
git push origin main
</code></pre>
</li>
<li>
<p><strong>ArgoCD Auto-Deploys</strong></p>
<ul>
<li>Detects new application definition</li>
<li>Creates namespace</li>
<li>Deploys application</li>
</ul>
</li>
</ol>
<h3 id="updating-applications"><a class="header" href="#updating-applications">Updating Applications</a></h3>
<ol>
<li><strong>Update Manifests in Git</strong></li>
<li><strong>ArgoCD Detects Changes</strong></li>
<li><strong>Automatic Sync (if enabled)</strong></li>
<li><strong>Rolling Update Performed</strong></li>
</ol>
<h3 id="removing-applications"><a class="header" href="#removing-applications">Removing Applications</a></h3>
<ol>
<li>
<p><strong>Delete ArgoCD Application</strong></p>
<pre><code class="language-bash">kubectl delete application my-app -n argocd
</code></pre>
</li>
<li>
<p><strong>Or Remove from Git</strong></p>
<ul>
<li>Delete application definition</li>
<li>ArgoCD removes application</li>
<li>Resources cleaned up</li>
</ul>
</li>
</ol>
<h2 id="troubleshooting-deployment"><a class="header" href="#troubleshooting-deployment">Troubleshooting Deployment</a></h2>
<h3 id="check-terraform-state"><a class="header" href="#check-terraform-state">Check Terraform State</a></h3>
<pre><code class="language-bash"># View current state
terraform show

# List resources
terraform state list

# Inspect specific resource
terraform state show module.eks.aws_eks_cluster.this[0]
</code></pre>
<h3 id="check-argocd-sync-status"><a class="header" href="#check-argocd-sync-status">Check ArgoCD Sync Status</a></h3>
<pre><code class="language-bash"># List all applications
kubectl get applications -n argocd

# Describe application
kubectl describe application &lt;app-name&gt; -n argocd

# Check sync status
argocd app sync &lt;app-name&gt;
</code></pre>
<h3 id="verify-pod-status"><a class="header" href="#verify-pod-status">Verify Pod Status</a></h3>
<pre><code class="language-bash"># Check all pods
kubectl get pods --all-namespaces

# Check specific namespace
kubectl get pods -n monitoring

# View pod logs
kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-monitoring--observability"><a class="header" href="#kubernetes-gitops-platform-monitoring--observability">Kubernetes GitOps Platform Monitoring &amp; Observability</a></h1>
<h2 id="monitoring-stack-1"><a class="header" href="#monitoring-stack-1">Monitoring Stack</a></h2>
<h3 id="prometheus-configuration-2"><a class="header" href="#prometheus-configuration-2">Prometheus Configuration</a></h3>
<p>Prometheus collects metrics from:</p>
<ul>
<li><strong>Kubernetes Pods</strong>: Application metrics via annotations</li>
<li><strong>Kubernetes Nodes</strong>: Node-level metrics via node-exporter</li>
<li><strong>Kubernetes Objects</strong>: Cluster state via kube-state-metrics</li>
<li><strong>Services</strong>: Service discovery and scraping</li>
</ul>
<h3 id="key-metrics-collected"><a class="header" href="#key-metrics-collected">Key Metrics Collected</a></h3>
<h4 id="application-metrics"><a class="header" href="#application-metrics">Application Metrics</a></h4>
<ul>
<li>Request rate and latency</li>
<li>Error rates and status codes</li>
<li>Resource utilization (CPU, memory)</li>
<li>Custom business metrics</li>
</ul>
<h4 id="infrastructure-metrics"><a class="header" href="#infrastructure-metrics">Infrastructure Metrics</a></h4>
<ul>
<li>Node CPU, memory, disk usage</li>
<li>Pod resource consumption</li>
<li>Network traffic and bandwidth</li>
<li>Storage utilization</li>
</ul>
<h4 id="kubernetes-metrics"><a class="header" href="#kubernetes-metrics">Kubernetes Metrics</a></h4>
<ul>
<li>Deployment status and replicas</li>
<li>Pod status and restarts</li>
<li>Service endpoints</li>
<li>HPA scaling events</li>
</ul>
<h3 id="grafana-dashboards-1"><a class="header" href="#grafana-dashboards-1">Grafana Dashboards</a></h3>
<h4 id="pre-configured-dashboards"><a class="header" href="#pre-configured-dashboards">Pre-configured Dashboards</a></h4>
<ul>
<li><strong>Kubernetes Cluster Overview</strong>: Cluster health and resource usage</li>
<li><strong>Online Boutique Dashboard</strong>: Microservices metrics and performance</li>
<li><strong>Node Exporter</strong>: Node-level system metrics</li>
<li><strong>Kube State Metrics</strong>: Kubernetes object state</li>
</ul>
<h4 id="custom-dashboards"><a class="header" href="#custom-dashboards">Custom Dashboards</a></h4>
<pre><code class="language-json">{
  "dashboard": {
    "title": "Online Boutique Metrics",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{service}}"
          }
        ]
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "{{service}}"
          }
        ]
      }
    ]
  }
}
</code></pre>
<h2 id="logging-stack"><a class="header" href="#logging-stack">Logging Stack</a></h2>
<h3 id="loki-configuration-1"><a class="header" href="#loki-configuration-1">Loki Configuration</a></h3>
<p>Loki aggregates logs from all pods:</p>
<ul>
<li><strong>Efficient Storage</strong>: Indexed by labels, not log content</li>
<li><strong>Prometheus-inspired</strong>: Similar query language</li>
<li><strong>Grafana Integration</strong>: Native Grafana data source</li>
</ul>
<h3 id="promtail-configuration-1"><a class="header" href="#promtail-configuration-1">Promtail Configuration</a></h3>
<p>Promtail collects logs:</p>
<ul>
<li><strong>DaemonSet</strong>: Runs on every node</li>
<li><strong>Automatic Discovery</strong>: Discovers pods automatically</li>
<li><strong>Metadata Enrichment</strong>: Adds Kubernetes labels</li>
<li><strong>Log Shipping</strong>: Sends logs to Loki</li>
</ul>
<h3 id="log-queries"><a class="header" href="#log-queries">Log Queries</a></h3>
<pre><code class="language-logql"># Query logs by service
{namespace="online-boutique", service="cartservice"}

# Filter by log level
{namespace="online-boutique"} |= "error"

# Count errors
count_over_time({namespace="online-boutique"} |= "error" [5m])
</code></pre>
<h2 id="testing--validation"><a class="header" href="#testing--validation">Testing &amp; Validation</a></h2>
<h3 id="sanity-test-monitoring"><a class="header" href="#sanity-test-monitoring">Sanity Test Monitoring</a></h3>
<p><strong>Purpose</strong>: Automated health check testing</p>
<ul>
<li>Tests all microservices every 60 seconds</li>
<li>Tracks response times and errors</li>
<li>Provides REST API for status</li>
<li>Web UI dashboard for results</li>
</ul>
<p><strong>Metrics Tracked</strong>:</p>
<ul>
<li>Total test runs</li>
<li>Pass/fail counts</li>
<li>Response times per service</li>
<li>Error rates</li>
</ul>
<h3 id="availability-test-monitoring"><a class="header" href="#availability-test-monitoring">Availability Test Monitoring</a></h3>
<p><strong>Purpose</strong>: SRE-style availability testing</p>
<ul>
<li>Real user workflow simulation</li>
<li>Tests every 5 minutes</li>
<li>Calculates uptime percentage</li>
<li>Tracks consecutive failures</li>
</ul>
<p><strong>SRE Metrics</strong>:</p>
<ul>
<li><strong>Uptime %</strong>: Service availability percentage</li>
<li><strong>MTTR</strong>: Mean Time To Recovery</li>
<li><strong>MTBF</strong>: Mean Time Between Failures</li>
<li><strong>Error Budget</strong>: Remaining error budget</li>
</ul>
<h2 id="alerting-1"><a class="header" href="#alerting-1">Alerting</a></h2>
<h3 id="prometheus-alert-rules"><a class="header" href="#prometheus-alert-rules">Prometheus Alert Rules</a></h3>
<pre><code class="language-yaml">groups:
  - name: kubernetes
    rules:
      - alert: HighCPUUsage
        expr: node_cpu_usage &gt; 80
        for: 5m
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
      
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[5m]) &gt; 0
        for: 5m
        annotations:
          summary: "Pod {{ $labels.pod }} is crash looping"
      
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) &gt; 0.1
        for: 5m
        annotations:
          summary: "High error rate for {{ $labels.service }}"
</code></pre>
<h3 id="alert-manager-configuration"><a class="header" href="#alert-manager-configuration">Alert Manager Configuration</a></h3>
<pre><code class="language-yaml">route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
receivers:
  - name: 'default'
    webhook_configs:
      - url: 'http://alertmanager:9093/api/v1/alerts'
  - name: 'critical-alerts'
    slack_configs:
      - api_url: 'YOUR_SLACK_WEBHOOK_URL'
        channel: '#alerts'
</code></pre>
<h2 id="observability-best-practices"><a class="header" href="#observability-best-practices">Observability Best Practices</a></h2>
<h3 id="1-comprehensive-instrumentation"><a class="header" href="#1-comprehensive-instrumentation">1. <strong>Comprehensive Instrumentation</strong></a></h3>
<ul>
<li>Instrument all services with metrics</li>
<li>Use consistent metric naming</li>
<li>Include business metrics</li>
<li>Track custom events</li>
</ul>
<h3 id="2-structured-logging"><a class="header" href="#2-structured-logging">2. <strong>Structured Logging</strong></a></h3>
<ul>
<li>Use structured log format (JSON)</li>
<li>Include correlation IDs</li>
<li>Log at appropriate levels</li>
<li>Include context information</li>
</ul>
<h3 id="3-dashboard-design"><a class="header" href="#3-dashboard-design">3. <strong>Dashboard Design</strong></a></h3>
<ul>
<li>Create service-specific dashboards</li>
<li>Include key SLIs and SLOs</li>
<li>Show trends over time</li>
<li>Enable drill-down capabilities</li>
</ul>
<h3 id="4-alert-tuning"><a class="header" href="#4-alert-tuning">4. <strong>Alert Tuning</strong></a></h3>
<ul>
<li>Set appropriate thresholds</li>
<li>Avoid alert fatigue</li>
<li>Use alert grouping</li>
<li>Include runbook links</li>
</ul>
<h3 id="5-log-retention"><a class="header" href="#5-log-retention">5. <strong>Log Retention</strong></a></h3>
<ul>
<li>Configure retention policies</li>
<li>Archive old logs</li>
<li>Compress stored logs</li>
<li>Monitor storage usage</li>
</ul>
<h2 id="key-performance-indicators-kpis"><a class="header" href="#key-performance-indicators-kpis">Key Performance Indicators (KPIs)</a></h2>
<h3 id="application-kpis"><a class="header" href="#application-kpis">Application KPIs</a></h3>
<ul>
<li><strong>Request Rate</strong>: Requests per second</li>
<li><strong>Error Rate</strong>: Percentage of failed requests</li>
<li><strong>Latency</strong>: P50, P95, P99 response times</li>
<li><strong>Availability</strong>: Uptime percentage</li>
</ul>
<h3 id="infrastructure-kpis"><a class="header" href="#infrastructure-kpis">Infrastructure KPIs</a></h3>
<ul>
<li><strong>CPU Utilization</strong>: Average and peak usage</li>
<li><strong>Memory Utilization</strong>: Memory consumption</li>
<li><strong>Network Throughput</strong>: Bytes per second</li>
<li><strong>Storage Usage</strong>: Disk space utilization</li>
</ul>
<h3 id="platform-kpis"><a class="header" href="#platform-kpis">Platform KPIs</a></h3>
<ul>
<li><strong>Deployment Frequency</strong>: Deployments per day</li>
<li><strong>Lead Time</strong>: Time from commit to production</li>
<li><strong>MTTR</strong>: Mean Time To Recovery</li>
<li><strong>Change Failure Rate</strong>: Percentage of failed deployments</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-security--best-practices"><a class="header" href="#kubernetes-gitops-platform-security--best-practices">Kubernetes GitOps Platform Security &amp; Best Practices</a></h1>
<h2 id="network-security-3"><a class="header" href="#network-security-3">Network Security</a></h2>
<h3 id="vpc-configuration-1"><a class="header" href="#vpc-configuration-1">VPC Configuration</a></h3>
<ul>
<li><strong>Private Subnets</strong>: Worker nodes in private subnets</li>
<li><strong>Public Subnets</strong>: Load balancers and NAT gateways</li>
<li><strong>Security Groups</strong>: Restrictive network policies</li>
<li><strong>VPC Flow Logs</strong>: Network traffic monitoring</li>
</ul>
<h3 id="security-group-rules"><a class="header" href="#security-group-rules">Security Group Rules</a></h3>
<pre><code class="language-hcl"># Worker node security group
resource "aws_security_group" "worker_group_mgmt" {
  name_prefix = "worker-group-mgmt"
  vpc_id      = module.vpc.vpc_id

  ingress {
    from_port = 22
    to_port   = 22
    protocol  = "tcp"
    cidr_blocks = ["10.0.0.0/16"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
</code></pre>
<h2 id="iam-security"><a class="header" href="#iam-security">IAM Security</a></h2>
<h3 id="eks-cluster-iam"><a class="header" href="#eks-cluster-iam">EKS Cluster IAM</a></h3>
<pre><code class="language-hcl"># Cluster service role
resource "aws_iam_role" "cluster" {
  name = "eks-cluster-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "eks.amazonaws.com"
        }
      }
    ]
  })
}

# Attach required policies
resource "aws_iam_role_policy_attachment" "cluster_policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role       = aws_iam_role.cluster.name
}
</code></pre>
<h3 id="node-group-iam"><a class="header" href="#node-group-iam">Node Group IAM</a></h3>
<pre><code class="language-hcl"># Worker node role
resource "aws_iam_role" "nodes" {
  name = "eks-node-group-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "ec2.amazonaws.com"
        }
      }
    ]
  })
}

# Required policies
resource "aws_iam_role_policy_attachment" "nodes_AmazonEKSWorkerNodePolicy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role       = aws_iam_role.nodes.name
}
</code></pre>
<h2 id="kubernetes-rbac"><a class="header" href="#kubernetes-rbac">Kubernetes RBAC</a></h2>
<h3 id="service-account-configuration"><a class="header" href="#service-account-configuration">Service Account Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: monitoring
</code></pre>
<h2 id="secrets-management-2"><a class="header" href="#secrets-management-2">Secrets Management</a></h2>
<h3 id="kubernetes-secrets"><a class="header" href="#kubernetes-secrets">Kubernetes Secrets</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
  namespace: production
type: Opaque
data:
  database-password: &lt;base64-encoded&gt;
  api-key: &lt;base64-encoded&gt;
</code></pre>
<h3 id="aws-secrets-manager-integration"><a class="header" href="#aws-secrets-manager-integration">AWS Secrets Manager Integration</a></h3>
<pre><code class="language-hcl"># Retrieve secret from AWS Secrets Manager
data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "production/database/password"
}

# Use in Kubernetes
resource "kubernetes_secret" "app_secrets" {
  metadata {
    name      = "app-secrets"
    namespace = "production"
  }

  data = {
    database-password = data.aws_secretsmanager_secret_version.db_password.secret_string
  }
}
</code></pre>
<h2 id="pod-security"><a class="header" href="#pod-security">Pod Security</a></h2>
<h3 id="pod-security-standards"><a class="header" href="#pod-security-standards">Pod Security Standards</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted
</code></pre>
<h3 id="security-context"><a class="header" href="#security-context">Security Context</a></h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
      containers:
      - name: app
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
              - ALL
</code></pre>
<h2 id="network-policies"><a class="header" href="#network-policies">Network Policies</a></h2>
<h3 id="pod-to-pod-communication"><a class="header" href="#pod-to-pod-communication">Pod-to-Pod Communication</a></h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-policy
  namespace: online-boutique
spec:
  podSelector:
    matchLabels:
      app: frontend
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app: loadbalancer
      ports:
        - protocol: TCP
          port: 8080
  egress:
    - to:
        - podSelector:
            matchLabels:
              app: cartservice
      ports:
        - protocol: TCP
          port: 7070
</code></pre>
<h2 id="argocd-security"><a class="header" href="#argocd-security">ArgoCD Security</a></h2>
<h3 id="rbac-configuration"><a class="header" href="#rbac-configuration">RBAC Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-rbac-cm
  namespace: argocd
data:
  policy.default: role:readonly
  policy.csv: |
    p, role:admin, applications, *, */*, allow
    p, role:admin, clusters, get, *, allow
    p, role:admin, repositories, get, *, allow
    g, admins, role:admin
</code></pre>
<h3 id="repository-access"><a class="header" href="#repository-access">Repository Access</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: repo-credentials
  namespace: argocd
type: Opaque
stringData:
  url: https://github.com/Lforlinux/k8s-platform-toolkit.git
  username: git
  password: &lt;token&gt;
</code></pre>
<h2 id="security-best-practices-3"><a class="header" href="#security-best-practices-3">Security Best Practices</a></h2>
<h3 id="1-least-privilege"><a class="header" href="#1-least-privilege">1. <strong>Least Privilege</strong></a></h3>
<ul>
<li>Grant minimum required permissions</li>
<li>Use service accounts with specific roles</li>
<li>Limit IAM policy scope</li>
<li>Regular permission audits</li>
</ul>
<h3 id="2-encryption"><a class="header" href="#2-encryption">2. <strong>Encryption</strong></a></h3>
<ul>
<li>Encrypt data at rest (EBS volumes)</li>
<li>Encrypt data in transit (TLS/SSL)</li>
<li>Use encrypted secrets</li>
<li>Enable EKS encryption</li>
</ul>
<h3 id="3-image-security"><a class="header" href="#3-image-security">3. <strong>Image Security</strong></a></h3>
<ul>
<li>Scan container images for vulnerabilities</li>
<li>Use trusted base images</li>
<li>Keep images updated</li>
<li>Implement image signing</li>
</ul>
<h3 id="4-network-segmentation"><a class="header" href="#4-network-segmentation">4. <strong>Network Segmentation</strong></a></h3>
<ul>
<li>Use network policies</li>
<li>Isolate namespaces</li>
<li>Limit external access</li>
<li>Monitor network traffic</li>
</ul>
<h3 id="5-audit-logging"><a class="header" href="#5-audit-logging">5. <strong>Audit Logging</strong></a></h3>
<ul>
<li>Enable Kubernetes audit logs</li>
<li>Log all API requests</li>
<li>Monitor access patterns</li>
<li>Alert on suspicious activity</li>
</ul>
<h3 id="6-compliance"><a class="header" href="#6-compliance">6. <strong>Compliance</strong></a></h3>
<ul>
<li>Follow CIS Kubernetes Benchmark</li>
<li>Implement security policies</li>
<li>Regular security assessments</li>
<li>Document security procedures</li>
</ul>
<h2 id="security-checklist"><a class="header" href="#security-checklist">Security Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
VPC with private subnets configured</li>
<li><input disabled="" type="checkbox"/>
Security groups with restrictive rules</li>
<li><input disabled="" type="checkbox"/>
IAM roles with least privilege</li>
<li><input disabled="" type="checkbox"/>
RBAC policies configured</li>
<li><input disabled="" type="checkbox"/>
Network policies implemented</li>
<li><input disabled="" type="checkbox"/>
Secrets encrypted and secured</li>
<li><input disabled="" type="checkbox"/>
Pod security standards enforced</li>
<li><input disabled="" type="checkbox"/>
Image scanning enabled</li>
<li><input disabled="" type="checkbox"/>
Audit logging configured</li>
<li><input disabled="" type="checkbox"/>
Regular security updates applied</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-scaling--performance"><a class="header" href="#kubernetes-gitops-platform-scaling--performance">Kubernetes GitOps Platform Scaling &amp; Performance</a></h1>
<h2 id="horizontal-pod-autoscaler-hpa"><a class="header" href="#horizontal-pod-autoscaler-hpa">Horizontal Pod Autoscaler (HPA)</a></h2>
<h3 id="hpa-configuration-1"><a class="header" href="#hpa-configuration-1">HPA Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nodejs-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nodejs-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 2
          periodSeconds: 15
      selectPolicy: Max
</code></pre>
<h3 id="custom-metrics-hpa"><a class="header" href="#custom-metrics-hpa">Custom Metrics HPA</a></h3>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa-custom
spec:
  metrics:
    - type: Pods
      pods:
        metric:
          name: http_requests_per_second
        target:
          type: AverageValue
          averageValue: "100"
</code></pre>
<h2 id="cluster-autoscaling"><a class="header" href="#cluster-autoscaling">Cluster Autoscaling</a></h2>
<h3 id="node-group-configuration"><a class="header" href="#node-group-configuration">Node Group Configuration</a></h3>
<pre><code class="language-hcl">eks_managed_node_groups = {
  application = {
    name = "application-nodes"
    instance_types = ["t3.small", "t3.medium"]
    
    min_size     = 1
    max_size     = 10
    desired_size = 3
    
    # Cluster Autoscaler labels
    labels = {
      "k8s.io/cluster-autoscaler/enabled" = "true"
      "k8s.io/cluster-autoscaler/${local.cluster_name}" = "owned"
    }
    
    # Taints and tolerations
    taints = []
  }
}
</code></pre>
<h3 id="cluster-autoscaler-deployment"><a class="header" href="#cluster-autoscaler-deployment">Cluster Autoscaler Deployment</a></h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  template:
    spec:
      containers:
      - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.28.0
        name: cluster-autoscaler
        command:
          - ./cluster-autoscaler
          - --v=4
          - --stderrthreshold=info
          - --cloud-provider=aws
          - --skip-nodes-with-local-storage=false
          - --expander=least-waste
          - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/${CLUSTER_NAME}
        env:
          - name: AWS_REGION
            value: us-east-1
          - name: CLUSTER_NAME
            value: production-eks
</code></pre>
<h2 id="vertical-pod-autoscaler-vpa"><a class="header" href="#vertical-pod-autoscaler-vpa">Vertical Pod Autoscaler (VPA)</a></h2>
<h3 id="vpa-configuration"><a class="header" href="#vpa-configuration">VPA Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: nodejs-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nodejs-app
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
      - containerName: app
        minAllowed:
          cpu: 100m
          memory: 128Mi
        maxAllowed:
          cpu: 2
          memory: 2Gi
        controlledResources: ["cpu", "memory"]
</code></pre>
<h2 id="performance-optimization-3"><a class="header" href="#performance-optimization-3">Performance Optimization</a></h2>
<h3 id="resource-requests-and-limits"><a class="header" href="#resource-requests-and-limits">Resource Requests and Limits</a></h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: optimized-app
spec:
  template:
    spec:
      containers:
      - name: app
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
</code></pre>
<h3 id="node-affinity"><a class="header" href="#node-affinity">Node Affinity</a></h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-affinity
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-type
                    operator: In
                    values:
                      - application
</code></pre>
<h3 id="pod-disruption-budget"><a class="header" href="#pod-disruption-budget">Pod Disruption Budget</a></h3>
<pre><code class="language-yaml">apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: app-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: nodejs-app
</code></pre>
<h2 id="load-testing"><a class="header" href="#load-testing">Load Testing</a></h2>
<h3 id="locust-configuration"><a class="header" href="#locust-configuration">Locust Configuration</a></h3>
<pre><code class="language-python">from locust import HttpUser, task, between

class WebsiteUser(HttpUser):
    wait_time = between(1, 3)
    
    @task(3)
    def view_home(self):
        self.client.get("/")
    
    @task(2)
    def add_to_cart(self):
        self.client.post("/cart/add", json={
            "product_id": "test-product",
            "quantity": 1
        })
    
    @task(1)
    def checkout(self):
        self.client.post("/checkout", json={
            "cart_id": "test-cart"
        })
</code></pre>
<h3 id="running-load-tests"><a class="header" href="#running-load-tests">Running Load Tests</a></h3>
<pre><code class="language-bash">export TARGET_HOST=&lt;your-alb-url&gt;

docker run -i --rm \
  -v $PWD/reports:/opt/reports \
  -p 8089:8089 \
  -e TARGET_HOST=$TARGET_HOST \
  -e LOCUST_FILE=locustfile.py \
  registry.opensource.zalan.do/tip/docker-locust
</code></pre>
<h2 id="monitoring-scaling-events"><a class="header" href="#monitoring-scaling-events">Monitoring Scaling Events</a></h2>
<h3 id="hpa-metrics"><a class="header" href="#hpa-metrics">HPA Metrics</a></h3>
<pre><code class="language-bash"># Watch HPA status
kubectl get hpa -w

# Describe HPA
kubectl describe hpa nodejs-app-hpa

# Check scaling events
kubectl get events --field-selector involvedObject.name=nodejs-app-hpa
</code></pre>
<h3 id="cluster-autoscaler-logs"><a class="header" href="#cluster-autoscaler-logs">Cluster Autoscaler Logs</a></h3>
<pre><code class="language-bash"># View autoscaler logs
kubectl logs -n kube-system deployment/cluster-autoscaler

# Check node scaling
kubectl get nodes -w
</code></pre>
<h2 id="scaling-strategies"><a class="header" href="#scaling-strategies">Scaling Strategies</a></h2>
<h3 id="1-predictive-scaling"><a class="header" href="#1-predictive-scaling">1. <strong>Predictive Scaling</strong></a></h3>
<ul>
<li>Analyze historical patterns</li>
<li>Scale before expected load</li>
<li>Use scheduled scaling</li>
<li>Monitor trends</li>
</ul>
<h3 id="2-reactive-scaling"><a class="header" href="#2-reactive-scaling">2. <strong>Reactive Scaling</strong></a></h3>
<ul>
<li>HPA for automatic scaling</li>
<li>Fast response to load changes</li>
<li>Multiple metrics consideration</li>
<li>Stabilization windows</li>
</ul>
<h3 id="3-cost-optimization"><a class="header" href="#3-cost-optimization">3. <strong>Cost Optimization</strong></a></h3>
<ul>
<li>Right-size resource requests</li>
<li>Use spot instances for non-critical workloads</li>
<li>Implement cluster autoscaling</li>
<li>Monitor and optimize</li>
</ul>
<h3 id="4-performance-tuning"><a class="header" href="#4-performance-tuning">4. <strong>Performance Tuning</strong></a></h3>
<ul>
<li>Optimize application code</li>
<li>Use connection pooling</li>
<li>Implement caching</li>
<li>Database query optimization</li>
</ul>
<h2 id="capacity-planning"><a class="header" href="#capacity-planning">Capacity Planning</a></h2>
<h3 id="resource-calculation"><a class="header" href="#resource-calculation">Resource Calculation</a></h3>
<pre><code>Total CPU Required = (Requests per Pod √ó CPU per Request) √ó Desired Pods
Total Memory Required = (Memory per Pod) √ó Desired Pods

Node Capacity = Node CPU / Pod CPU Request
Max Pods per Node = min(Node Capacity, Pod Limit)
</code></pre>
<h3 id="scaling-triggers-1"><a class="header" href="#scaling-triggers-1">Scaling Triggers</a></h3>
<ul>
<li><strong>CPU Utilization</strong>: &gt; 70% average</li>
<li><strong>Memory Utilization</strong>: &gt; 80% average</li>
<li><strong>Request Rate</strong>: &gt; Threshold</li>
<li><strong>Queue Depth</strong>: &gt; Limit</li>
<li><strong>Custom Metrics</strong>: Business-specific</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform---k6-performance-testing"><a class="header" href="#kubernetes-gitops-platform---k6-performance-testing">Kubernetes GitOps Platform - k6 Performance Testing</a></h1>
<h2 id="what-is-k6"><a class="header" href="#what-is-k6">What is k6?</a></h2>
<p>k6 is a modern, developer-centric performance testing tool built by Grafana Labs. It's designed for testing the performance of APIs, microservices, and websites using JavaScript.</p>
<h3 id="key-features-of-k6"><a class="header" href="#key-features-of-k6">Key Features of k6</a></h3>
<ul>
<li><strong>JavaScript-based</strong>: Write tests in JavaScript (ES6+)</li>
<li><strong>Developer-friendly</strong>: Easy to learn and integrate into CI/CD</li>
<li><strong>Cloud-native</strong>: Designed for containerized environments</li>
<li><strong>Metrics Integration</strong>: Native Prometheus and StatsD support</li>
<li><strong>High Performance</strong>: Can generate massive load from a single machine</li>
<li><strong>Open Source</strong>: Free and open-source tool</li>
</ul>
<h3 id="why-k6-for-kubernetes"><a class="header" href="#why-k6-for-kubernetes">Why k6 for Kubernetes?</a></h3>
<ul>
<li><strong>Kubernetes-native</strong>: Runs as Kubernetes Jobs</li>
<li><strong>Resource Efficient</strong>: Single container can generate high load</li>
<li><strong>GitOps Compatible</strong>: Test scripts stored in Git</li>
<li><strong>Observability</strong>: Metrics exported to Prometheus</li>
<li><strong>Automation</strong>: Can be scheduled via CronJobs</li>
</ul>
<h2 id="k6-implementation-in-kubernetes-gitops-platform"><a class="header" href="#k6-implementation-in-kubernetes-gitops-platform">k6 Implementation in Kubernetes GitOps Platform</a></h2>
<h3 id="architecture"><a class="header" href="#architecture">Architecture</a></h3>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  k6 Test Jobs   ‚îÇ
‚îÇ  (Kubernetes)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Metrics Export
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ StatsD Exporter‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   Prometheus    ‚îÇ
‚îÇ                ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                               ‚îÇ Query
                               ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ    Grafana     ‚îÇ
                       ‚îÇ   Dashboards   ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h3 id="test-types-implemented"><a class="header" href="#test-types-implemented">Test Types Implemented</a></h3>
<h4 id="1-smoke-test"><a class="header" href="#1-smoke-test">1. Smoke Test</a></h4>
<p><strong>Purpose</strong>: Basic functionality verification with minimal load</p>
<pre><code class="language-javascript">export const options = {
  stages: [
    { duration: '1m', target: 1 },   // Ramp up to 1 user
    { duration: '2m', target: 1 },   // Stay at 1 user
    { duration: '1m', target: 0 },    // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)&lt;2000'],  // 95% &lt; 2s
    http_req_failed: ['rate&lt;0.01'],     // &lt; 1% errors
  },
};
</code></pre>
<p><strong>Use Cases</strong>:</p>
<ul>
<li>Quick validation after deployment</li>
<li>Pre-deployment sanity checks</li>
<li>CI/CD pipeline integration</li>
<li>Daily health verification</li>
</ul>
<h4 id="2-load-test"><a class="header" href="#2-load-test">2. Load Test</a></h4>
<p><strong>Purpose</strong>: Normal production load testing</p>
<pre><code class="language-javascript">export const options = {
  stages: [
    { duration: '2m', target: 50 },   // Ramp to 50 users
    { duration: '5m', target: 50 },   // Normal load
    { duration: '2m', target: 100 },  // Ramp to 100 users
    { duration: '5m', target: 100 },  // Higher load
    { duration: '2m', target: 0 },    // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)&lt;3000', 'p(99)&lt;5000'],
    http_req_failed: ['rate&lt;0.05'],
  },
};
</code></pre>
<p><strong>Use Cases</strong>:</p>
<ul>
<li>Validate performance under expected load</li>
<li>Capacity planning</li>
<li>Performance baseline establishment</li>
<li>SLO validation</li>
</ul>
<h4 id="3-stress-test"><a class="header" href="#3-stress-test">3. Stress Test</a></h4>
<p><strong>Purpose</strong>: Find breaking point and maximum capacity</p>
<pre><code class="language-javascript">export const options = {
  stages: [
    { duration: '2m', target: 100 },
    { duration: '5m', target: 100 },
    { duration: '2m', target: 200 },
    { duration: '5m', target: 200 },
    { duration: '2m', target: 300 },
    { duration: '5m', target: 300 },
    { duration: '2m', target: 400 },
    { duration: '5m', target: 400 },
    { duration: '2m', target: 500 },
    { duration: '5m', target: 500 },
    { duration: '10m', target: 0 },
  ],
  thresholds: {
    http_req_duration: ['p(95)&lt;10000'],
    http_req_failed: ['rate&lt;0.20'],
  },
};
</code></pre>
<p><strong>Use Cases</strong>:</p>
<ul>
<li>Find maximum capacity</li>
<li>Identify bottlenecks</li>
<li>Test autoscaling limits</li>
<li>Disaster recovery planning</li>
</ul>
<h4 id="4-spike-test"><a class="header" href="#4-spike-test">4. Spike Test</a></h4>
<p><strong>Purpose</strong>: Test handling of sudden traffic spikes</p>
<pre><code class="language-javascript">export const options = {
  stages: [
    { duration: '1m', target: 10 },
    { duration: '30s', target: 500 },   // Sudden spike
    { duration: '1m', target: 500 },
    { duration: '30s', target: 10 },
    { duration: '1m', target: 10 },
    { duration: '30s', target: 1000 },  // Larger spike
    { duration: '1m', target: 1000 },
    { duration: '30s', target: 10 },
    { duration: '1m', target: 0 },
  ],
};
</code></pre>
<p><strong>Use Cases</strong>:</p>
<ul>
<li>Validate autoscaling response</li>
<li>Test rate limiting</li>
<li>Verify circuit breakers</li>
<li>Black Friday scenarios</li>
</ul>
<h2 id="test-implementation-details"><a class="header" href="#test-implementation-details">Test Implementation Details</a></h2>
<h3 id="test-structure"><a class="header" href="#test-structure">Test Structure</a></h3>
<p>Each test script follows this structure:</p>
<pre><code class="language-javascript">// 1. Import k6 modules
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

// 2. Define custom metrics
const errorRate = new Rate('errors');
const frontendErrorRate = new Rate('frontend_errors');
const backendErrorRate = new Rate('backend_errors');

// 3. Configure test options
export const options = {
  stages: [...],
  thresholds: {...},
};

// 4. Main test function
export default function () {
  // Frontend tests (HTTP)
  // Backend tests (health checks)
}

// 5. Summary handler
export function handleSummary(data) {
  return { 'stdout': textSummary(data) };
}
</code></pre>
<h3 id="test-scenarios"><a class="header" href="#test-scenarios">Test Scenarios</a></h3>
<h4 id="frontend-testing"><a class="header" href="#frontend-testing">Frontend Testing</a></h4>
<ul>
<li><strong>Homepage Load</strong>: Tests main page accessibility</li>
<li><strong>Product Pages</strong>: Tests product detail pages</li>
<li><strong>Error Tracking</strong>: Monitors frontend-specific errors</li>
</ul>
<h4 id="backend-testing"><a class="header" href="#backend-testing">Backend Testing</a></h4>
<ul>
<li><strong>Health Checks</strong>: Validates backend service health</li>
<li><strong>Service Integration</strong>: Tests microservice communication</li>
<li><strong>Error Tracking</strong>: Monitors backend-specific errors</li>
</ul>
<h3 id="custom-metrics-1"><a class="header" href="#custom-metrics-1">Custom Metrics</a></h3>
<pre><code class="language-javascript">// Custom error rate metrics
const errorRate = new Rate('errors');
const frontendErrorRate = new Rate('frontend_errors');
const backendErrorRate = new Rate('backend_errors');

// Track errors in tests
errorRate.add(!success);
frontendErrorRate.add(!success);
backendErrorRate.add(!success);
</code></pre>
<h2 id="kubernetes-deployment"><a class="header" href="#kubernetes-deployment">Kubernetes Deployment</a></h2>
<h3 id="job-configuration"><a class="header" href="#job-configuration">Job Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: k6-load-test
  namespace: performance-testing
spec:
  template:
    spec:
      containers:
      - name: k6
        image: grafana/k6:0.50.0
        command: ["k6", "run"]
        args:
          - "--out"
          - "statsd"
          - "/scripts/k6-load-test.js"
        env:
        - name: TARGET_URL
          value: "http://frontend-external.online-boutique.svc.cluster.local"
        - name: K6_STATSD_ADDR
          value: "statsd-exporter.performance-testing.svc.cluster.local:9125"
        volumeMounts:
        - name: test-scripts
          mountPath: /scripts
      volumes:
      - name: test-scripts
        configMap:
          name: k6-test-scripts
</code></pre>
<h3 id="configmap-for-test-scripts"><a class="header" href="#configmap-for-test-scripts">ConfigMap for Test Scripts</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: k6-test-scripts
  namespace: performance-testing
data:
  k6-smoke-test.js: |
    // Test script content
  k6-load-test.js: |
    // Test script content
  k6-stress-test.js: |
    // Test script content
  k6-spike-test.js: |
    // Test script content
</code></pre>
<h3 id="scheduled-testing-cronjob"><a class="header" href="#scheduled-testing-cronjob">Scheduled Testing (CronJob)</a></h3>
<pre><code class="language-yaml">apiVersion: batch/v1
kind: CronJob
metadata:
  name: k6-scheduled-test
  namespace: performance-testing
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: k6
            image: grafana/k6:0.50.0
            command: ["k6", "run", "/scripts/k6-smoke-test.js"]
</code></pre>
<h2 id="prometheus-integration"><a class="header" href="#prometheus-integration">Prometheus Integration</a></h2>
<h3 id="statsd-exporter"><a class="header" href="#statsd-exporter">StatsD Exporter</a></h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: statsd-exporter
  namespace: performance-testing
spec:
  template:
    spec:
      containers:
      - name: statsd-exporter
        image: prom/statsd-exporter:latest
        ports:
        - containerPort: 9125  # StatsD
        - containerPort: 9102  # Prometheus metrics
</code></pre>
<h3 id="metrics-export"><a class="header" href="#metrics-export">Metrics Export</a></h3>
<p>k6 exports metrics via StatsD to Prometheus:</p>
<pre><code class="language-javascript">// k6 configuration
export const options = {
  // Metrics automatically exported to StatsD
  // Then scraped by Prometheus
};
</code></pre>
<h3 id="available-metrics"><a class="header" href="#available-metrics">Available Metrics</a></h3>
<ul>
<li><code>k6_http_reqs_total</code> - Total HTTP requests</li>
<li><code>k6_http_req_duration_seconds</code> - Request duration histogram</li>
<li><code>k6_http_req_failed_total</code> - Failed requests</li>
<li><code>k6_vus</code> - Current virtual users</li>
<li><code>k6_data_received_total</code> - Data received</li>
<li><code>k6_data_sent_total</code> - Data sent</li>
<li><code>k6_iterations_total</code> - Total test iterations</li>
</ul>
<h2 id="grafana-dashboards-2"><a class="header" href="#grafana-dashboards-2">Grafana Dashboards</a></h2>
<h3 id="official-k6-dashboard"><a class="header" href="#official-k6-dashboard">Official k6 Dashboard</a></h3>
<ul>
<li><strong>Dashboard ID</strong>: <code>19665</code></li>
<li><strong>Source</strong>: Grafana Labs official dashboard</li>
<li><strong>Features</strong>:
<ul>
<li>Request rate visualization</li>
<li>Response time percentiles (p50, p95, p99)</li>
<li>Error rate tracking</li>
<li>Virtual user count</li>
<li>Data transfer metrics</li>
</ul>
</li>
</ul>
<h3 id="custom-dashboard"><a class="header" href="#custom-dashboard">Custom Dashboard</a></h3>
<p>Custom dashboard includes:</p>
<ul>
<li>Test type filtering</li>
<li>Service-specific metrics</li>
<li>Threshold visualization</li>
<li>Historical comparison</li>
<li>Alert integration</li>
</ul>
<h2 id="running-tests"><a class="header" href="#running-tests">Running Tests</a></h2>
<h3 id="quick-test-execution"><a class="header" href="#quick-test-execution">Quick Test Execution</a></h3>
<pre><code class="language-bash"># Run smoke test
./deployment/run-test.sh smoke

# Run load test
./deployment/run-test.sh load

# Run stress test
./deployment/run-test.sh stress

# Run spike test
./deployment/run-test.sh spike
</code></pre>
<h3 id="manual-execution"><a class="header" href="#manual-execution">Manual Execution</a></h3>
<pre><code class="language-bash"># Create test job
kubectl apply -f k8s-manifest/job-load-test.yaml

# Watch logs
kubectl logs -f job/k6-load-test -n performance-testing

# Check results
kubectl get job k6-load-test -n performance-testing
</code></pre>
<h3 id="scheduled-tests"><a class="header" href="#scheduled-tests">Scheduled Tests</a></h3>
<pre><code class="language-bash"># Deploy CronJob
kubectl apply -f k8s-manifest/cronjob-scheduled-test.yaml

# View scheduled jobs
kubectl get cronjobs -n performance-testing

# View job history
kubectl get jobs -n performance-testing
</code></pre>
<h2 id="test-results-analysis"><a class="header" href="#test-results-analysis">Test Results Analysis</a></h2>
<h3 id="key-metrics-to-monitor-1"><a class="header" href="#key-metrics-to-monitor-1">Key Metrics to Monitor</a></h3>
<ol>
<li>
<p><strong>Response Times</strong></p>
<ul>
<li>p50 (median)</li>
<li>p95 (95th percentile)</li>
<li>p99 (99th percentile)</li>
</ul>
</li>
<li>
<p><strong>Error Rates</strong></p>
<ul>
<li>HTTP error rate</li>
<li>Frontend errors</li>
<li>Backend errors</li>
</ul>
</li>
<li>
<p><strong>Throughput</strong></p>
<ul>
<li>Requests per second</li>
<li>Successful requests</li>
<li>Failed requests</li>
</ul>
</li>
<li>
<p><strong>Resource Usage</strong></p>
<ul>
<li>CPU utilization</li>
<li>Memory usage</li>
<li>Network bandwidth</li>
</ul>
</li>
</ol>
<h3 id="interpreting-results"><a class="header" href="#interpreting-results">Interpreting Results</a></h3>
<p><strong>Good Performance</strong>:</p>
<pre><code>‚úì checks: 100.00%
‚úì thresholds: 100.00%
http_req_duration: p95=500ms, p99=800ms
http_req_failed: 0.00%
</code></pre>
<p><strong>Performance Issues</strong>:</p>
<pre><code>‚úó checks: 85.00%
‚úó thresholds: 60.00%
http_req_duration: p95=5000ms, p99=10000ms
http_req_failed: 15.00%
</code></pre>
<h2 id="integration-with-hpa"><a class="header" href="#integration-with-hpa">Integration with HPA</a></h2>
<h3 id="triggering-autoscaling"><a class="header" href="#triggering-autoscaling">Triggering Autoscaling</a></h3>
<p>k6 tests can trigger HPA scaling:</p>
<pre><code class="language-bash"># Run load test
./deployment/run-test.sh load

# Watch HPA scaling
kubectl get hpa -w

# Watch pod scaling
kubectl get pods -w
</code></pre>
<h3 id="validating-autoscaling"><a class="header" href="#validating-autoscaling">Validating Autoscaling</a></h3>
<ol>
<li><strong>Start Test</strong>: Run k6 load test</li>
<li><strong>Monitor Metrics</strong>: Watch CPU/memory usage</li>
<li><strong>Observe Scaling</strong>: HPA creates new pods</li>
<li><strong>Verify Performance</strong>: Response times remain stable</li>
<li><strong>Scale Down</strong>: After test, pods scale down</li>
</ol>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="1-test-design"><a class="header" href="#1-test-design">1. <strong>Test Design</strong></a></h3>
<ul>
<li>Start with smoke tests</li>
<li>Progress to load tests</li>
<li>Use stress tests for capacity planning</li>
<li>Run spike tests for autoscaling validation</li>
</ul>
<h3 id="2-thresholds"><a class="header" href="#2-thresholds">2. <strong>Thresholds</strong></a></h3>
<ul>
<li>Set realistic thresholds</li>
<li>Use percentiles (p95, p99)</li>
<li>Consider business requirements</li>
<li>Update based on baseline</li>
</ul>
<h3 id="3-test-frequency"><a class="header" href="#3-test-frequency">3. <strong>Test Frequency</strong></a></h3>
<ul>
<li>Smoke tests: After each deployment</li>
<li>Load tests: Weekly or monthly</li>
<li>Stress tests: Quarterly</li>
<li>Spike tests: Before major events</li>
</ul>
<h3 id="4-monitoring"><a class="header" href="#4-monitoring">4. <strong>Monitoring</strong></a></h3>
<ul>
<li>Export metrics to Prometheus</li>
<li>Create Grafana dashboards</li>
<li>Set up alerts</li>
<li>Track trends over time</li>
</ul>
<h3 id="5-cicd-integration"><a class="header" href="#5-cicd-integration">5. <strong>CI/CD Integration</strong></a></h3>
<ul>
<li>Run smoke tests in CI pipeline</li>
<li>Block deployments on test failures</li>
<li>Store test results</li>
<li>Generate reports</li>
</ul>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="test-failures"><a class="header" href="#test-failures">Test Failures</a></h3>
<pre><code class="language-bash"># Check job status
kubectl get job k6-load-test -n performance-testing

# View logs
kubectl logs job/k6-load-test -n performance-testing

# Check pod events
kubectl describe job k6-load-test -n performance-testing
</code></pre>
<h3 id="metrics-not-appearing"><a class="header" href="#metrics-not-appearing">Metrics Not Appearing</a></h3>
<pre><code class="language-bash"># Check StatsD exporter
kubectl get pods -n performance-testing -l app=statsd-exporter

# Check Prometheus scraping
kubectl port-forward -n monitoring svc/prometheus 9090:9090
# Access http://localhost:9090/targets

# Verify metrics
# Query: {__name__=~"k6_.*"}
</code></pre>
<h4 id="verify-statsd-exporter-is-receiving-metrics"><a class="header" href="#verify-statsd-exporter-is-receiving-metrics">Verify StatsD Exporter is Receiving Metrics</a></h4>
<p>Check if the statsd-exporter is receiving metrics from k6 by querying its metrics endpoint:</p>
<pre><code class="language-bash">kubectl exec -n performance-testing deployment/statsd-exporter -- \
  wget -qO- http://localhost:9102/metrics 2&gt;/dev/null | \
  grep -E "statsd_exporter_udp_packets_total|statsd_exporter_samples_total|^k6_http_reqs|^k6_vus"
</code></pre>
<p><strong>Expected Output</strong> (when metrics are being received):</p>
<pre><code>k6_http_reqs 237
k6_vus 1
k6_vus_max 1
# HELP statsd_exporter_samples_total The total number of StatsD samples received.
# TYPE statsd_exporter_samples_total counter
statsd_exporter_samples_total 3798
# HELP statsd_exporter_udp_packets_total The total number of StatsD packets received over UDP.
# TYPE statsd_exporter_udp_packets_total counter
statsd_exporter_udp_packets_total 270
</code></pre>
<p><strong>What to Look For</strong>:</p>
<ul>
<li><code>k6_http_reqs</code> - Should show request count (increases during test)</li>
<li><code>k6_vus</code> - Current virtual users (should match test configuration)</li>
<li><code>statsd_exporter_udp_packets_total</code> - Should increase as k6 sends metrics</li>
<li><code>statsd_exporter_samples_total</code> - Total samples received</li>
</ul>
<p><strong>If metrics are missing</strong>:</p>
<ol>
<li>Verify k6 job is running: <code>kubectl get jobs -n performance-testing</code></li>
<li>Check k6 job logs for StatsD connection errors</li>
<li>Verify <code>K6_STATSD_ADDR</code> environment variable in k6 job</li>
<li>Check network connectivity between k6 pod and statsd-exporter</li>
</ol>
<h3 id="performance-issues-during-tests"><a class="header" href="#performance-issues-during-tests">Performance Issues During Tests</a></h3>
<pre><code class="language-bash"># Check application pods
kubectl get pods -n online-boutique

# Check resource usage
kubectl top pods -n online-boutique

# Check HPA status
kubectl get hpa -n online-boutique
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform---opa-policy-enforcement"><a class="header" href="#kubernetes-gitops-platform---opa-policy-enforcement">Kubernetes GitOps Platform - OPA Policy Enforcement</a></h1>
<h2 id="what-is-opa-open-policy-agent"><a class="header" href="#what-is-opa-open-policy-agent">What is OPA (Open Policy Agent)?</a></h2>
<p>Open Policy Agent (OPA) is an open-source, general-purpose policy engine that enables unified, context-aware policy enforcement across the entire stack. In Kubernetes, OPA is implemented via Gatekeeper, which provides policy enforcement for Kubernetes resources.</p>
<h3 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h3>
<ul>
<li><strong>Policy as Code</strong>: Policies are written in Rego, a declarative language</li>
<li><strong>Admission Control</strong>: Policies are enforced at the Kubernetes API level</li>
<li><strong>Gatekeeper</strong>: Kubernetes-native implementation of OPA</li>
<li><strong>ConstraintTemplates</strong>: Define reusable policy logic</li>
<li><strong>Constraints</strong>: Apply policies to specific resources/namespaces</li>
</ul>
<h2 id="why-opa-for-kubernetes"><a class="header" href="#why-opa-for-kubernetes">Why OPA for Kubernetes?</a></h2>
<h3 id="benefits"><a class="header" href="#benefits">Benefits</a></h3>
<ol>
<li><strong>Security</strong>: Enforce security best practices automatically</li>
<li><strong>Compliance</strong>: Meet regulatory requirements (SOC 2, PCI-DSS, HIPAA)</li>
<li><strong>Governance</strong>: Ensure consistent resource configurations</li>
<li><strong>Prevention</strong>: Block bad configurations before they reach the cluster</li>
<li><strong>Audit</strong>: Track policy violations for compliance reporting</li>
</ol>
<h3 id="real-world-impact"><a class="header" href="#real-world-impact">Real-World Impact</a></h3>
<p><strong>Without OPA:</strong></p>
<ul>
<li>Developers accidentally deploy insecure configurations</li>
<li>Manual security reviews are time-consuming</li>
<li>Inconsistent security postures across teams</li>
<li>Compliance violations discovered after deployment</li>
</ul>
<p><strong>With OPA:</strong></p>
<ul>
<li>Bad configurations are blocked automatically</li>
<li>Security is enforced consistently</li>
<li>Compliance is built into the deployment process</li>
<li>Violations are caught before production</li>
</ul>
<h2 id="opa-implementation-in-kubernetes-gitops-platform"><a class="header" href="#opa-implementation-in-kubernetes-gitops-platform">OPA Implementation in Kubernetes GitOps Platform</a></h2>
<h3 id="architecture-1"><a class="header" href="#architecture-1">Architecture</a></h3>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Developer      ‚îÇ
‚îÇ  kubectl apply  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Kubernetes API  ‚îÇ
‚îÇ     Server      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OPA Gatekeeper  ‚îÇ
‚îÇ  Validates      ‚îÇ
‚îÇ  Policies       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚úÖ Allow or ‚ùå Deny
</code></pre>
<h3 id="components-1"><a class="header" href="#components-1">Components</a></h3>
<ol>
<li><strong>Gatekeeper Controller</strong>: Validates resources against policies</li>
<li><strong>ConstraintTemplates</strong>: Define policy logic in Rego</li>
<li><strong>Constraints</strong>: Apply policies to specific resources</li>
<li><strong>Audit</strong>: Continuously validates existing resources</li>
</ol>
<h2 id="implemented-policies"><a class="header" href="#implemented-policies">Implemented Policies</a></h2>
<h3 id="1-require-non-root-users"><a class="header" href="#1-require-non-root-users">1. Require Non-Root Users</a></h3>
<p><strong>Purpose</strong>: Ensures all containers run as non-root users for security compliance.</p>
<p><strong>Policy Definition</strong>:</p>
<pre><code class="language-yaml">apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: k8srequirednonroot
spec:
  crd:
    spec:
      names:
        kind: K8sRequiredNonRoot
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package k8srequirednonroot
        
        violation[{"msg": msg}] {
            container := input.review.object.spec.containers[_]
            not container.securityContext.runAsNonRoot
            not container.securityContext.runAsUser
            msg := sprintf("Container '%v' must run as non-root user", [container.name])
        }
</code></pre>
<p><strong>Enforcement</strong>:</p>
<pre><code class="language-yaml">apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredNonRoot
metadata:
  name: online-boutique-must-run-nonroot
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Pod"]
    namespaces: ["online-boutique"]
  parameters: {}
</code></pre>
<p><strong>What It Blocks</strong>:</p>
<ul>
<li>Pods without <code>securityContext.runAsNonRoot: true</code></li>
<li>Containers with <code>runAsUser: 0</code> (root)</li>
<li>Pods missing security context configuration</li>
</ul>
<h3 id="2-require-resource-limits"><a class="header" href="#2-require-resource-limits">2. Require Resource Limits</a></h3>
<p><strong>Purpose</strong>: Forces CPU and memory limits on all containers to prevent resource exhaustion.</p>
<p><strong>What It Enforces</strong>:</p>
<ul>
<li>CPU limits on all containers</li>
<li>Memory limits on all containers</li>
<li>Prevents "noisy neighbor" problems</li>
<li>Enables fair resource scheduling</li>
</ul>
<p><strong>Example Violation</strong>:</p>
<pre><code class="language-yaml"># This pod would be blocked
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: app
    image: nginx
    # Missing resources.limits
</code></pre>
<h3 id="3-disallow-latest-tags"><a class="header" href="#3-disallow-latest-tags">3. Disallow Latest Tags</a></h3>
<p><strong>Purpose</strong>: Blocks images with <code>:latest</code> tag for production stability.</p>
<p><strong>Why It Matters</strong>:</p>
<ul>
<li><code>:latest</code> tags are unpredictable</li>
<li>Can break deployments unexpectedly</li>
<li>Makes rollbacks difficult</li>
<li>Violates reproducible deployments</li>
</ul>
<p><strong>What It Blocks</strong>:</p>
<ul>
<li>Images with <code>:latest</code> tag</li>
<li>Images without explicit tags</li>
<li>Unversioned images</li>
</ul>
<h3 id="4-require-read-only-root-filesystem"><a class="header" href="#4-require-read-only-root-filesystem">4. Require Read-Only Root Filesystem</a></h3>
<p><strong>Purpose</strong>: Forces containers to use read-only root filesystem for security.</p>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Prevents malicious code from writing to filesystem</li>
<li>Immutable container principle</li>
<li>Reduces attack surface</li>
<li>Security hardening</li>
</ul>
<h3 id="5-disallow-privileged-containers"><a class="header" href="#5-disallow-privileged-containers">5. Disallow Privileged Containers</a></h3>
<p><strong>Purpose</strong>: Blocks containers with <code>privileged: true</code> for security.</p>
<p><strong>Why Critical</strong>:</p>
<ul>
<li>Privileged containers have full host access</li>
<li>Can escape container isolation</li>
<li>Major security risk</li>
<li>Should be extremely rare</li>
</ul>
<h3 id="6-require-labels"><a class="header" href="#6-require-labels">6. Require Labels</a></h3>
<p><strong>Purpose</strong>: Forces pods to have required labels for organization and monitoring.</p>
<p><strong>Required Labels</strong>:</p>
<ul>
<li><code>app</code>: Application name</li>
<li><code>team</code>: Team ownership</li>
<li><code>environment</code>: Environment (dev, staging, prod)</li>
</ul>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Cost tracking and allocation</li>
<li>Monitoring and alerting</li>
<li>Resource organization</li>
<li>Multi-tenant governance</li>
</ul>
<h2 id="enforcement-modes"><a class="header" href="#enforcement-modes">Enforcement Modes</a></h2>
<h3 id="1-enforce-mode-production"><a class="header" href="#1-enforce-mode-production">1. Enforce Mode (Production)</a></h3>
<p><strong>Behavior</strong>: Blocks violations completely</p>
<pre><code class="language-yaml">spec:
  enforcementAction: deny  # Default
</code></pre>
<p><strong>Result</strong>: Pods are rejected if they violate policies</p>
<p><strong>Use Case</strong>: Production environments where security is critical</p>
<h3 id="2-dryrun-mode-demoaudit"><a class="header" href="#2-dryrun-mode-demoaudit">2. Dryrun Mode (Demo/Audit)</a></h3>
<p><strong>Behavior</strong>: Reports violations but allows deployments</p>
<pre><code class="language-yaml">spec:
  enforcementAction: dryrun
</code></pre>
<p><strong>Result</strong>: Pods are created, violations are logged</p>
<p><strong>Use Case</strong>: Demo environments, testing, gradual rollout</p>
<h3 id="3-warn-mode-soft-enforcement"><a class="header" href="#3-warn-mode-soft-enforcement">3. Warn Mode (Soft Enforcement)</a></h3>
<p><strong>Behavior</strong>: Warnings in events but allows deployments</p>
<pre><code class="language-yaml">spec:
  enforcementAction: warn
</code></pre>
<p><strong>Result</strong>: Pods are created with warnings in Kubernetes events</p>
<p><strong>Use Case</strong>: Migration period, gradual adoption</p>
<h3 id="switching-enforcement-modes"><a class="header" href="#switching-enforcement-modes">Switching Enforcement Modes</a></h3>
<pre><code class="language-bash"># Switch to dryrun mode (non-blocking)
cd opa/deployment
./switch-enforcement-mode.sh dryrun online-boutique-must-run-nonroot

# Switch to enforce mode (blocking)
./switch-enforcement-mode.sh enforce online-boutique-must-run-nonroot

# Switch to warn mode (soft)
./switch-enforcement-mode.sh warn online-boutique-must-run-nonroot
</code></pre>
<h2 id="deployment-1"><a class="header" href="#deployment-1">Deployment</a></h2>
<h3 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h3>
<p>Gatekeeper must be installed (via Helm in <code>k8s-infrastructure-as-code</code> repo).</p>
<h3 id="deploy-all-policies"><a class="header" href="#deploy-all-policies">Deploy All Policies</a></h3>
<pre><code class="language-bash"># Deploy all OPA policies
./opa/deploy-opa-policies.sh

# Or manually with Kustomize
kubectl apply -k opa/k8s-policy-manifest/
</code></pre>
<h3 id="deployment-order"><a class="header" href="#deployment-order">Deployment Order</a></h3>
<ol>
<li><strong>Gatekeeper Installation</strong>: Via Helm (creates CRDs)</li>
<li><strong>ConstraintTemplates</strong>: Applied first (creates Constraint CRDs)</li>
<li><strong>Constraints</strong>: Applied second (may need retry if CRDs not ready)</li>
</ol>
<pre><code class="language-bash"># If constraints fail, wait and retry
sleep 10 &amp;&amp; kubectl apply -k opa/k8s-policy-manifest/
</code></pre>
<h2 id="policy-validation-flow"><a class="header" href="#policy-validation-flow">Policy Validation Flow</a></h2>
<h3 id="step-by-step-process"><a class="header" href="#step-by-step-process">Step-by-Step Process</a></h3>
<ol>
<li><strong>Developer Action</strong>: <code>kubectl apply -f pod.yaml</code></li>
<li><strong>API Server</strong>: Receives request</li>
<li><strong>Gatekeeper</strong>: Intercepts via admission webhook</li>
<li><strong>Policy Evaluation</strong>: Rego policies are evaluated</li>
<li><strong>Decision</strong>: Allow or deny based on policies</li>
<li><strong>Response</strong>: Pod created or error returned</li>
</ol>
<h3 id="example-non-root-policy"><a class="header" href="#example-non-root-policy">Example: Non-Root Policy</a></h3>
<pre><code class="language-bash"># Try to create pod as root (will be blocked)
kubectl run test-root-pod --image=nginx --restart=Never \
  -n online-boutique \
  --overrides='{"spec":{"containers":[{"name":"test","securityContext":{"runAsUser":0}}]}}'

# Error: admission webhook "validation.gatekeeper.sh" denied the request
</code></pre>
<h2 id="audit-and-compliance"><a class="header" href="#audit-and-compliance">Audit and Compliance</a></h2>
<h3 id="audit-existing-resources"><a class="header" href="#audit-existing-resources">Audit Existing Resources</a></h3>
<pre><code class="language-bash"># Audit all policies
./opa/audit-policies.sh all

# Audit specific policy
./opa/audit-policies.sh resource-limits online-boutique

# Audit all namespaces
./opa/audit-policies.sh all-namespace
</code></pre>
<h3 id="view-violations"><a class="header" href="#view-violations">View Violations</a></h3>
<pre><code class="language-bash"># Check constraint status
kubectl get K8sRequiredNonRoot online-boutique-must-run-nonroot

# View detailed violations
kubectl describe K8sRequiredNonRoot online-boutique-must-run-nonroot

# Get violation count
kubectl get K8sRequiredNonRoot online-boutique-must-run-nonroot \
  -o jsonpath='{.status.totalViolations}'
</code></pre>
<h3 id="compliance-reporting"><a class="header" href="#compliance-reporting">Compliance Reporting</a></h3>
<p>OPA provides:</p>
<ul>
<li><strong>Real-time Violations</strong>: Current policy violations</li>
<li><strong>Audit Trail</strong>: Historical violation tracking</li>
<li><strong>Compliance Status</strong>: Per-policy compliance metrics</li>
<li><strong>Resource Coverage</strong>: Percentage of resources compliant</li>
</ul>
<h2 id="integration-with-gitops"><a class="header" href="#integration-with-gitops">Integration with GitOps</a></h2>
<h3 id="argocd-integration"><a class="header" href="#argocd-integration">ArgoCD Integration</a></h3>
<p>OPA policies work seamlessly with ArgoCD:</p>
<ol>
<li><strong>Git Commit</strong>: Developer commits configuration</li>
<li><strong>ArgoCD Sync</strong>: Attempts to deploy to cluster</li>
<li><strong>OPA Validation</strong>: Gatekeeper validates resources</li>
<li><strong>Result</strong>: Deployment succeeds or fails based on policies</li>
</ol>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Bad configurations from Git are blocked</li>
<li>GitOps safety net</li>
<li>Automatic policy enforcement</li>
<li>No manual review needed</li>
</ul>
<h3 id="sync-waves-1"><a class="header" href="#sync-waves-1">Sync Waves</a></h3>
<p>OPA policies can be deployed in sync waves:</p>
<pre><code class="language-yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: opa-policies
  annotations:
    argocd.argoproj.io/sync-wave: "1"  # Deploy before applications
</code></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="policy-not-working"><a class="header" href="#policy-not-working">Policy Not Working</a></h3>
<pre><code class="language-bash"># Check Gatekeeper is running
kubectl get pods -n gatekeeper-system

# Check constraint template is installed
kubectl get constrainttemplate

# Check constraint status
kubectl get K8sRequiredNonRoot

# View Gatekeeper logs
kubectl logs -n gatekeeper-system -l control-plane=controller-manager
</code></pre>
<h3 id="policy-blocking-valid-pods"><a class="header" href="#policy-blocking-valid-pods">Policy Blocking Valid Pods</a></h3>
<pre><code class="language-bash"># Switch to dryrun mode for testing
cd opa/deployment
./switch-enforcement-mode.sh dryrun &lt;constraint-name&gt;

# Or temporarily disable constraint
kubectl delete -f opa/k8s-policy-manifest/constraint-online-boutique-nonroot.yaml
</code></pre>
<h3 id="crd-not-ready"><a class="header" href="#crd-not-ready">CRD Not Ready</a></h3>
<pre><code class="language-bash"># Wait for CRDs to be established
kubectl wait --for condition=established crd/constrainttemplates.templates.gatekeeper.sh

# Retry constraint deployment
kubectl apply -k opa/k8s-policy-manifest/
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="1-start-with-security-policies"><a class="header" href="#1-start-with-security-policies">1. Start with Security Policies</a></h3>
<ul>
<li>Non-root users</li>
<li>Read-only filesystem</li>
<li>No privileged containers</li>
</ul>
<h3 id="2-add-resource-management"><a class="header" href="#2-add-resource-management">2. Add Resource Management</a></h3>
<ul>
<li>Resource limits</li>
<li>Resource requests</li>
<li>Quotas</li>
</ul>
<h3 id="3-enforce-image-security"><a class="header" href="#3-enforce-image-security">3. Enforce Image Security</a></h3>
<ul>
<li>No latest tags</li>
<li>Approved registries</li>
<li>Image digests</li>
</ul>
<h3 id="4-use-dryrun-first"><a class="header" href="#4-use-dryrun-first">4. Use Dryrun First</a></h3>
<ul>
<li>Test policies in dryrun mode</li>
<li>Identify violations</li>
<li>Fix issues before enforcing</li>
</ul>
<h3 id="5-monitor-violations"><a class="header" href="#5-monitor-violations">5. Monitor Violations</a></h3>
<ul>
<li>Regular audit checks</li>
<li>Track violation trends</li>
<li>Update policies as needed</li>
</ul>
<h2 id="advanced-use-cases"><a class="header" href="#advanced-use-cases">Advanced Use Cases</a></h2>
<h3 id="custom-policies"><a class="header" href="#custom-policies">Custom Policies</a></h3>
<p>Create custom ConstraintTemplates for organization-specific requirements:</p>
<pre><code class="language-rego">package custompolicy

violation[{"msg": msg}] {
    # Custom policy logic
    input.review.object.spec.containers[_]
    # Your validation rules
    msg := "Custom policy violation"
}
</code></pre>
<h3 id="multi-namespace-policies"><a class="header" href="#multi-namespace-policies">Multi-Namespace Policies</a></h3>
<p>Apply policies across multiple namespaces:</p>
<pre><code class="language-yaml">spec:
  match:
    namespaces: ["production", "staging"]
</code></pre>
<h3 id="exemptions"><a class="header" href="#exemptions">Exemptions</a></h3>
<p>Exempt specific resources from policies:</p>
<pre><code class="language-yaml">spec:
  match:
    excludedNamespaces: ["kube-system", "gatekeeper-system"]
</code></pre>
<h2 id="metrics-and-monitoring"><a class="header" href="#metrics-and-monitoring">Metrics and Monitoring</a></h2>
<h3 id="gatekeeper-metrics"><a class="header" href="#gatekeeper-metrics">Gatekeeper Metrics</a></h3>
<ul>
<li>Policy evaluation count</li>
<li>Violation count</li>
<li>Admission latency</li>
<li>Audit scan duration</li>
</ul>
<h3 id="prometheus-integration-1"><a class="header" href="#prometheus-integration-1">Prometheus Integration</a></h3>
<p>Gatekeeper exposes metrics for Prometheus:</p>
<ul>
<li><code>gatekeeper_violations_total</code></li>
<li><code>gatekeeper_admission_duration_seconds</code></li>
<li><code>gatekeeper_audit_duration_seconds</code></li>
</ul>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>OPA Gatekeeper provides:</p>
<ul>
<li><strong>Automatic Security</strong>: No manual checks needed</li>
<li><strong>Consistent Enforcement</strong>: Same rules for everyone</li>
<li><strong>GitOps Safety</strong>: Bad configs from Git are blocked</li>
<li><strong>Compliance</strong>: Automatic audit trail</li>
<li><strong>Prevention</strong>: Issues caught before deployment</li>
</ul>
<p>This ensures your Kubernetes cluster maintains security and compliance standards automatically, without requiring manual intervention or review.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform---sanity-test"><a class="header" href="#kubernetes-gitops-platform---sanity-test">Kubernetes GitOps Platform - Sanity Test</a></h1>
<h2 id="what-is-sanity-test"><a class="header" href="#what-is-sanity-test">What is Sanity Test?</a></h2>
<p>Sanity Test is an automated health check application that continuously monitors the health of all microservices in the Kubernetes cluster. It performs periodic health checks and provides a real-time dashboard showing the status of each service.</p>
<h3 id="key-features-4"><a class="header" href="#key-features-4">Key Features</a></h3>
<ul>
<li><strong>Automated Health Checks</strong>: Tests all microservices every 60 seconds</li>
<li><strong>Real-time Dashboard</strong>: Web UI showing test results and service status</li>
<li><strong>Individual Service Monitoring</strong>: Tracks each microservice separately</li>
<li><strong>Response Time Metrics</strong>: Measures and displays response times</li>
<li><strong>History Tracking</strong>: Maintains last 50 test runs for trend analysis</li>
<li><strong>REST API</strong>: Programmatic access to test results</li>
</ul>
<h2 id="architecture-2"><a class="header" href="#architecture-2">Architecture</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Sanity Test    ‚îÇ
‚îÇ   Application   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Health Checks
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Online Boutique Microservices     ‚îÇ
‚îÇ  - frontend                         ‚îÇ
‚îÇ  - cartservice                      ‚îÇ
‚îÇ  - productcatalogservice            ‚îÇ
‚îÇ  - recommendationservice            ‚îÇ
‚îÇ  - currencyservice                  ‚îÇ
‚îÇ  - paymentservice (gRPC)            ‚îÇ
‚îÇ  - shippingservice (gRPC)           ‚îÇ
‚îÇ  - checkoutservice                  ‚îÇ
‚îÇ  - emailservice                     ‚îÇ
‚îÇ  - adservice                        ‚îÇ
‚îÇ  - redis-cart                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="implementation-details"><a class="header" href="#implementation-details">Implementation Details</a></h2>
<h3 id="deployment-configuration"><a class="header" href="#deployment-configuration">Deployment Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: sanity-test-app
  namespace: sanity-test
spec:
  replicas: 2  # High availability
  template:
    spec:
      containers:
      - name: sanity-test
        image: python:3.11-slim
        command: ["/bin/bash"]
        args:
          - -c
          - |
            pip install Flask Flask-CORS requests gunicorn
            python /app/app.py
        env:
        - name: NAMESPACE
          value: "online-boutique"
        - name: TEST_INTERVAL
          value: "60"  # 1 minute
        - name: TIMEOUT
          value: "5"   # 5 seconds
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 5000
        readinessProbe:
          httpGet:
            path: /api/health
            port: 5000
</code></pre>
<h3 id="health-check-logic"><a class="header" href="#health-check-logic">Health Check Logic</a></h3>
<p>The application tests each microservice by:</p>
<ol>
<li>
<p><strong>HTTP Health Endpoints</strong>: For HTTP-based services</p>
<ul>
<li>Tests <code>/health</code> or <code>/healthz</code> endpoints</li>
<li>Validates HTTP status codes (200 = healthy)</li>
<li>Measures response time</li>
</ul>
</li>
<li>
<p><strong>gRPC Health Checks</strong>: For gRPC services</p>
<ul>
<li>Uses gRPC health checking protocol</li>
<li>Tests service availability</li>
<li>Validates service responses</li>
</ul>
</li>
<li>
<p><strong>Redis Health Check</strong>: For Redis cache</p>
<ul>
<li>Tests Redis connectivity</li>
<li>Validates PING command</li>
<li>Checks response time</li>
</ul>
</li>
</ol>
<h3 id="tested-microservices"><a class="header" href="#tested-microservices">Tested Microservices</a></h3>
<h4 id="http-services"><a class="header" href="#http-services">HTTP Services</a></h4>
<ul>
<li><strong>frontend</strong>: Main web interface</li>
<li><strong>cartservice</strong>: Shopping cart management</li>
<li><strong>productcatalogservice</strong>: Product information</li>
<li><strong>recommendationservice</strong>: Product recommendations</li>
<li><strong>currencyservice</strong>: Currency conversion</li>
<li><strong>checkoutservice</strong>: Checkout process</li>
<li><strong>emailservice</strong>: Email notifications</li>
<li><strong>adservice</strong>: Advertisement service</li>
</ul>
<h4 id="grpc-services"><a class="header" href="#grpc-services">gRPC Services</a></h4>
<ul>
<li><strong>paymentservice</strong>: Payment processing (gRPC)</li>
<li><strong>shippingservice</strong>: Shipping calculations (gRPC)</li>
</ul>
<h4 id="data-stores"><a class="header" href="#data-stores">Data Stores</a></h4>
<ul>
<li><strong>redis-cart</strong>: Redis cache for cart data</li>
</ul>
<h2 id="api-endpoints"><a class="header" href="#api-endpoints">API Endpoints</a></h2>
<h3 id="dashboard-ui"><a class="header" href="#dashboard-ui">Dashboard UI</a></h3>
<pre><code>GET /
</code></pre>
<p>Returns HTML dashboard showing all test results.</p>
<h3 id="status-api"><a class="header" href="#status-api">Status API</a></h3>
<pre><code>GET /api/status
</code></pre>
<p>Returns JSON with current test status:</p>
<pre><code class="language-json">{
  "status": "passed",
  "timestamp": "2024-01-15T10:30:00Z",
  "services": {
    "frontend": {
      "status": "healthy",
      "response_time": 0.15,
      "last_check": "2024-01-15T10:30:00Z"
    },
    "cartservice": {
      "status": "healthy",
      "response_time": 0.08,
      "last_check": "2024-01-15T10:30:00Z"
    }
  },
  "summary": {
    "total": 11,
    "healthy": 11,
    "unhealthy": 0
  }
}
</code></pre>
<h3 id="manual-test-trigger"><a class="header" href="#manual-test-trigger">Manual Test Trigger</a></h3>
<pre><code>GET /api/run-test
</code></pre>
<p>Triggers an immediate test run and returns results.</p>
<h3 id="health-check"><a class="header" href="#health-check">Health Check</a></h3>
<pre><code>GET /api/health
</code></pre>
<p>Returns application health status (for Kubernetes probes).</p>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<h3 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h3>
<ul>
<li><strong>NAMESPACE</strong>: Target namespace to test (default: <code>online-boutique</code>)</li>
<li><strong>TEST_INTERVAL</strong>: Seconds between test runs (default: <code>60</code>)</li>
<li><strong>TIMEOUT</strong>: Request timeout in seconds (default: <code>5</code>)</li>
</ul>
<h3 id="service-discovery"><a class="header" href="#service-discovery">Service Discovery</a></h3>
<p>The application discovers services by:</p>
<ol>
<li>Querying Kubernetes API for services in target namespace</li>
<li>Filtering services based on labels/annotations</li>
<li>Testing each service's health endpoint</li>
</ol>
<h2 id="deployment-2"><a class="header" href="#deployment-2">Deployment</a></h2>
<h3 id="via-argocd-recommended"><a class="header" href="#via-argocd-recommended">Via ArgoCD (Recommended)</a></h3>
<pre><code class="language-bash"># Deploy via ArgoCD application
kubectl apply -f argocd/apps/sanity-test-app.yaml
</code></pre>
<h3 id="manual-deployment"><a class="header" href="#manual-deployment">Manual Deployment</a></h3>
<pre><code class="language-bash"># Create namespace
kubectl apply -f sanity-test/namespace.yaml

# Deploy application
kubectl apply -f sanity-test/deployment.yaml

# Deploy service
kubectl apply -f sanity-test/service.yaml

# Expose via LoadBalancer (optional)
kubectl apply -f sanity-test/sanity-test-ingress-alb.yaml
</code></pre>
<h2 id="access"><a class="header" href="#access">Access</a></h2>
<h3 id="loadbalancer-url"><a class="header" href="#loadbalancer-url">LoadBalancer URL</a></h3>
<pre><code class="language-bash"># Get external URL
kubectl get svc sanity-test-service -n sanity-test

# Access dashboard
http://&lt;loadbalancer-external-ip&gt;
</code></pre>
<h3 id="port-forward"><a class="header" href="#port-forward">Port Forward</a></h3>
<pre><code class="language-bash"># Port forward to local machine
kubectl port-forward -n sanity-test svc/sanity-test-service 8080:80

# Access dashboard
http://localhost:8080
</code></pre>
<h2 id="dashboard-features"><a class="header" href="#dashboard-features">Dashboard Features</a></h2>
<h3 id="real-time-status"><a class="header" href="#real-time-status">Real-time Status</a></h3>
<ul>
<li><strong>Overall Status</strong>: Pass/Fail indicator</li>
<li><strong>Service Status</strong>: Individual service health</li>
<li><strong>Response Times</strong>: Per-service response time metrics</li>
<li><strong>Last Check</strong>: Timestamp of last health check</li>
<li><strong>History</strong>: Last 50 test runs</li>
</ul>
<h3 id="visual-indicators"><a class="header" href="#visual-indicators">Visual Indicators</a></h3>
<ul>
<li><strong>Green</strong>: Service is healthy</li>
<li><strong>Red</strong>: Service is unhealthy</li>
<li><strong>Yellow</strong>: Service check in progress</li>
<li><strong>Gray</strong>: Service not tested yet</li>
</ul>
<h3 id="metrics-display"><a class="header" href="#metrics-display">Metrics Display</a></h3>
<ul>
<li>Total services tested</li>
<li>Healthy services count</li>
<li>Unhealthy services count</li>
<li>Average response time</li>
<li>Test run history</li>
</ul>
<h2 id="test-results-interpretation"><a class="header" href="#test-results-interpretation">Test Results Interpretation</a></h2>
<h3 id="pass-criteria"><a class="header" href="#pass-criteria">Pass Criteria</a></h3>
<p>A test <strong>passes</strong> if:</p>
<ul>
<li>All services return HTTP 200 status</li>
<li>All services respond within timeout</li>
<li>No connection errors occur</li>
<li>All gRPC services are reachable</li>
</ul>
<h3 id="fail-criteria"><a class="header" href="#fail-criteria">Fail Criteria</a></h3>
<p>A test <strong>fails</strong> if:</p>
<ul>
<li>Any service returns non-200 status</li>
<li>Any service times out</li>
<li>Connection errors occur</li>
<li>gRPC services are unreachable</li>
</ul>
<h3 id="example-output"><a class="header" href="#example-output">Example Output</a></h3>
<p><strong>Successful Test</strong>:</p>
<pre><code>Status: ‚úÖ PASSED
Services: 11/11 Healthy
Average Response Time: 0.12s
Last Check: 2024-01-15 10:30:00
</code></pre>
<p><strong>Failed Test</strong>:</p>
<pre><code>Status: ‚ùå FAILED
Services: 9/11 Healthy
Unhealthy: cartservice, redis-cart
Average Response Time: 0.45s
Last Check: 2024-01-15 10:30:00
</code></pre>
<h2 id="integration-with-monitoring"><a class="header" href="#integration-with-monitoring">Integration with Monitoring</a></h2>
<h3 id="prometheus-metrics-1"><a class="header" href="#prometheus-metrics-1">Prometheus Metrics</a></h3>
<p>Sanity test results can be exported to Prometheus:</p>
<ul>
<li><code>sanity_test_total</code> - Total test runs</li>
<li><code>sanity_test_passed</code> - Passed test count</li>
<li><code>sanity_test_failed</code> - Failed test count</li>
<li><code>sanity_test_service_health</code> - Per-service health (0/1)</li>
<li><code>sanity_test_response_time</code> - Per-service response time</li>
</ul>
<h3 id="grafana-dashboard"><a class="header" href="#grafana-dashboard">Grafana Dashboard</a></h3>
<p>Create dashboards showing:</p>
<ul>
<li>Test success rate over time</li>
<li>Service health trends</li>
<li>Response time percentiles</li>
<li>Service availability percentage</li>
</ul>
<h3 id="alerting-2"><a class="header" href="#alerting-2">Alerting</a></h3>
<p>Set up alerts for:</p>
<ul>
<li>Test failures</li>
<li>Service degradation</li>
<li>High response times</li>
<li>Consecutive failures</li>
</ul>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<h3 id="1-post-deployment-validation"><a class="header" href="#1-post-deployment-validation">1. Post-Deployment Validation</a></h3>
<p>After deploying new versions:</p>
<pre><code class="language-bash"># Deploy new version
kubectl apply -f new-deployment.yaml

# Check sanity test dashboard
# Verify all services are healthy
</code></pre>
<h3 id="2-continuous-monitoring"><a class="header" href="#2-continuous-monitoring">2. Continuous Monitoring</a></h3>
<p>Monitor service health continuously:</p>
<ul>
<li>Automated checks every 60 seconds</li>
<li>Real-time dashboard updates</li>
<li>Historical trend analysis</li>
</ul>
<h3 id="3-troubleshooting"><a class="header" href="#3-troubleshooting">3. Troubleshooting</a></h3>
<p>Identify problematic services:</p>
<ul>
<li>Dashboard shows which services are failing</li>
<li>Response times indicate performance issues</li>
<li>History shows when issues started</li>
</ul>
<h3 id="4-cicd-integration"><a class="header" href="#4-cicd-integration">4. CI/CD Integration</a></h3>
<p>Integrate into deployment pipelines:</p>
<pre><code class="language-yaml"># GitHub Actions example
- name: Run Sanity Test
  run: |
    kubectl port-forward -n sanity-test svc/sanity-test-service 8080:80 &amp;
    sleep 5
    curl http://localhost:8080/api/run-test
    # Verify all services are healthy
</code></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="1-high-availability"><a class="header" href="#1-high-availability">1. High Availability</a></h3>
<p>Deploy with multiple replicas:</p>
<pre><code class="language-yaml">spec:
  replicas: 2  # Ensures availability if one pod fails
</code></pre>
<h3 id="2-resource-limits"><a class="header" href="#2-resource-limits">2. Resource Limits</a></h3>
<p>Set appropriate resource limits:</p>
<pre><code class="language-yaml">resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
  limits:
    memory: "256Mi"
    cpu: "200m"
</code></pre>
<h3 id="3-health-probes"><a class="header" href="#3-health-probes">3. Health Probes</a></h3>
<p>Configure proper health checks:</p>
<pre><code class="language-yaml">livenessProbe:
  httpGet:
    path: /api/health
    port: 5000
  initialDelaySeconds: 30
  periodSeconds: 30
</code></pre>
<h3 id="4-monitoring-1"><a class="header" href="#4-monitoring-1">4. Monitoring</a></h3>
<p>Integrate with monitoring stack:</p>
<ul>
<li>Export metrics to Prometheus</li>
<li>Create Grafana dashboards</li>
<li>Set up alerts</li>
</ul>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<h3 id="application-not-starting"><a class="header" href="#application-not-starting">Application Not Starting</a></h3>
<pre><code class="language-bash"># Check pod status
kubectl get pods -n sanity-test

# View logs
kubectl logs -n sanity-test deployment/sanity-test-app

# Check events
kubectl describe pod -n sanity-test &lt;pod-name&gt;
</code></pre>
<h3 id="services-not-being-tested"><a class="header" href="#services-not-being-tested">Services Not Being Tested</a></h3>
<pre><code class="language-bash"># Verify namespace configuration
kubectl get deployment sanity-test-app -n sanity-test -o yaml | grep NAMESPACE

# Check service discovery
kubectl get svc -n online-boutique

# Verify network connectivity
kubectl exec -n sanity-test deployment/sanity-test-app -- curl http://frontend.online-boutique.svc.cluster.local/health
</code></pre>
<h3 id="dashboard-not-accessible"><a class="header" href="#dashboard-not-accessible">Dashboard Not Accessible</a></h3>
<pre><code class="language-bash"># Check service
kubectl get svc -n sanity-test

# Check port forwarding
kubectl port-forward -n sanity-test svc/sanity-test-service 8080:80

# Check LoadBalancer
kubectl get svc sanity-test-service -n sanity-test -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
</code></pre>
<h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<p>Sanity Test provides:</p>
<ul>
<li><strong>Automated Health Monitoring</strong>: Continuous service health checks</li>
<li><strong>Real-time Dashboard</strong>: Visual status of all services</li>
<li><strong>Quick Validation</strong>: Fast post-deployment verification</li>
<li><strong>Troubleshooting Aid</strong>: Identify problematic services quickly</li>
<li><strong>CI/CD Integration</strong>: Automated validation in pipelines</li>
</ul>
<p>This ensures all microservices are healthy and accessible, providing early detection of issues and maintaining system reliability.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform---availability-test"><a class="header" href="#kubernetes-gitops-platform---availability-test">Kubernetes GitOps Platform - Availability Test</a></h1>
<h2 id="what-is-availability-test"><a class="header" href="#what-is-availability-test">What is Availability Test?</a></h2>
<p>Availability Test is an SRE-style testing application that simulates real user workflows to validate end-to-end system availability. Unlike simple health checks, it tests complete user journeys and provides SRE metrics like uptime percentage, consecutive failures, and error budgets.</p>
<h3 id="key-features-5"><a class="header" href="#key-features-5">Key Features</a></h3>
<ul>
<li><strong>Real User Simulation</strong>: Tests actual user workflows (not just health endpoints)</li>
<li><strong>SRE Metrics</strong>: Calculates uptime percentage, MTTR, error budgets</li>
<li><strong>Jenkins-like Dashboard</strong>: Visual status indicators (green/red) similar to CI/CD pipelines</li>
<li><strong>Automated Testing</strong>: Runs every 5 minutes automatically</li>
<li><strong>Manual Trigger</strong>: On-demand test execution</li>
<li><strong>Consecutive Failure Tracking</strong>: Monitors continuous failures for alerting</li>
</ul>
<h2 id="architecture-3"><a class="header" href="#architecture-3">Architecture</a></h2>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Availability   ‚îÇ
‚îÇ  Test App       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Simulates User Workflow
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User Journey Simulation            ‚îÇ
‚îÇ  1. Visit Website (Frontend)        ‚îÇ
‚îÇ  2. Browse Products                 ‚îÇ
‚îÇ  3. Add Product to Cart             ‚îÇ
‚îÇ  4. Remove Product from Cart        ‚îÇ
‚îÇ  5. Verify Cart Service Health      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h2 id="test-workflow"><a class="header" href="#test-workflow">Test Workflow</a></h2>
<h3 id="complete-user-journey"><a class="header" href="#complete-user-journey">Complete User Journey</a></h3>
<p>The application simulates a real user shopping experience:</p>
<ol>
<li>
<p><strong>User Visits Website</strong></p>
<ul>
<li>Tests frontend accessibility</li>
<li>Verifies homepage loads</li>
<li>Validates HTTP 200 response</li>
</ul>
</li>
<li>
<p><strong>User Browses Products</strong></p>
<ul>
<li>Checks product catalog is accessible</li>
<li>Verifies product data is loaded</li>
<li>Validates frontend functionality</li>
</ul>
</li>
<li>
<p><strong>User Adds Product to Cart</strong></p>
<ul>
<li>Simulates adding product to cart</li>
<li>Tests cart service integration</li>
<li>Validates cart functionality</li>
</ul>
</li>
<li>
<p><strong>User Removes Product from Cart</strong></p>
<ul>
<li>Simulates removing product from cart</li>
<li>Tests cart service removal</li>
<li>Validates cart state management</li>
</ul>
</li>
<li>
<p><strong>Health Check Verification</strong></p>
<ul>
<li>Verifies cart service health endpoints</li>
<li>Validates backend service status</li>
<li>Confirms microservices integration</li>
</ul>
</li>
</ol>
<h2 id="implementation-details-1"><a class="header" href="#implementation-details-1">Implementation Details</a></h2>
<h3 id="application-structure"><a class="header" href="#application-structure">Application Structure</a></h3>
<pre><code class="language-python">class AvailabilityTester:
    """Manages availability testing"""
    
    def run_cart_services_test(self):
        """Run complete cart service test"""
        # Step 1: Frontend accessibility
        # Step 2: Product browsing
        # Step 3: Add to cart
        # Step 4: Remove from cart
        # Step 5: Health verification
</code></pre>
<h3 id="test-execution"><a class="header" href="#test-execution">Test Execution</a></h3>
<pre><code class="language-python"># Test configuration
CART_SERVICE_URL = "http://cartservice:7070"
FRONTEND_URL = "http://frontend:8080"
TEST_INTERVAL = 300  # 5 minutes

# Test execution
test_result = {
    'timestamp': datetime.now(),
    'status': 'passed' | 'failed',
    'duration': 0.0,
    'steps': [],
    'error': None
}
</code></pre>
<h3 id="sre-metrics-calculation"><a class="header" href="#sre-metrics-calculation">SRE Metrics Calculation</a></h3>
<pre><code class="language-python"># Uptime percentage
uptime_percentage = (successful_tests / total_tests) * 100

# Consecutive failures
if test_failed:
    consecutive_failures += 1
else:
    consecutive_failures = 0

# Error budget
error_budget = 100 - uptime_percentage
</code></pre>
<h2 id="deployment-configuration-1"><a class="header" href="#deployment-configuration-1">Deployment Configuration</a></h2>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: availability-test-app
  namespace: availability-test
spec:
  replicas: 2  # High availability
  template:
    spec:
      containers:
      - name: availability-test
        image: python:3.11-slim
        env:
        - name: CART_SERVICE_URL
          value: "http://cartservice.default.svc.cluster.local:7070"
        - name: FRONTEND_URL
          value: "http://frontend.default.svc.cluster.local:80"
        - name: TEST_INTERVAL
          value: "300"  # 5 minutes
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
</code></pre>
<h2 id="dashboard-features-1"><a class="header" href="#dashboard-features-1">Dashboard Features</a></h2>
<h3 id="jenkins-like-interface"><a class="header" href="#jenkins-like-interface">Jenkins-like Interface</a></h3>
<ul>
<li><strong>Build Number</strong>: Sequential test run numbers</li>
<li><strong>Status Indicators</strong>: Green (pass) / Red (fail)</li>
<li><strong>Test Details</strong>: Step-by-step test execution</li>
<li><strong>Timestamps</strong>: When each test ran</li>
<li><strong>Error Messages</strong>: Detailed failure information</li>
</ul>
<h3 id="sre-metrics-display"><a class="header" href="#sre-metrics-display">SRE Metrics Display</a></h3>
<ul>
<li><strong>Uptime Percentage</strong>: Overall system availability</li>
<li><strong>Consecutive Failures</strong>: Continuous failure count</li>
<li><strong>Test Duration</strong>: How long tests take</li>
<li><strong>Success Rate</strong>: Pass/fail ratio over time</li>
</ul>
<h3 id="real-time-updates"><a class="header" href="#real-time-updates">Real-time Updates</a></h3>
<ul>
<li>Auto-refresh every 30 seconds</li>
<li>Manual refresh button</li>
<li>On-demand test execution</li>
<li>Historical test results</li>
</ul>
<h2 id="api-endpoints-1"><a class="header" href="#api-endpoints-1">API Endpoints</a></h2>
<h3 id="dashboard"><a class="header" href="#dashboard">Dashboard</a></h3>
<pre><code>GET /
</code></pre>
<p>Returns HTML dashboard with test results.</p>
<h3 id="status-api-1"><a class="header" href="#status-api-1">Status API</a></h3>
<pre><code>GET /api/status
</code></pre>
<p>Returns current test status:</p>
<pre><code class="language-json">{
  "status": "passed",
  "uptime_percentage": 99.5,
  "consecutive_failures": 0,
  "last_test": {
    "timestamp": "2024-01-15T10:30:00Z",
    "status": "passed",
    "duration": 1.2,
    "steps": [...]
  },
  "test_history": [...]
}
</code></pre>
<h3 id="manual-test-trigger-1"><a class="header" href="#manual-test-trigger-1">Manual Test Trigger</a></h3>
<pre><code>GET /api/run-test
</code></pre>
<p>Triggers immediate test execution.</p>
<h3 id="health-check-1"><a class="header" href="#health-check-1">Health Check</a></h3>
<pre><code>GET /api/health
</code></pre>
<p>Returns application health status.</p>
<h2 id="sre-integration"><a class="header" href="#sre-integration">SRE Integration</a></h2>
<h3 id="alerting-criteria"><a class="header" href="#alerting-criteria">Alerting Criteria</a></h3>
<ul>
<li><strong>Red Status</strong>: Consecutive failures &gt; 0</li>
<li><strong>Green Status</strong>: All tests passing</li>
<li><strong>Uptime &lt; 95%</strong>: Service degradation threshold</li>
<li><strong>Consecutive Failures &gt; 3</strong>: Critical alert</li>
</ul>
<h3 id="metrics-for-prometheus"><a class="header" href="#metrics-for-prometheus">Metrics for Prometheus</a></h3>
<pre><code class="language-python"># Export metrics
uptime_gauge.set(uptime_percentage)
consecutive_failures_gauge.set(consecutive_failures)
test_duration_histogram.observe(test_duration)
test_status_gauge.set(1 if passed else 0)
</code></pre>
<h3 id="grafana-dashboard-1"><a class="header" href="#grafana-dashboard-1">Grafana Dashboard</a></h3>
<p>Create dashboards showing:</p>
<ul>
<li>Uptime percentage over time</li>
<li>Consecutive failure trends</li>
<li>Test duration percentiles</li>
<li>Success rate trends</li>
<li>Error budget consumption</li>
</ul>
<h2 id="use-cases-1"><a class="header" href="#use-cases-1">Use Cases</a></h2>
<h3 id="1-sre-monitoring"><a class="header" href="#1-sre-monitoring">1. SRE Monitoring</a></h3>
<p>Monitor system availability:</p>
<ul>
<li>Track uptime percentage</li>
<li>Monitor consecutive failures</li>
<li>Calculate error budgets</li>
<li>Set up alerting</li>
</ul>
<h3 id="2-post-deployment-validation"><a class="header" href="#2-post-deployment-validation">2. Post-Deployment Validation</a></h3>
<p>After deploying new versions:</p>
<pre><code class="language-bash"># Deploy new version
kubectl apply -f new-deployment.yaml

# Check availability test dashboard
# Verify user workflows still work
</code></pre>
<h3 id="3-performance-monitoring"><a class="header" href="#3-performance-monitoring">3. Performance Monitoring</a></h3>
<p>Track system performance:</p>
<ul>
<li>Test duration trends</li>
<li>Response time monitoring</li>
<li>Service degradation detection</li>
</ul>
<h3 id="4-incident-response"><a class="header" href="#4-incident-response">4. Incident Response</a></h3>
<p>During incidents:</p>
<ul>
<li>Check availability test status</li>
<li>Identify which steps are failing</li>
<li>Track recovery time</li>
<li>Monitor consecutive failures</li>
</ul>
<h2 id="test-cases"><a class="header" href="#test-cases">Test Cases</a></h2>
<h3 id="cart-services-test"><a class="header" href="#cart-services-test">Cart Services Test</a></h3>
<p><strong>Test Name</strong>: <code>cart_services_test</code></p>
<p><strong>Steps</strong>:</p>
<ol>
<li>Frontend accessibility check</li>
<li>Product catalog verification</li>
<li>Add product to cart simulation</li>
<li>Remove product from cart simulation</li>
<li>Cart service health verification</li>
<li>Microservices integration check</li>
</ol>
<p><strong>Success Criteria</strong>:</p>
<ul>
<li>All steps complete successfully</li>
<li>No errors in test execution</li>
<li>Response times within thresholds</li>
</ul>
<h3 id="adding-new-test-cases"><a class="header" href="#adding-new-test-cases">Adding New Test Cases</a></h3>
<ol>
<li>Create test method in <code>TestCaseManager</code>:</li>
</ol>
<pre><code class="language-python">def run_new_test_case(self):
    """Run new test case"""
    test_result = {
        'test_name': 'new_test',
        'status': 'failed',
        'steps': []
    }
    # Test logic
    return test_result
</code></pre>
<ol start="2">
<li>Register in test suite:</li>
</ol>
<pre><code class="language-python">self.test_cases = {
    'new_test': {
        'name': 'New Test Case',
        'description': 'Test description',
        'enabled': True
    }
}
</code></pre>
<ol start="3">
<li>Update dashboard template to display results</li>
</ol>
<h2 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h2>
<h3 id="environment-variables-2"><a class="header" href="#environment-variables-2">Environment Variables</a></h3>
<ul>
<li><strong>CART_SERVICE_URL</strong>: Cart service endpoint (default: <code>http://cartservice:7070</code>)</li>
<li><strong>FRONTEND_URL</strong>: Frontend service endpoint (default: <code>http://frontend:8080</code>)</li>
<li><strong>TEST_INTERVAL</strong>: Test execution interval in seconds (default: <code>300</code> = 5 minutes)</li>
</ul>
<h3 id="kubernetes-resources"><a class="header" href="#kubernetes-resources">Kubernetes Resources</a></h3>
<ul>
<li><strong>Namespace</strong>: <code>availability-test</code></li>
<li><strong>Deployment</strong>: 2 replicas for high availability</li>
<li><strong>Service</strong>: ClusterIP for internal communication</li>
<li><strong>LoadBalancer</strong>: External access via AWS ELB</li>
<li><strong>Ingress</strong>: ALB configuration for custom domain</li>
</ul>
<h2 id="deployment-3"><a class="header" href="#deployment-3">Deployment</a></h2>
<h3 id="via-argocd-recommended-1"><a class="header" href="#via-argocd-recommended-1">Via ArgoCD (Recommended)</a></h3>
<pre><code class="language-bash"># Deploy via ArgoCD application
kubectl apply -f argocd/apps/availability-test-app.yaml
</code></pre>
<h3 id="manual-deployment-1"><a class="header" href="#manual-deployment-1">Manual Deployment</a></h3>
<pre><code class="language-bash"># Create namespace
kubectl apply -f availability-test/namespace.yaml

# Deploy application
kubectl apply -f availability-test/deployment.yaml

# Expose via LoadBalancer
kubectl apply -f availability-test/loadbalancer.yaml
</code></pre>
<h2 id="access-1"><a class="header" href="#access-1">Access</a></h2>
<h3 id="loadbalancer-url-1"><a class="header" href="#loadbalancer-url-1">LoadBalancer URL</a></h3>
<pre><code class="language-bash"># Get external URL
kubectl get svc availability-test-loadbalancer -n availability-test

# Access dashboard
http://&lt;loadbalancer-external-ip&gt;
</code></pre>
<h3 id="port-forward-1"><a class="header" href="#port-forward-1">Port Forward</a></h3>
<pre><code class="language-bash"># Port forward to local machine
kubectl port-forward -n availability-test svc/availability-test-service 8080:80

# Access dashboard
http://localhost:8080
</code></pre>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="test-failures-1"><a class="header" href="#test-failures-1">Test Failures</a></h3>
<pre><code class="language-bash"># Check application logs
kubectl logs -f deployment/availability-test-app -n availability-test

# Check pod status
kubectl get pods -n availability-test

# Check service connectivity
kubectl exec -n availability-test deployment/availability-test-app -- \
  curl http://frontend.default.svc.cluster.local
</code></pre>
<h3 id="service-unreachable"><a class="header" href="#service-unreachable">Service Unreachable</a></h3>
<pre><code class="language-bash"># Verify services are running
kubectl get pods -n default -l app=frontend
kubectl get pods -n default -l app=cartservice

# Check service endpoints
kubectl get endpoints -n default

# Test connectivity
kubectl run -it --rm debug --image=busybox --restart=Never -- \
  wget -O- http://frontend.default.svc.cluster.local
</code></pre>
<h3 id="dashboard-not-loading"><a class="header" href="#dashboard-not-loading">Dashboard Not Loading</a></h3>
<pre><code class="language-bash"># Check service
kubectl get svc -n availability-test

# Check LoadBalancer
kubectl get svc availability-test-loadbalancer -n availability-test

# Check ingress
kubectl get ingress -n availability-test
</code></pre>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<h3 id="1-test-frequency"><a class="header" href="#1-test-frequency">1. Test Frequency</a></h3>
<ul>
<li><strong>Production</strong>: Every 5 minutes (default)</li>
<li><strong>Staging</strong>: Every 10 minutes</li>
<li><strong>Development</strong>: Every 15 minutes</li>
</ul>
<h3 id="2-alerting-thresholds"><a class="header" href="#2-alerting-thresholds">2. Alerting Thresholds</a></h3>
<ul>
<li><strong>Critical</strong>: Consecutive failures &gt; 3</li>
<li><strong>Warning</strong>: Consecutive failures &gt; 1</li>
<li><strong>Info</strong>: Uptime &lt; 99%</li>
</ul>
<h3 id="3-high-availability"><a class="header" href="#3-high-availability">3. High Availability</a></h3>
<p>Deploy with multiple replicas:</p>
<pre><code class="language-yaml">spec:
  replicas: 2  # Ensures availability if one pod fails
</code></pre>
<h3 id="4-resource-limits"><a class="header" href="#4-resource-limits">4. Resource Limits</a></h3>
<p>Set appropriate resource limits:</p>
<pre><code class="language-yaml">resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
  limits:
    memory: "256Mi"
    cpu: "200m"
</code></pre>
<h2 id="summary-2"><a class="header" href="#summary-2">Summary</a></h2>
<p>Availability Test provides:</p>
<ul>
<li><strong>Real User Simulation</strong>: Tests actual workflows, not just health endpoints</li>
<li><strong>SRE Metrics</strong>: Uptime percentage, consecutive failures, error budgets</li>
<li><strong>Visual Dashboard</strong>: Jenkins-like interface for quick status checks</li>
<li><strong>Automated Monitoring</strong>: Continuous availability validation</li>
<li><strong>Incident Detection</strong>: Early warning of service issues</li>
</ul>
<p>This ensures your system maintains high availability and provides early detection of issues that affect real users.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform---argocd-gitops"><a class="header" href="#kubernetes-gitops-platform---argocd-gitops">Kubernetes GitOps Platform - ArgoCD GitOps</a></h1>
<h2 id="what-is-argocd"><a class="header" href="#what-is-argocd">What is ArgoCD?</a></h2>
<p>ArgoCD is a declarative, GitOps continuous delivery tool for Kubernetes. It automates the deployment of applications to Kubernetes clusters by continuously monitoring Git repositories and automatically syncing the desired state defined in Git with the actual state in the cluster.</p>
<h3 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h3>
<ul>
<li><strong>GitOps</strong>: Git as the single source of truth</li>
<li><strong>Declarative</strong>: Define desired state, ArgoCD makes it happen</li>
<li><strong>Continuous Sync</strong>: Automatically detects and applies changes</li>
<li><strong>Self-Healing</strong>: Automatically corrects drift from desired state</li>
<li><strong>Multi-Environment</strong>: Manage multiple clusters and environments</li>
</ul>
<h2 id="why-argocd-for-kubernetes"><a class="header" href="#why-argocd-for-kubernetes">Why ArgoCD for Kubernetes?</a></h2>
<h3 id="benefits-1"><a class="header" href="#benefits-1">Benefits</a></h3>
<ol>
<li><strong>Automation</strong>: Automatic deployment from Git</li>
<li><strong>Consistency</strong>: Same process for all applications</li>
<li><strong>Audit Trail</strong>: All changes tracked in Git</li>
<li><strong>Rollback</strong>: Easy rollback via Git revert</li>
<li><strong>Multi-Cluster</strong>: Manage multiple clusters from one place</li>
<li><strong>RBAC</strong>: Fine-grained access control</li>
<li><strong>UI &amp; CLI</strong>: Both web interface and command-line tools</li>
</ol>
<h3 id="gitops-principles"><a class="header" href="#gitops-principles">GitOps Principles</a></h3>
<ol>
<li><strong>Git as Source of Truth</strong>: All configurations in Git</li>
<li><strong>Declarative Descriptions</strong>: Define what you want, not how</li>
<li><strong>Automated Sync</strong>: Changes automatically applied</li>
<li><strong>Reconciliation</strong>: Continuous state verification</li>
<li><strong>Observability</strong>: Full visibility into deployments</li>
</ol>
<h2 id="argocd-implementation-in-kubernetes-gitops-platform"><a class="header" href="#argocd-implementation-in-kubernetes-gitops-platform">ArgoCD Implementation in Kubernetes GitOps Platform</a></h2>
<h3 id="architecture-4"><a class="header" href="#architecture-4">Architecture</a></h3>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Git Repository ‚îÇ
‚îÇ  (Source of     ‚îÇ
‚îÇ   Truth)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Monitors
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ArgoCD        ‚îÇ
‚îÇ   Controller    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Syncs
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Kubernetes     ‚îÇ
‚îÇ  Cluster        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<h3 id="components-2"><a class="header" href="#components-2">Components</a></h3>
<ol>
<li><strong>ArgoCD Server</strong>: API server and UI</li>
<li><strong>Application Controller</strong>: Syncs applications</li>
<li><strong>Repo Server</strong>: Clones and caches Git repositories</li>
<li><strong>Redis</strong>: Caching and session storage</li>
</ol>
<h2 id="app-of-apps-pattern-2"><a class="header" href="#app-of-apps-pattern-2">App-of-Apps Pattern</a></h2>
<h3 id="what-is-app-of-apps"><a class="header" href="#what-is-app-of-apps">What is App-of-Apps?</a></h3>
<p>App-of-Apps is an ArgoCD pattern where a root application manages multiple child applications. This provides centralized management and consistent deployment patterns.</p>
<h3 id="implementation"><a class="header" href="#implementation">Implementation</a></h3>
<pre><code class="language-yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: k8s-platform-toolkit
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/Lforlinux/k8s-platform-toolkit.git
    targetRevision: HEAD
    path: argocd/apps
    directory:
      recurse: true  # Discovers all applications
  destination:
    server: https://kubernetes.default.svc
    namespace: argocd
  syncPolicy:
    automated:
      prune: true      # Remove resources not in Git
      selfHeal: true   # Auto-correct drift
    syncOptions:
      - CreateNamespace=true
</code></pre>
<h3 id="benefits-2"><a class="header" href="#benefits-2">Benefits</a></h3>
<ul>
<li><strong>Centralized Management</strong>: Single point of control</li>
<li><strong>Automatic Discovery</strong>: Discovers all applications recursively</li>
<li><strong>Consistent Patterns</strong>: Same deployment approach for all apps</li>
<li><strong>Easy Scaling</strong>: Add new apps by adding files to Git</li>
</ul>
<h2 id="application-definitions"><a class="header" href="#application-definitions">Application Definitions</a></h2>
<h3 id="monitoring-stack-application"><a class="header" href="#monitoring-stack-application">Monitoring Stack Application</a></h3>
<pre><code class="language-yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: monitoring-stack
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "3"  # Deploy in wave 3
spec:
  project: default
  source:
    repoURL: https://github.com/Lforlinux/k8s-platform-toolkit.git
    path: monitoring
    targetRevision: HEAD
  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
</code></pre>
<h3 id="sync-waves-2"><a class="header" href="#sync-waves-2">Sync Waves</a></h3>
<p>Sync waves control deployment order:</p>
<pre><code class="language-yaml">annotations:
  argocd.argoproj.io/sync-wave: "1"  # Deploy first
  argocd.argoproj.io/sync-wave: "2"  # Deploy second
  argocd.argoproj.io/sync-wave: "3"  # Deploy third
</code></pre>
<p><strong>Typical Order</strong>:</p>
<ol>
<li><strong>Wave 1</strong>: Testing infrastructure (sanity-test, availability-test)</li>
<li><strong>Wave 2</strong>: Demo applications (online-boutique)</li>
<li><strong>Wave 3</strong>: Monitoring stack (Prometheus, Grafana)</li>
<li><strong>Wave 4</strong>: Logging stack (Loki)</li>
<li><strong>Wave 5</strong>: Log collection (Promtail)</li>
</ol>
<h2 id="deployment-workflow-1"><a class="header" href="#deployment-workflow-1">Deployment Workflow</a></h2>
<h3 id="gitops-flow-1"><a class="header" href="#gitops-flow-1">GitOps Flow</a></h3>
<ol>
<li><strong>Developer</strong>: Makes changes in Git repository</li>
<li><strong>Commit &amp; Push</strong>: Changes pushed to main branch</li>
<li><strong>ArgoCD Detection</strong>: ArgoCD detects changes automatically</li>
<li><strong>Sync</strong>: Applications sync with desired state</li>
<li><strong>Verification</strong>: Health checks validate deployment</li>
<li><strong>Monitoring</strong>: Continuous state reconciliation</li>
</ol>
<h3 id="automated-sync"><a class="header" href="#automated-sync">Automated Sync</a></h3>
<pre><code class="language-yaml">syncPolicy:
  automated:
    prune: true      # Delete resources not in Git
    selfHeal: true   # Auto-correct manual changes
</code></pre>
<p><strong>What It Does</strong>:</p>
<ul>
<li><strong>Prune</strong>: Removes resources deleted from Git</li>
<li><strong>Self-Heal</strong>: Reverts manual changes to match Git</li>
<li><strong>Auto-Sync</strong>: Automatically syncs on Git changes</li>
</ul>
<h3 id="manual-sync"><a class="header" href="#manual-sync">Manual Sync</a></h3>
<pre><code class="language-bash"># Sync specific application
argocd app sync monitoring-stack

# Sync all applications
argocd app sync --all

# Force refresh
argocd app get monitoring-stack --refresh
</code></pre>
<h2 id="application-management"><a class="header" href="#application-management">Application Management</a></h2>
<h3 id="list-applications"><a class="header" href="#list-applications">List Applications</a></h3>
<pre><code class="language-bash"># List all applications
argocd app list

# Get application details
argocd app get monitoring-stack

# View application status
argocd app get monitoring-stack --refresh
</code></pre>
<h3 id="application-status"><a class="header" href="#application-status">Application Status</a></h3>
<p><strong>Healthy</strong>: Application is synced and all resources are healthy
<strong>Syncing</strong>: Application is currently syncing
<strong>OutOfSync</strong>: Git and cluster states differ
<strong>Unknown</strong>: Status cannot be determined
<strong>Degraded</strong>: Some resources are unhealthy</p>
<h3 id="viewing-resources"><a class="header" href="#viewing-resources">Viewing Resources</a></h3>
<pre><code class="language-bash"># View application resources
argocd app resources monitoring-stack

# View application logs
argocd app logs monitoring-stack

# View application events
argocd app events monitoring-stack
</code></pre>
<h2 id="access-and-authentication"><a class="header" href="#access-and-authentication">Access and Authentication</a></h2>
<h3 id="initial-setup"><a class="header" href="#initial-setup">Initial Setup</a></h3>
<pre><code class="language-bash"># Get admin password
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d

# Port forward to access UI
kubectl port-forward -n argocd svc/argocd-server 8080:443

# Access UI
https://localhost:8080
</code></pre>
<h3 id="login"><a class="header" href="#login">Login</a></h3>
<pre><code class="language-bash"># CLI login
argocd login localhost:8080

# Or with username/password
argocd login localhost:8080 --username admin --password &lt;password&gt;
</code></pre>
<h3 id="rbac-configuration-1"><a class="header" href="#rbac-configuration-1">RBAC Configuration</a></h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-rbac-cm
  namespace: argocd
data:
  policy.default: role:readonly
  policy.csv: |
    p, role:admin, applications, *, */*, allow
    p, role:admin, clusters, get, *, allow
    g, admins, role:admin
</code></pre>
<h2 id="sync-strategies"><a class="header" href="#sync-strategies">Sync Strategies</a></h2>
<h3 id="automatic-sync"><a class="header" href="#automatic-sync">Automatic Sync</a></h3>
<pre><code class="language-yaml">syncPolicy:
  automated:
    prune: true
    selfHeal: true
</code></pre>
<p><strong>When It Syncs</strong>:</p>
<ul>
<li>Git repository changes detected</li>
<li>Manual sync triggered</li>
<li>Self-healing corrections</li>
</ul>
<h3 id="manual-sync-1"><a class="header" href="#manual-sync-1">Manual Sync</a></h3>
<pre><code class="language-yaml">syncPolicy:
  automated: {}  # Disabled
</code></pre>
<p><strong>When It Syncs</strong>:</p>
<ul>
<li>Manual sync via UI or CLI</li>
<li>Scheduled sync (if configured)</li>
</ul>
<h3 id="sync-options"><a class="header" href="#sync-options">Sync Options</a></h3>
<pre><code class="language-yaml">syncOptions:
  - CreateNamespace=true      # Auto-create namespaces
  - PrunePropagationPolicy=foreground
  - PruneLast=true            # Prune after sync
  - ApplyOutOfSyncOnly=true   # Only sync out-of-sync resources
</code></pre>
<h2 id="rollback-and-history"><a class="header" href="#rollback-and-history">Rollback and History</a></h2>
<h3 id="view-history"><a class="header" href="#view-history">View History</a></h3>
<pre><code class="language-bash"># View application history
argocd app history monitoring-stack

# View specific revision
argocd app get monitoring-stack --revision &lt;revision&gt;
</code></pre>
<h3 id="rollback"><a class="header" href="#rollback">Rollback</a></h3>
<pre><code class="language-bash"># Rollback to previous version
argocd app rollback monitoring-stack

# Rollback to specific revision
argocd app rollback monitoring-stack &lt;revision&gt;
</code></pre>
<h3 id="git-revert"><a class="header" href="#git-revert">Git Revert</a></h3>
<pre><code class="language-bash"># Revert in Git (recommended)
git revert &lt;commit-hash&gt;
git push origin main

# ArgoCD automatically syncs
</code></pre>
<h2 id="multi-environment-management"><a class="header" href="#multi-environment-management">Multi-Environment Management</a></h2>
<h3 id="environment-specific-applications"><a class="header" href="#environment-specific-applications">Environment-Specific Applications</a></h3>
<pre><code class="language-yaml"># Production
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: monitoring-stack-prod
spec:
  source:
    path: monitoring
    targetRevision: main
  destination:
    server: https://prod-cluster.example.com
    namespace: monitoring

# Staging
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: monitoring-stack-staging
spec:
  source:
    path: monitoring
    targetRevision: develop
  destination:
    server: https://staging-cluster.example.com
    namespace: monitoring
</code></pre>
<h2 id="integration-with-cicd"><a class="header" href="#integration-with-cicd">Integration with CI/CD</a></h2>
<h3 id="github-actions-integration"><a class="header" href="#github-actions-integration">GitHub Actions Integration</a></h3>
<pre><code class="language-yaml"># .github/workflows/deploy.yml
- name: Deploy to ArgoCD
  run: |
    argocd app sync monitoring-stack
    argocd app wait monitoring-stack --health
</code></pre>
<h3 id="webhook-integration"><a class="header" href="#webhook-integration">Webhook Integration</a></h3>
<p>Configure Git webhooks for faster sync:</p>
<ul>
<li>GitHub webhooks</li>
<li>GitLab webhooks</li>
<li>Bitbucket webhooks</li>
</ul>
<h2 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h2>
<h3 id="application-not-syncing"><a class="header" href="#application-not-syncing">Application Not Syncing</a></h3>
<pre><code class="language-bash"># Check application status
argocd app get &lt;app-name&gt;

# Check for sync errors
argocd app get &lt;app-name&gt; --refresh

# View application logs
argocd app logs &lt;app-name&gt;

# Check repository connectivity
argocd repo list
</code></pre>
<h3 id="sync-failures"><a class="header" href="#sync-failures">Sync Failures</a></h3>
<pre><code class="language-bash"># View sync operation details
argocd app get &lt;app-name&gt; --refresh

# Check resource events
kubectl get events -n &lt;namespace&gt;

# View ArgoCD server logs
kubectl logs -n argocd deployment/argocd-server
</code></pre>
<h3 id="repository-access-issues"><a class="header" href="#repository-access-issues">Repository Access Issues</a></h3>
<pre><code class="language-bash"># List repositories
argocd repo list

# Add repository
argocd repo add https://github.com/user/repo.git

# Test repository access
argocd repo get https://github.com/user/repo.git
</code></pre>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<h3 id="1-use-app-of-apps-pattern"><a class="header" href="#1-use-app-of-apps-pattern">1. Use App-of-Apps Pattern</a></h3>
<p>Centralize application management:</p>
<ul>
<li>Single root application</li>
<li>Recursive application discovery</li>
<li>Consistent deployment patterns</li>
</ul>
<h3 id="2-enable-automated-sync"><a class="header" href="#2-enable-automated-sync">2. Enable Automated Sync</a></h3>
<p>For most applications:</p>
<pre><code class="language-yaml">syncPolicy:
  automated:
    prune: true
    selfHeal: true
</code></pre>
<h3 id="3-use-sync-waves"><a class="header" href="#3-use-sync-waves">3. Use Sync Waves</a></h3>
<p>Control deployment order:</p>
<pre><code class="language-yaml">annotations:
  argocd.argoproj.io/sync-wave: "1"
</code></pre>
<h3 id="4-implement-rbac"><a class="header" href="#4-implement-rbac">4. Implement RBAC</a></h3>
<p>Control access:</p>
<ul>
<li>Read-only for most users</li>
<li>Admin for operators</li>
<li>Project-based access control</li>
</ul>
<h3 id="5-monitor-applications"><a class="header" href="#5-monitor-applications">5. Monitor Applications</a></h3>
<p>Set up monitoring:</p>
<ul>
<li>Application health metrics</li>
<li>Sync status alerts</li>
<li>Failure notifications</li>
</ul>
<h2 id="summary-3"><a class="header" href="#summary-3">Summary</a></h2>
<p>ArgoCD provides:</p>
<ul>
<li><strong>GitOps Automation</strong>: Automatic deployment from Git</li>
<li><strong>Self-Healing</strong>: Auto-corrects drift from desired state</li>
<li><strong>Multi-Environment</strong>: Manage multiple clusters</li>
<li><strong>Audit Trail</strong>: All changes tracked in Git</li>
<li><strong>Easy Rollback</strong>: Simple rollback via Git revert</li>
<li><strong>UI &amp; CLI</strong>: Both web interface and command-line tools</li>
</ul>
<p>This ensures your Kubernetes applications are always in sync with Git, providing a reliable and auditable deployment process.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-troubleshooting"><a class="header" href="#kubernetes-gitops-platform-troubleshooting">Kubernetes GitOps Platform Troubleshooting</a></h1>
<h2 id="cluster-access-issues"><a class="header" href="#cluster-access-issues">Cluster Access Issues</a></h2>
<h3 id="verify-aws-credentials"><a class="header" href="#verify-aws-credentials">Verify AWS Credentials</a></h3>
<pre><code class="language-bash"># Check AWS identity
aws sts get-caller-identity

# Verify credentials
aws configure list

# Test EKS access
aws eks list-clusters --region us-east-1
</code></pre>
<h3 id="update-kubeconfig"><a class="header" href="#update-kubeconfig">Update Kubeconfig</a></h3>
<pre><code class="language-bash"># Get cluster details from Terraform
terraform output cluster_name
terraform output region

# Update kubeconfig
aws eks --region $(terraform output -raw region) \
  update-kubeconfig --name $(terraform output -raw cluster_name)

# Verify access
kubectl get nodes
</code></pre>
<h3 id="common-issues-1"><a class="header" href="#common-issues-1">Common Issues</a></h3>
<ul>
<li><strong>Invalid credentials</strong>: Check AWS credentials configuration</li>
<li><strong>Wrong region</strong>: Verify cluster region matches</li>
<li><strong>Network issues</strong>: Check VPC and security groups</li>
<li><strong>IAM permissions</strong>: Verify required IAM policies</li>
</ul>
<h2 id="argocd-issues"><a class="header" href="#argocd-issues">ArgoCD Issues</a></h2>
<h3 id="argocd-not-accessible"><a class="header" href="#argocd-not-accessible">ArgoCD Not Accessible</a></h3>
<pre><code class="language-bash"># Check ArgoCD server status
kubectl get svc -n argocd argocd-server

# Get LoadBalancer URL
kubectl get svc -n argocd argocd-server -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'

# Check ArgoCD pods
kubectl get pods -n argocd

# View ArgoCD logs
kubectl logs -n argocd deployment/argocd-server
</code></pre>
<h3 id="get-argocd-password"><a class="header" href="#get-argocd-password">Get ArgoCD Password</a></h3>
<pre><code class="language-bash"># Get admin password
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d

# Or use argocd CLI
argocd admin initial-password -n argocd
</code></pre>
<h3 id="application-sync-issues"><a class="header" href="#application-sync-issues">Application Sync Issues</a></h3>
<pre><code class="language-bash"># List all applications
kubectl get applications -n argocd

# Describe application
kubectl describe application &lt;app-name&gt; -n argocd

# Check sync status
argocd app get &lt;app-name&gt;

# Manual sync
argocd app sync &lt;app-name&gt;

# Force refresh
argocd app get &lt;app-name&gt; --refresh
</code></pre>
<h3 id="common-argocd-issues"><a class="header" href="#common-argocd-issues">Common ArgoCD Issues</a></h3>
<ul>
<li><strong>Repository access</strong>: Check repository credentials</li>
<li><strong>Sync failures</strong>: Review application manifests</li>
<li><strong>Health status</strong>: Check pod and service status</li>
<li><strong>Permission errors</strong>: Verify RBAC configuration</li>
</ul>
<h2 id="pod-issues"><a class="header" href="#pod-issues">Pod Issues</a></h2>
<h3 id="pod-not-starting"><a class="header" href="#pod-not-starting">Pod Not Starting</a></h3>
<pre><code class="language-bash"># Check pod status
kubectl get pods -n &lt;namespace&gt;

# Describe pod
kubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;

# View pod logs
kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;

# Check events
kubectl get events -n &lt;namespace&gt; --sort-by='.lastTimestamp'
</code></pre>
<h3 id="common-pod-issues"><a class="header" href="#common-pod-issues">Common Pod Issues</a></h3>
<ul>
<li><strong>ImagePullBackOff</strong>: Check image name and registry access</li>
<li><strong>CrashLoopBackOff</strong>: Check application logs and configuration</li>
<li><strong>Pending</strong>: Check resource availability and node capacity</li>
<li><strong>Error</strong>: Review container logs and health checks</li>
</ul>
<h3 id="resource-issues"><a class="header" href="#resource-issues">Resource Issues</a></h3>
<pre><code class="language-bash"># Check node resources
kubectl top nodes

# Check pod resources
kubectl top pods -n &lt;namespace&gt;

# Check resource requests/limits
kubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt; | grep -A 5 "Limits\|Requests"
</code></pre>
<h2 id="service-issues"><a class="header" href="#service-issues">Service Issues</a></h2>
<h3 id="service-not-accessible"><a class="header" href="#service-not-accessible">Service Not Accessible</a></h3>
<pre><code class="language-bash"># Check service status
kubectl get svc -n &lt;namespace&gt;

# Describe service
kubectl describe svc &lt;service-name&gt; -n &lt;namespace&gt;

# Check endpoints
kubectl get endpoints &lt;service-name&gt; -n &lt;namespace&gt;

# Test service from pod
kubectl run -it --rm debug --image=busybox --restart=Never -- \
  wget -O- http://&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local
</code></pre>
<h3 id="loadbalancer-issues"><a class="header" href="#loadbalancer-issues">LoadBalancer Issues</a></h3>
<pre><code class="language-bash"># Check LoadBalancer status
kubectl get svc -n &lt;namespace&gt; &lt;service-name&gt;

# Check AWS ELB
aws elbv2 describe-load-balancers --region us-east-1

# Check target health
aws elbv2 describe-target-health \
  --target-group-arn &lt;target-group-arn&gt; \
  --region us-east-1
</code></pre>
<h2 id="network-issues"><a class="header" href="#network-issues">Network Issues</a></h2>
<h3 id="dns-resolution"><a class="header" href="#dns-resolution">DNS Resolution</a></h3>
<pre><code class="language-bash"># Test DNS from pod
kubectl run -it --rm debug --image=busybox --restart=Never -- \
  nslookup &lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local

# Check CoreDNS
kubectl get pods -n kube-system -l k8s-app=kube-dns

# Check CoreDNS logs
kubectl logs -n kube-system -l k8s-app=kube-dns
</code></pre>
<h3 id="network-policies-1"><a class="header" href="#network-policies-1">Network Policies</a></h3>
<pre><code class="language-bash"># List network policies
kubectl get networkpolicies -n &lt;namespace&gt;

# Describe network policy
kubectl describe networkpolicy &lt;policy-name&gt; -n &lt;namespace&gt;

# Temporarily disable for testing
kubectl delete networkpolicy &lt;policy-name&gt; -n &lt;namespace&gt;
</code></pre>
<h2 id="monitoring-issues"><a class="header" href="#monitoring-issues">Monitoring Issues</a></h2>
<h3 id="prometheus-not-scraping"><a class="header" href="#prometheus-not-scraping">Prometheus Not Scraping</a></h3>
<pre><code class="language-bash"># Check Prometheus targets
# Access Prometheus UI and check /targets endpoint

# Check service discovery
kubectl get pods -n monitoring -l app=prometheus
kubectl logs -n monitoring -l app=prometheus

# Verify service annotations
kubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt; -o yaml | grep prometheus.io
</code></pre>
<h3 id="grafana-not-loading-dashboards"><a class="header" href="#grafana-not-loading-dashboards">Grafana Not Loading Dashboards</a></h3>
<pre><code class="language-bash"># Check Grafana pods
kubectl get pods -n monitoring -l app=grafana

# Check Grafana logs
kubectl logs -n monitoring -l app=grafana

# Verify data source
# Access Grafana UI and check data source configuration
</code></pre>
<h2 id="application-specific-issues"><a class="header" href="#application-specific-issues">Application-Specific Issues</a></h2>
<h3 id="online-boutique-issues"><a class="header" href="#online-boutique-issues">Online Boutique Issues</a></h3>
<pre><code class="language-bash"># Check all microservices
kubectl get pods -n online-boutique

# Check specific service
kubectl logs -n online-boutique deployment/&lt;service-name&gt;

# Test service connectivity
kubectl exec -it -n online-boutique &lt;pod-name&gt; -- curl http://&lt;service-name&gt;:&lt;port&gt;
</code></pre>
<h3 id="sanity-test-issues"><a class="header" href="#sanity-test-issues">Sanity Test Issues</a></h3>
<pre><code class="language-bash"># Check sanity test status
kubectl get pods -n sanity-test

# View test results
kubectl logs -n sanity-test deployment/sanity-test

# Access dashboard
kubectl get svc -n sanity-test sanity-test-loadbalancer
</code></pre>
<h3 id="availability-test-issues"><a class="header" href="#availability-test-issues">Availability Test Issues</a></h3>
<pre><code class="language-bash"># Check availability test
kubectl get pods -n availability-test

# View test logs
kubectl logs -n availability-test deployment/availability-test

# Check test results
curl http://&lt;availability-test-lb-url&gt;/api/status
</code></pre>
<h2 id="terraform-issues"><a class="header" href="#terraform-issues">Terraform Issues</a></h2>
<h3 id="state-lock"><a class="header" href="#state-lock">State Lock</a></h3>
<pre><code class="language-bash"># Check for state lock
terraform force-unlock &lt;lock-id&gt;

# Or remove lock manually
aws dynamodb delete-item \
  --table-name terraform-state-lock \
  --key '{"LockID":{"S":"&lt;lock-id&gt;"}}'
</code></pre>
<h3 id="state-issues"><a class="header" href="#state-issues">State Issues</a></h3>
<pre><code class="language-bash"># Refresh state
terraform refresh

# Import existing resource
terraform import &lt;resource&gt; &lt;resource-id&gt;

# Validate configuration
terraform validate

# Format code
terraform fmt
</code></pre>
<h3 id="deployment-failures"><a class="header" href="#deployment-failures">Deployment Failures</a></h3>
<pre><code class="language-bash"># Check Terraform logs
terraform apply -no-color 2&gt;&amp;1 | tee terraform.log

# Review plan
terraform plan -detailed-exitcode

# Destroy and recreate
terraform destroy
terraform apply
</code></pre>
<h2 id="performance-issues-1"><a class="header" href="#performance-issues-1">Performance Issues</a></h2>
<h3 id="slow-pod-startup"><a class="header" href="#slow-pod-startup">Slow Pod Startup</a></h3>
<pre><code class="language-bash"># Check node resources
kubectl describe node &lt;node-name&gt;

# Check pod scheduling
kubectl get events --field-selector involvedObject.name=&lt;pod-name&gt;

# Check image pull time
kubectl describe pod &lt;pod-name&gt; | grep -A 5 "Events"
</code></pre>
<h3 id="high-resource-usage"><a class="header" href="#high-resource-usage">High Resource Usage</a></h3>
<pre><code class="language-bash"># Check resource usage
kubectl top nodes
kubectl top pods --all-namespaces

# Check HPA status
kubectl get hpa --all-namespaces

# Review resource requests/limits
kubectl describe pod &lt;pod-name&gt; | grep -A 5 "Limits\|Requests"
</code></pre>
<h2 id="debugging-commands-1"><a class="header" href="#debugging-commands-1">Debugging Commands</a></h2>
<h3 id="general-debugging"><a class="header" href="#general-debugging">General Debugging</a></h3>
<pre><code class="language-bash"># Get all resources in namespace
kubectl get all -n &lt;namespace&gt;

# Describe resource
kubectl describe &lt;resource-type&gt; &lt;resource-name&gt; -n &lt;namespace&gt;

# View logs
kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; --tail=100 -f

# Execute command in pod
kubectl exec -it &lt;pod-name&gt; -n &lt;namespace&gt; -- /bin/sh

# Port forward for local access
kubectl port-forward -n &lt;namespace&gt; &lt;pod-name&gt; 8080:8080
</code></pre>
<h3 id="cluster-debugging"><a class="header" href="#cluster-debugging">Cluster Debugging</a></h3>
<pre><code class="language-bash"># Check cluster status
kubectl cluster-info

# Check API server
kubectl get --raw /healthz

# Check node status
kubectl get nodes -o wide

# Check system pods
kubectl get pods -n kube-system
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kubernetes-gitops-platform-technical-qa"><a class="header" href="#kubernetes-gitops-platform-technical-qa">Kubernetes GitOps Platform Technical Q&amp;A</a></h1>
<h2 id="architecture--design-questions-3"><a class="header" href="#architecture--design-questions-3">Architecture &amp; Design Questions</a></h2>
<h3 id="q1-walk-me-through-the-architecture-of-your-kubernetes-gitops-platform"><a class="header" href="#q1-walk-me-through-the-architecture-of-your-kubernetes-gitops-platform">Q1: "Walk me through the architecture of your Kubernetes GitOps Platform."</a></h3>
<p><strong>Answer:</strong>
"The platform uses a two-repository architecture:</p>
<ul>
<li><strong>k8s-infrastructure-as-code</strong>: Terraform provisions AWS EKS cluster, VPC, networking, and installs ArgoCD</li>
<li><strong>k8s-platform-toolkit</strong>: Contains all platform applications (monitoring, logging, testing) deployed via GitOps</li>
</ul>
<p>The workflow:</p>
<ol>
<li>Terraform creates EKS cluster and installs ArgoCD</li>
<li>ArgoCD uses app-of-apps pattern to reference platform toolkit repository</li>
<li>All platform applications deploy automatically via GitOps</li>
<li>Changes in Git automatically sync to cluster with zero downtime</li>
</ol>
<p>Key components:</p>
<ul>
<li><strong>Infrastructure</strong>: AWS EKS, VPC, IAM, Security Groups</li>
<li><strong>GitOps</strong>: ArgoCD with app-of-apps pattern</li>
<li><strong>Monitoring</strong>: Prometheus, Grafana, kube-state-metrics, node-exporter</li>
<li><strong>Logging</strong>: Loki and Promtail</li>
<li><strong>Testing</strong>: Sanity Test and Availability Test</li>
<li><strong>Demo</strong>: Online Boutique microservices"</li>
</ul>
<h3 id="q2-why-did-you-choose-a-two-repository-architecture"><a class="header" href="#q2-why-did-you-choose-a-two-repository-architecture">Q2: "Why did you choose a two-repository architecture?"</a></h3>
<p><strong>Answer:</strong>
"Two-repository architecture provides:</p>
<ol>
<li><strong>Separation of Concerns</strong>: Infrastructure vs. applications</li>
<li><strong>Independent Lifecycles</strong>: Infrastructure changes don't affect applications</li>
<li><strong>Team Collaboration</strong>: Different teams can work on different repos</li>
<li><strong>Security</strong>: Different access controls per repository</li>
<li><strong>Reusability</strong>: Platform toolkit can deploy to multiple clusters</li>
<li><strong>GitOps Best Practices</strong>: Clear separation of infrastructure and application code</li>
</ol>
<p>This pattern is common in enterprise GitOps implementations."</p>
<h3 id="q3-explain-the-app-of-apps-pattern"><a class="header" href="#q3-explain-the-app-of-apps-pattern">Q3: "Explain the app-of-apps pattern."</a></h3>
<p><strong>Answer:</strong>
"App-of-apps is an ArgoCD pattern for managing multiple applications:</p>
<ul>
<li><strong>Root Application</strong>: Manages child applications</li>
<li><strong>Child Applications</strong>: Individual application definitions</li>
<li><strong>Hierarchical Management</strong>: Single point of control</li>
<li><strong>Automated Sync</strong>: All apps sync from Git automatically</li>
<li><strong>Sync Waves</strong>: Ordered deployment using annotations</li>
</ul>
<p>Benefits:</p>
<ul>
<li>Centralized application management</li>
<li>Consistent deployment patterns</li>
<li>Easy to add/remove applications</li>
<li>Automated reconciliation"</li>
</ul>
<h2 id="infrastructure-questions-1"><a class="header" href="#infrastructure-questions-1">Infrastructure Questions</a></h2>
<h3 id="q4-how-does-terraform-provision-the-eks-cluster"><a class="header" href="#q4-how-does-terraform-provision-the-eks-cluster">Q4: "How does Terraform provision the EKS cluster?"</a></h3>
<p><strong>Answer:</strong>
"Terraform uses the official EKS module:</p>
<ol>
<li><strong>VPC Module</strong>: Creates networking infrastructure</li>
<li><strong>EKS Module</strong>: Provisions managed control plane</li>
<li><strong>Node Groups</strong>: Configures managed worker nodes</li>
<li><strong>IAM Roles</strong>: Sets up service accounts and permissions</li>
<li><strong>Helm Provider</strong>: Installs ArgoCD via Helm</li>
<li><strong>Kubernetes Provider</strong>: Configures app-of-apps</li>
</ol>
<p>The entire infrastructure is defined as code with:</p>
<ul>
<li>Multi-AZ deployment for high availability</li>
<li>Auto-scaling node groups</li>
<li>Security groups and network policies</li>
<li>IAM roles with least privilege"</li>
</ul>
<h3 id="q5-how-do-you-ensure-high-availability"><a class="header" href="#q5-how-do-you-ensure-high-availability">Q5: "How do you ensure high availability?"</a></h3>
<p><strong>Answer:</strong>
"Multiple HA strategies:</p>
<ol>
<li><strong>Multi-AZ Deployment</strong>: Control plane and nodes across zones</li>
<li><strong>Auto Scaling</strong>: Worker nodes and pods scale automatically</li>
<li><strong>Replica Sets</strong>: Multiple pod instances per service</li>
<li><strong>HPA</strong>: Horizontal Pod Autoscaler for pod scaling</li>
<li><strong>Cluster Autoscaler</strong>: Node-level auto-scaling</li>
<li><strong>Load Balancing</strong>: AWS ALB for external access</li>
<li><strong>Health Checks</strong>: Readiness and liveness probes</li>
</ol>
<p>This ensures the platform can handle failures and scale with demand."</p>
<h2 id="gitops-questions"><a class="header" href="#gitops-questions">GitOps Questions</a></h2>
<h3 id="q6-how-does-argocd-automatically-deploy-applications"><a class="header" href="#q6-how-does-argocd-automatically-deploy-applications">Q6: "How does ArgoCD automatically deploy applications?"</a></h3>
<p><strong>Answer:</strong>
"ArgoCD GitOps workflow:</p>
<ol>
<li><strong>Repository Monitoring</strong>: ArgoCD watches Git repositories</li>
<li><strong>Change Detection</strong>: Detects commits and changes</li>
<li><strong>Sync Policy</strong>: Automated sync with self-healing enabled</li>
<li><strong>Application Deployment</strong>: Applies manifests to cluster</li>
<li><strong>Health Monitoring</strong>: Tracks application health status</li>
<li><strong>Reconciliation</strong>: Continuously ensures desired state</li>
</ol>
<p>Configuration:</p>
<ul>
<li>Auto-sync enabled for most applications</li>
<li>Sync waves for ordered deployment</li>
<li>Self-healing for automatic recovery</li>
<li>Pruning for resource cleanup"</li>
</ul>
<h3 id="q7-how-do-you-handle-application-updates"><a class="header" href="#q7-how-do-you-handle-application-updates">Q7: "How do you handle application updates?"</a></h3>
<p><strong>Answer:</strong>
"Update process:</p>
<ol>
<li><strong>Make Changes</strong>: Update manifests in Git repository</li>
<li><strong>Commit and Push</strong>: Changes pushed to main branch</li>
<li><strong>ArgoCD Detection</strong>: ArgoCD detects changes automatically</li>
<li><strong>Sync</strong>: Applications sync with rolling updates</li>
<li><strong>Verification</strong>: Health checks validate deployment</li>
<li><strong>Rollback</strong>: Git revert for quick rollback if needed</li>
</ol>
<p>Zero-downtime through:</p>
<ul>
<li>Kubernetes rolling updates</li>
<li>Readiness probes</li>
<li>Multiple replicas</li>
<li>Health check validation"</li>
</ul>
<h2 id="monitoring-questions-2"><a class="header" href="#monitoring-questions-2">Monitoring Questions</a></h2>
<h3 id="q8-how-do-you-monitor-the-platform"><a class="header" href="#q8-how-do-you-monitor-the-platform">Q8: "How do you monitor the platform?"</a></h3>
<p><strong>Answer:</strong>
"Comprehensive monitoring stack:</p>
<ol>
<li><strong>Prometheus</strong>: Metrics collection from all services</li>
<li><strong>Grafana</strong>: Visualization with pre-built dashboards</li>
<li><strong>kube-state-metrics</strong>: Kubernetes object metrics</li>
<li><strong>node-exporter</strong>: Node-level system metrics</li>
<li><strong>Loki</strong>: Centralized log aggregation</li>
<li><strong>Promtail</strong>: Log collection agent</li>
</ol>
<p>Key metrics:</p>
<ul>
<li>Application performance (request rate, latency, errors)</li>
<li>Infrastructure metrics (CPU, memory, disk)</li>
<li>Kubernetes metrics (pod status, deployments)</li>
<li>Business metrics (custom application metrics)"</li>
</ul>
<h3 id="q9-how-do-you-test-application-availability"><a class="header" href="#q9-how-do-you-test-application-availability">Q9: "How do you test application availability?"</a></h3>
<p><strong>Answer:</strong>
"Two testing approaches:</p>
<ol>
<li>
<p><strong>Sanity Test</strong>: Health checks for all microservices every 60 seconds</p>
<ul>
<li>Tests individual service health</li>
<li>Tracks response times</li>
<li>Provides web dashboard</li>
</ul>
</li>
<li>
<p><strong>Availability Test</strong>: SRE-style testing every 5 minutes</p>
<ul>
<li>Simulates real user workflows</li>
<li>Tests complete user journeys</li>
<li>Calculates uptime percentage and SRE metrics</li>
<li>Provides Jenkins-like dashboard</li>
</ul>
</li>
</ol>
<p>Both tests run automatically and provide real-time status."</p>
<h2 id="scaling-questions"><a class="header" href="#scaling-questions">Scaling Questions</a></h2>
<h3 id="q10-how-does-auto-scaling-work"><a class="header" href="#q10-how-does-auto-scaling-work">Q10: "How does auto-scaling work?"</a></h3>
<p><strong>Answer:</strong>
"Multi-level auto-scaling:</p>
<ol>
<li>
<p><strong>HPA</strong>: Horizontal Pod Autoscaler scales pods based on CPU/memory</p>
<ul>
<li>Monitors pod resource usage</li>
<li>Scales between min/max replicas</li>
<li>Fast response to load changes</li>
</ul>
</li>
<li>
<p><strong>Cluster Autoscaler</strong>: Scales worker nodes</p>
<ul>
<li>Monitors unschedulable pods</li>
<li>Adds nodes when needed</li>
<li>Removes nodes when underutilized</li>
</ul>
</li>
<li>
<p><strong>VPA</strong>: Vertical Pod Autoscaler (optional)</p>
<ul>
<li>Adjusts resource requests/limits</li>
<li>Based on historical usage</li>
<li>Optimizes resource allocation</li>
</ul>
</li>
</ol>
<p>This ensures the platform scales automatically with demand."</p>
<h2 id="security-questions-1"><a class="header" href="#security-questions-1">Security Questions</a></h2>
<h3 id="q11-how-do-you-secure-the-platform"><a class="header" href="#q11-how-do-you-secure-the-platform">Q11: "How do you secure the platform?"</a></h3>
<p><strong>Answer:</strong>
"Multi-layer security:</p>
<ol>
<li><strong>Network</strong>: Private subnets, security groups, network policies</li>
<li><strong>IAM</strong>: Least privilege roles, service accounts, RBAC</li>
<li><strong>Secrets</strong>: Kubernetes secrets, AWS Secrets Manager integration</li>
<li><strong>Pod Security</strong>: Security contexts, pod security standards</li>
<li><strong>Encryption</strong>: Data at rest and in transit</li>
<li><strong>Audit</strong>: Kubernetes audit logging, VPC flow logs</li>
</ol>
<p>Security best practices:</p>
<ul>
<li>Defense in depth</li>
<li>Regular security updates</li>
<li>Image vulnerability scanning</li>
<li>Compliance with CIS benchmarks"</li>
</ul>
<h2 id="performance-testing-questions"><a class="header" href="#performance-testing-questions">Performance Testing Questions</a></h2>
<h3 id="q12-tell-me-about-k6-performance-testing-in-your-platform"><a class="header" href="#q12-tell-me-about-k6-performance-testing-in-your-platform">Q12: "Tell me about k6 performance testing in your platform."</a></h3>
<p><strong>Answer:</strong>
"k6 is a modern, developer-centric performance testing tool integrated into the platform:</p>
<ul>
<li><strong>Test Types</strong>: Smoke, Load, Stress, and Spike tests</li>
<li><strong>Kubernetes Native</strong>: Runs as Kubernetes Jobs</li>
<li><strong>GitOps Integrated</strong>: Test scripts stored in Git, deployed via ArgoCD</li>
<li><strong>Prometheus Integration</strong>: Metrics exported via StatsD exporter</li>
<li><strong>Grafana Dashboards</strong>: Real-time visualization of test results</li>
</ul>
<p>Test scenarios:</p>
<ul>
<li><strong>Smoke Test</strong>: Basic functionality (1 user, ~4 minutes)</li>
<li><strong>Load Test</strong>: Normal production load (50-100 users, ~16 minutes)</li>
<li><strong>Stress Test</strong>: Find breaking point (100-500 users, ~40 minutes)</li>
<li><strong>Spike Test</strong>: Sudden traffic spikes (10‚Üí500‚Üí1000 users, ~6 minutes)</li>
</ul>
<p>Each test validates:</p>
<ul>
<li>Frontend HTTP endpoints (homepage, product pages)</li>
<li>Backend health checks</li>
<li>Error rates and response times</li>
<li>Custom metrics (frontend_errors, backend_errors)</li>
</ul>
<p>Tests can be run manually or scheduled via CronJobs for continuous validation."</p>
<h3 id="q13-how-does-k6-integrate-with-your-monitoring-stack"><a class="header" href="#q13-how-does-k6-integrate-with-your-monitoring-stack">Q13: "How does k6 integrate with your monitoring stack?"</a></h3>
<p><strong>Answer:</strong>
"k6 metrics flow through this pipeline:</p>
<ol>
<li><strong>k6 Test Jobs</strong>: Generate load and collect metrics</li>
<li><strong>StatsD Exporter</strong>: Receives metrics from k6 via StatsD protocol</li>
<li><strong>Prometheus</strong>: Scrapes StatsD exporter metrics</li>
<li><strong>Grafana</strong>: Visualizes metrics in dashboards</li>
</ol>
<p>Available metrics:</p>
<ul>
<li><code>k6_http_reqs_total</code> - Total requests</li>
<li><code>k6_http_req_duration_seconds</code> - Response time histogram</li>
<li><code>k6_http_req_failed_total</code> - Failed requests</li>
<li><code>k6_vus</code> - Current virtual users</li>
<li>Custom metrics: <code>frontend_errors</code>, <code>backend_errors</code></li>
</ul>
<p>We use the official Grafana k6 dashboard (ID: 19665) for visualization, showing:</p>
<ul>
<li>Request rate over time</li>
<li>Response time percentiles (p50, p95, p99)</li>
<li>Error rates</li>
<li>Virtual user count</li>
<li>Data transfer metrics</li>
</ul>
<p>This integration allows us to correlate performance test results with application metrics in real-time."</p>
<h3 id="q14-how-do-you-use-k6-to-validate-autoscaling"><a class="header" href="#q14-how-do-you-use-k6-to-validate-autoscaling">Q14: "How do you use k6 to validate autoscaling?"</a></h3>
<p><strong>Answer:</strong>
"k6 tests validate HPA and Cluster Autoscaler:</p>
<ol>
<li>
<p><strong>Load Test</strong>: Gradually increases load to trigger HPA</p>
<ul>
<li>Watch HPA create new pods</li>
<li>Verify response times remain stable</li>
<li>Confirm pods scale down after test</li>
</ul>
</li>
<li>
<p><strong>Spike Test</strong>: Sudden load spikes test autoscaling response</p>
<ul>
<li>Validates rapid scaling capability</li>
<li>Tests rate limiting and circuit breakers</li>
<li>Verifies system recovers after spike</li>
</ul>
</li>
<li>
<p><strong>Stress Test</strong>: Finds autoscaling limits</p>
<ul>
<li>Identifies maximum capacity</li>
<li>Tests cluster autoscaler node addition</li>
<li>Validates resource constraints</li>
</ul>
</li>
</ol>
<p>Process:</p>
<ul>
<li>Run k6 test with increasing load</li>
<li>Monitor HPA status: <code>kubectl get hpa -w</code></li>
<li>Watch pod scaling: <code>kubectl get pods -w</code></li>
<li>Verify metrics in Grafana</li>
<li>Confirm performance remains within thresholds</li>
</ul>
<p>This ensures autoscaling works correctly and maintains SLOs under load."</p>
<h2 id="advanced-questions-3"><a class="header" href="#advanced-questions-3">Advanced Questions</a></h2>
<h3 id="q15-how-would-you-scale-this-to-production"><a class="header" href="#q15-how-would-you-scale-this-to-production">Q15: "How would you scale this to production?"</a></h3>
<p><strong>Answer:</strong>
"Production scaling strategies:</p>
<ol>
<li><strong>Multi-Cluster</strong>: Deploy to multiple regions/clusters</li>
<li><strong>Service Mesh</strong>: Istio or Linkerd for advanced traffic management</li>
<li><strong>CI/CD Integration</strong>: Automated testing and deployment pipelines</li>
<li><strong>Disaster Recovery</strong>: Backup and restore procedures</li>
<li><strong>Advanced Monitoring</strong>: Custom metrics and alerting</li>
<li><strong>Cost Optimization</strong>: Spot instances, reserved capacity</li>
<li><strong>Compliance</strong>: Enhanced security and audit logging</li>
</ol>
<p>The architecture supports horizontal scaling and can be extended for enterprise production use."</p>
<h3 id="q16-how-do-you-handle-performance-testing-in-cicd"><a class="header" href="#q16-how-do-you-handle-performance-testing-in-cicd">Q16: "How do you handle performance testing in CI/CD?"</a></h3>
<p><strong>Answer:</strong>
"Performance testing integration:</p>
<ol>
<li>
<p><strong>Smoke Tests</strong>: Run after each deployment</p>
<ul>
<li>Quick validation (&lt; 5 minutes)</li>
<li>Blocks deployment on failure</li>
<li>Integrated in GitHub Actions</li>
</ul>
</li>
<li>
<p><strong>Scheduled Tests</strong>: CronJobs run regularly</p>
<ul>
<li>Load tests weekly</li>
<li>Stress tests monthly</li>
<li>Spike tests before major releases</li>
</ul>
</li>
<li>
<p><strong>Metrics Collection</strong>: All tests export to Prometheus</p>
<ul>
<li>Historical trend analysis</li>
<li>Performance regression detection</li>
<li>SLO validation</li>
</ul>
</li>
<li>
<p><strong>Alerting</strong>: Prometheus alerts on threshold violations</p>
<ul>
<li>High error rates</li>
<li>Slow response times</li>
<li>Test failures</li>
</ul>
</li>
</ol>
<p>This ensures continuous performance validation and early detection of regressions."</p>
<h2 id="opa-policy-enforcement-questions"><a class="header" href="#opa-policy-enforcement-questions">OPA Policy Enforcement Questions</a></h2>
<h3 id="q17-what-is-opa-and-why-did-you-implement-it"><a class="header" href="#q17-what-is-opa-and-why-did-you-implement-it">Q17: "What is OPA and why did you implement it?"</a></h3>
<p><strong>Answer:</strong>
"OPA (Open Policy Agent) is a general-purpose policy engine that enables unified policy enforcement. We use OPA Gatekeeper for Kubernetes to enforce security and governance policies automatically.</p>
<p>Benefits:</p>
<ol>
<li><strong>Security</strong>: Automatically enforces security best practices</li>
<li><strong>Compliance</strong>: Meets regulatory requirements (SOC 2, PCI-DSS, HIPAA)</li>
<li><strong>Prevention</strong>: Blocks bad configurations before they reach the cluster</li>
<li><strong>Consistency</strong>: Ensures all resources follow the same policies</li>
<li><strong>Audit</strong>: Provides compliance reporting and violation tracking</li>
</ol>
<p>We implemented 6 core policies:</p>
<ul>
<li>Require non-root users</li>
<li>Require resource limits</li>
<li>Disallow latest tags</li>
<li>Require read-only filesystem</li>
<li>Disallow privileged containers</li>
<li>Require labels"</li>
</ul>
<h3 id="q18-how-does-opa-gatekeeper-enforce-policies"><a class="header" href="#q18-how-does-opa-gatekeeper-enforce-policies">Q18: "How does OPA Gatekeeper enforce policies?"</a></h3>
<p><strong>Answer:</strong>
"OPA Gatekeeper enforces policies through Kubernetes admission control:</p>
<ol>
<li><strong>Admission Webhook</strong>: Gatekeeper registers as validating admission webhook</li>
<li><strong>Request Interception</strong>: All pod/deployment creation requests are intercepted</li>
<li><strong>Policy Evaluation</strong>: Rego policies evaluate the resource against constraints</li>
<li><strong>Decision</strong>: Allow or deny based on policy evaluation</li>
<li><strong>Response</strong>: Pod is created or error is returned</li>
</ol>
<p>Flow:</p>
<pre><code>Developer: kubectl apply pod.yaml
    ‚Üì
Kubernetes API Server
    ‚Üì
Gatekeeper Admission Webhook
    ‚Üì
Policy Evaluation (Rego)
    ‚Üì
‚úÖ Allow or ‚ùå Deny
</code></pre>
<p>This happens before resources are created, preventing violations from reaching the cluster."</p>
<h3 id="q19-explain-your-opa-policy-enforcement-modes"><a class="header" href="#q19-explain-your-opa-policy-enforcement-modes">Q19: "Explain your OPA policy enforcement modes."</a></h3>
<p><strong>Answer:</strong>
"We support three enforcement modes:</p>
<ol>
<li>
<p><strong>Enforce Mode (Production)</strong>:</p>
<ul>
<li>Blocks violations completely</li>
<li>Pods are rejected if they violate policies</li>
<li>Use case: Production environments</li>
</ul>
</li>
<li>
<p><strong>Dryrun Mode (Demo/Audit)</strong>:</p>
<ul>
<li>Reports violations but allows deployments</li>
<li>Pods are created, violations are logged</li>
<li>Use case: Testing, gradual rollout, demos</li>
</ul>
</li>
<li>
<p><strong>Warn Mode (Soft Enforcement)</strong>:</p>
<ul>
<li>Warnings in events but allows deployments</li>
<li>Pods are created with warnings</li>
<li>Use case: Migration period</li>
</ul>
</li>
</ol>
<p>We use dryrun mode for demos to show policy violations without blocking deployments. In production, we use enforce mode for security-critical policies."</p>
<h3 id="q20-how-do-you-audit-opa-policy-compliance"><a class="header" href="#q20-how-do-you-audit-opa-policy-compliance">Q20: "How do you audit OPA policy compliance?"</a></h3>
<p><strong>Answer:</strong>
"Multiple audit approaches:</p>
<ol>
<li>
<p><strong>Automated Audit Script</strong>:</p>
<pre><code class="language-bash">./opa/audit-policies.sh all
</code></pre>
<ul>
<li>Scans all pods in namespace</li>
<li>Reports compliant/non-compliant resources</li>
<li>Color-coded output with summaries</li>
</ul>
</li>
<li>
<p><strong>Constraint Status</strong>:</p>
<pre><code class="language-bash">kubectl get K8sRequiredNonRoot
kubectl describe K8sRequiredNonRoot online-boutique-must-run-nonroot
</code></pre>
<ul>
<li>Shows violation count</li>
<li>Lists violating resources</li>
<li>Provides detailed violation messages</li>
</ul>
</li>
<li>
<p><strong>Prometheus Metrics</strong>:</p>
<ul>
<li><code>gatekeeper_violations_total</code> - Total violations</li>
<li><code>gatekeeper_admission_duration_seconds</code> - Policy evaluation time</li>
<li>Export to Grafana for visualization</li>
</ul>
</li>
<li>
<p><strong>Manual kubectl Commands</strong>:</p>
<ul>
<li>Check specific resources for compliance</li>
<li>Query constraint status</li>
<li>View violation details</li>
</ul>
</li>
</ol>
<p>This provides comprehensive compliance visibility and audit trails."</p>
<h2 id="sanity-test-questions"><a class="header" href="#sanity-test-questions">Sanity Test Questions</a></h2>
<h3 id="q21-what-is-sanity-test-and-how-does-it-work"><a class="header" href="#q21-what-is-sanity-test-and-how-does-it-work">Q21: "What is Sanity Test and how does it work?"</a></h3>
<p><strong>Answer:</strong>
"Sanity Test is an automated health check application that continuously monitors all microservices:</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Tests 11 microservices every 60 seconds</li>
<li>Supports HTTP, gRPC, and TCP protocols</li>
<li>Real-time dashboard showing service status</li>
<li>Response time tracking</li>
<li>History of last 50 test runs</li>
</ul>
<p><strong>How It Works</strong>:</p>
<ol>
<li>Discovers services in target namespace</li>
<li>Tests each service's health endpoint</li>
<li>Measures response times</li>
<li>Tracks pass/fail status</li>
<li>Updates dashboard in real-time</li>
</ol>
<p><strong>Tested Services</strong>:</p>
<ul>
<li>HTTP: frontend, cartservice, productcatalogservice, etc.</li>
<li>gRPC: paymentservice, shippingservice</li>
<li>TCP: redis-cart</li>
</ul>
<p>The application runs as a Kubernetes deployment with 2 replicas for high availability."</p>
<h3 id="q22-how-does-sanity-test-handle-different-service-protocols"><a class="header" href="#q22-how-does-sanity-test-handle-different-service-protocols">Q22: "How does Sanity Test handle different service protocols?"</a></h3>
<p><strong>Answer:</strong>
"Sanity Test supports multiple protocols:</p>
<ol>
<li>
<p><strong>HTTP Services</strong>:</p>
<ul>
<li>Tests <code>/health</code> or <code>/_healthz</code> endpoints</li>
<li>Validates HTTP status codes (200 = healthy)</li>
<li>Measures response time</li>
<li>Example: frontend service</li>
</ul>
</li>
<li>
<p><strong>gRPC Services</strong>:</p>
<ul>
<li>Uses TCP socket connection test</li>
<li>Tests port connectivity</li>
<li>Validates service is listening</li>
<li>Example: paymentservice, shippingservice</li>
</ul>
</li>
<li>
<p><strong>TCP Services</strong>:</p>
<ul>
<li>Tests port connectivity</li>
<li>Validates service is reachable</li>
<li>Example: redis-cart</li>
</ul>
</li>
</ol>
<p>The application uses Python's socket library for TCP/gRPC and requests library for HTTP, with configurable timeouts for each check."</p>
<h3 id="q23-how-do-you-integrate-sanity-test-with-monitoring"><a class="header" href="#q23-how-do-you-integrate-sanity-test-with-monitoring">Q23: "How do you integrate Sanity Test with monitoring?"</a></h3>
<p><strong>Answer:</strong>
"Sanity Test can be integrated with monitoring:</p>
<ol>
<li>
<p><strong>Prometheus Metrics</strong> (potential):</p>
<ul>
<li><code>sanity_test_total</code> - Total test runs</li>
<li><code>sanity_test_passed</code> - Passed test count</li>
<li><code>sanity_test_failed</code> - Failed test count</li>
<li><code>sanity_test_service_health</code> - Per-service health (0/1)</li>
<li><code>sanity_test_response_time</code> - Per-service response time</li>
</ul>
</li>
<li>
<p><strong>Grafana Dashboards</strong>:</p>
<ul>
<li>Test success rate over time</li>
<li>Service health trends</li>
<li>Response time percentiles</li>
<li>Service availability percentage</li>
</ul>
</li>
<li>
<p><strong>Alerting</strong>:</p>
<ul>
<li>Alert on test failures</li>
<li>Alert on service degradation</li>
<li>Alert on high response times</li>
<li>Alert on consecutive failures</li>
</ul>
</li>
<li>
<p><strong>API Integration</strong>:</p>
<ul>
<li>REST API for programmatic access</li>
<li><code>/api/status</code> endpoint for monitoring tools</li>
<li><code>/api/run-test</code> for manual triggers</li>
</ul>
</li>
</ol>
<p>This provides comprehensive visibility into service health."</p>
<h2 id="availability-test-questions"><a class="header" href="#availability-test-questions">Availability Test Questions</a></h2>
<h3 id="q24-what-is-availability-test-and-how-does-it-differ-from-sanity-test"><a class="header" href="#q24-what-is-availability-test-and-how-does-it-differ-from-sanity-test">Q24: "What is Availability Test and how does it differ from Sanity Test?"</a></h3>
<p><strong>Answer:</strong>
"Availability Test is an SRE-style testing application that simulates real user workflows:</p>
<p><strong>Key Differences</strong>:</p>
<ul>
<li><strong>Sanity Test</strong>: Tests individual service health endpoints</li>
<li><strong>Availability Test</strong>: Tests complete user journeys (end-to-end)</li>
</ul>
<p><strong>Availability Test Features</strong>:</p>
<ul>
<li>Simulates real user workflows (visit ‚Üí browse ‚Üí add to cart ‚Üí remove)</li>
<li>Calculates SRE metrics (uptime percentage, consecutive failures)</li>
<li>Jenkins-like dashboard with build numbers</li>
<li>Tests every 5 minutes</li>
<li>Provides error budgets and MTTR metrics</li>
</ul>
<p><strong>Test Workflow</strong>:</p>
<ol>
<li>User visits website (frontend accessibility)</li>
<li>User browses products (catalog verification)</li>
<li>User adds product to cart (cart service integration)</li>
<li>User removes product from cart (cart state management)</li>
<li>Health check verification (backend services)</li>
</ol>
<p>This validates that the entire system works together, not just individual services."</p>
<h3 id="q25-how-do-you-calculate-sre-metrics-in-availability-test"><a class="header" href="#q25-how-do-you-calculate-sre-metrics-in-availability-test">Q25: "How do you calculate SRE metrics in Availability Test?"</a></h3>
<p><strong>Answer:</strong>
"SRE metrics calculation:</p>
<ol>
<li>
<p><strong>Uptime Percentage</strong>:</p>
<pre><code class="language-python">uptime_percentage = (successful_tests / total_tests) * 100
</code></pre>
<ul>
<li>Tracks overall system availability</li>
<li>Target: 99.9% or higher</li>
</ul>
</li>
<li>
<p><strong>Consecutive Failures</strong>:</p>
<pre><code class="language-python">if test_failed:
    consecutive_failures += 1
else:
    consecutive_failures = 0
</code></pre>
<ul>
<li>Monitors continuous failures</li>
<li>Used for alerting thresholds</li>
</ul>
</li>
<li>
<p><strong>Error Budget</strong>:</p>
<pre><code class="language-python">error_budget = 100 - uptime_percentage
</code></pre>
<ul>
<li>Remaining error budget</li>
<li>Tracks SLA compliance</li>
</ul>
</li>
<li>
<p><strong>Test Duration</strong>:</p>
<ul>
<li>Measures how long tests take</li>
<li>Performance monitoring</li>
<li>Identifies slow services</li>
</ul>
</li>
<li>
<p><strong>Success Rate</strong>:</p>
<ul>
<li>Pass/fail ratio over time</li>
<li>Trend analysis</li>
<li>Historical comparison</li>
</ul>
</li>
</ol>
<p>These metrics provide SRE-style visibility into system reliability."</p>
<h3 id="q26-how-does-availability-test-integrate-with-sre-practices"><a class="header" href="#q26-how-does-availability-test-integrate-with-sre-practices">Q26: "How does Availability Test integrate with SRE practices?"</a></h3>
<p><strong>Answer:</strong>
"Availability Test implements SRE best practices:</p>
<ol>
<li>
<p><strong>SLI/SLO Tracking</strong>:</p>
<ul>
<li>Uptime percentage as SLI</li>
<li>99.9% uptime as SLO</li>
<li>Error budget tracking</li>
</ul>
</li>
<li>
<p><strong>Alerting Criteria</strong>:</p>
<ul>
<li>Red status: Consecutive failures &gt; 0</li>
<li>Green status: All tests passing</li>
<li>Uptime &lt; 95%: Service degradation threshold</li>
</ul>
</li>
<li>
<p><strong>Incident Detection</strong>:</p>
<ul>
<li>Early warning of service issues</li>
<li>Real user workflow validation</li>
<li>Automated testing reduces MTTR</li>
</ul>
</li>
<li>
<p><strong>Dashboard Design</strong>:</p>
<ul>
<li>Jenkins-like interface (familiar to DevOps teams)</li>
<li>Build numbers for test runs</li>
<li>Visual status indicators (green/red)</li>
</ul>
</li>
<li>
<p><strong>Metrics Export</strong>:</p>
<ul>
<li>Can export to Prometheus</li>
<li>Grafana dashboards for trends</li>
<li>Historical analysis</li>
</ul>
</li>
</ol>
<p>This provides production-ready SRE monitoring capabilities."</p>
<h2 id="argocd-gitops-questions"><a class="header" href="#argocd-gitops-questions">ArgoCD GitOps Questions</a></h2>
<h3 id="q27-how-does-the-app-of-apps-pattern-work-in-your-setup"><a class="header" href="#q27-how-does-the-app-of-apps-pattern-work-in-your-setup">Q27: "How does the app-of-apps pattern work in your setup?"</a></h3>
<p><strong>Answer:</strong>
"App-of-apps pattern implementation:</p>
<p><strong>Root Application</strong>:</p>
<pre><code class="language-yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: k8s-platform-toolkit
spec:
  source:
    repoURL: https://github.com/Lforlinux/k8s-platform-toolkit.git
    path: argocd/apps
    directory:
      recurse: true  # Discovers all applications
</code></pre>
<p><strong>How It Works</strong>:</p>
<ol>
<li>Root application references <code>argocd/apps</code> directory</li>
<li><code>recurse: true</code> discovers all application YAML files</li>
<li>Each child application is automatically created</li>
<li>All applications sync from Git automatically</li>
</ol>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Single point of management</li>
<li>Automatic application discovery</li>
<li>Consistent deployment patterns</li>
<li>Easy to add new applications (just add YAML file)</li>
</ul>
<p><strong>Child Applications</strong>:</p>
<ul>
<li>monitoring-stack</li>
<li>logging-stack</li>
<li>sanity-test</li>
<li>availability-test</li>
<li>online-boutique</li>
<li>performance-testing</li>
</ul>
<p>All managed by the root application automatically."</p>
<h3 id="q28-explain-argocd-sync-waves-and-why-you-use-them"><a class="header" href="#q28-explain-argocd-sync-waves-and-why-you-use-them">Q28: "Explain ArgoCD sync waves and why you use them."</a></h3>
<p><strong>Answer:</strong>
"Sync waves control deployment order using annotations:</p>
<pre><code class="language-yaml">annotations:
  argocd.argoproj.io/sync-wave: "1"  # Deploy first
</code></pre>
<p><strong>Our Sync Wave Order</strong>:</p>
<ol>
<li><strong>Wave 1</strong>: Testing infrastructure (sanity-test, availability-test)</li>
<li><strong>Wave 2</strong>: Demo applications (online-boutique)</li>
<li><strong>Wave 3</strong>: Monitoring stack (Prometheus, Grafana)</li>
<li><strong>Wave 4</strong>: Logging stack (Loki)</li>
<li><strong>Wave 5</strong>: Log collection (Promtail)</li>
</ol>
<p><strong>Why Use Sync Waves</strong>:</p>
<ul>
<li><strong>Dependencies</strong>: Some services depend on others</li>
<li><strong>Order Matters</strong>: Monitoring should deploy before applications</li>
<li><strong>Reliability</strong>: Ensures proper startup sequence</li>
<li><strong>Predictability</strong>: Consistent deployment order</li>
</ul>
<p><strong>Example</strong>:</p>
<ul>
<li>Promtail (wave 5) needs Loki (wave 4) to be ready</li>
<li>Applications (wave 2) can be monitored by Prometheus (wave 3)</li>
<li>Testing (wave 1) validates everything works</li>
</ul>
<p>This ensures dependencies are met and deployments are reliable."</p>
<h3 id="q29-how-does-argocd-self-healing-work"><a class="header" href="#q29-how-does-argocd-self-healing-work">Q29: "How does ArgoCD self-healing work?"</a></h3>
<p><strong>Answer:</strong>
"ArgoCD self-healing automatically corrects drift:</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-yaml">syncPolicy:
  automated:
    selfHeal: true
</code></pre>
<p><strong>How It Works</strong>:</p>
<ol>
<li><strong>Drift Detection</strong>: ArgoCD continuously compares Git state with cluster state</li>
<li><strong>Manual Changes Detected</strong>: If someone manually changes resources</li>
<li><strong>Automatic Correction</strong>: ArgoCD reverts changes to match Git</li>
<li><strong>Continuous Reconciliation</strong>: Happens automatically every few minutes</li>
</ol>
<p><strong>Example Scenario</strong>:</p>
<pre><code>Developer: kubectl scale deployment frontend --replicas=5
    ‚Üì
ArgoCD detects: Git says 3 replicas, cluster has 5
    ‚Üì
ArgoCD corrects: Scales back to 3 replicas
</code></pre>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Prevents configuration drift</li>
<li>Maintains Git as source of truth</li>
<li>Automatic recovery from manual changes</li>
<li>No manual intervention needed</li>
</ul>
<p><strong>When to Use</strong>:</p>
<ul>
<li>Production environments</li>
<li>Critical applications</li>
<li>Compliance requirements</li>
<li>Multi-team environments"</li>
</ul>
<h3 id="q30-how-do-you-handle-rollbacks-in-argocd"><a class="header" href="#q30-how-do-you-handle-rollbacks-in-argocd">Q30: "How do you handle rollbacks in ArgoCD?"</a></h3>
<p><strong>Answer:</strong>
"Multiple rollback strategies:</p>
<ol>
<li>
<p><strong>Git Revert (Recommended)</strong>:</p>
<pre><code class="language-bash">git revert &lt;commit-hash&gt;
git push origin main
</code></pre>
<ul>
<li>ArgoCD automatically syncs</li>
<li>Maintains Git history</li>
<li>Full audit trail</li>
</ul>
</li>
<li>
<p><strong>ArgoCD Rollback</strong>:</p>
<pre><code class="language-bash">argocd app rollback monitoring-stack
argocd app rollback monitoring-stack &lt;revision&gt;
</code></pre>
<ul>
<li>Rollback to previous revision</li>
<li>Quick recovery</li>
<li>View history: <code>argocd app history monitoring-stack</code></li>
</ul>
</li>
<li>
<p><strong>Manual Sync to Previous Revision</strong>:</p>
<pre><code class="language-bash">argocd app sync monitoring-stack --revision &lt;revision&gt;
</code></pre>
</li>
</ol>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Always use Git revert for production</li>
<li>Keep revision history (default: 10 revisions)</li>
<li>Test rollbacks in staging first</li>
<li>Document rollback procedures</li>
</ul>
<p><strong>Rollback Process</strong>:</p>
<ol>
<li>Identify problematic revision</li>
<li>Revert in Git or use ArgoCD rollback</li>
<li>ArgoCD syncs automatically</li>
<li>Verify application health</li>
<li>Monitor for issues"</li>
</ol>
<h2 id="monitoring--observability-questions"><a class="header" href="#monitoring--observability-questions">Monitoring &amp; Observability Questions</a></h2>
<h3 id="q31-how-does-prometheus-scrape-metrics-in-your-setup"><a class="header" href="#q31-how-does-prometheus-scrape-metrics-in-your-setup">Q31: "How does Prometheus scrape metrics in your setup?"</a></h3>
<p><strong>Answer:</strong>
"Prometheus uses service discovery and static configurations:</p>
<p><strong>Service Discovery</strong>:</p>
<pre><code class="language-yaml">scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
</code></pre>
<p><strong>Scraping Methods</strong>:</p>
<ol>
<li><strong>Pod Annotations</strong>: Pods with <code>prometheus.io/scrape: "true"</code> are scraped</li>
<li><strong>Service Discovery</strong>: Automatic discovery of Kubernetes pods</li>
<li><strong>Static Targets</strong>: Fixed endpoints (Prometheus, Grafana)</li>
<li><strong>Service Monitors</strong>: Custom resource for advanced configuration</li>
</ol>
<p><strong>Key Metrics Collected</strong>:</p>
<ul>
<li>Application metrics (request rate, latency, errors)</li>
<li>Infrastructure metrics (CPU, memory, disk)</li>
<li>Kubernetes metrics (pod status, deployments)</li>
<li>Custom business metrics</li>
</ul>
<p><strong>Scrape Interval</strong>: 15 seconds (configurable)
<strong>Retention</strong>: 30 days (configurable)</p>
<p>This provides comprehensive metrics collection from all services."</p>
<h3 id="q32-how-do-you-create-and-manage-grafana-dashboards"><a class="header" href="#q32-how-do-you-create-and-manage-grafana-dashboards">Q32: "How do you create and manage Grafana dashboards?"</a></h3>
<p><strong>Answer:</strong>
"Grafana dashboard management:</p>
<p><strong>Pre-configured Dashboards</strong>:</p>
<ol>
<li><strong>Official k6 Dashboard</strong>: ID 19665 (imported from Grafana Labs)</li>
<li><strong>Kubernetes Cluster Overview</strong>: Cluster health and resources</li>
<li><strong>Online Boutique Dashboard</strong>: Microservices metrics</li>
<li><strong>Node Exporter Dashboard</strong>: Node-level system metrics</li>
</ol>
<p><strong>Dashboard Import</strong>:</p>
<ol>
<li>Access Grafana UI</li>
<li>Go to Dashboards ‚Üí Import</li>
<li>Enter Dashboard ID or upload JSON</li>
<li>Select Prometheus as data source</li>
<li>Save dashboard</li>
</ol>
<p><strong>Custom Dashboards</strong>:</p>
<ul>
<li>Create dashboards in Grafana UI</li>
<li>Export as JSON</li>
<li>Store in Git repository</li>
<li>Deploy via ArgoCD</li>
</ul>
<p><strong>Dashboard Features</strong>:</p>
<ul>
<li>Request rate visualization</li>
<li>Response time percentiles (p50, p95, p99)</li>
<li>Error rate tracking</li>
<li>Resource utilization</li>
<li>Historical trends</li>
</ul>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Use official dashboards when available</li>
<li>Customize for specific needs</li>
<li>Version control dashboard JSON</li>
<li>Document dashboard purposes"</li>
</ul>
<h3 id="q33-how-does-loki-aggregate-logs-from-all-pods"><a class="header" href="#q33-how-does-loki-aggregate-logs-from-all-pods">Q33: "How does Loki aggregate logs from all pods?"</a></h3>
<p><strong>Answer:</strong>
"Loki log aggregation pipeline:</p>
<p><strong>Components</strong>:</p>
<ol>
<li><strong>Promtail</strong>: Log collection agent (DaemonSet on each node)</li>
<li><strong>Loki</strong>: Log aggregation server</li>
<li><strong>Grafana</strong>: Log visualization</li>
</ol>
<p><strong>How It Works</strong>:</p>
<ol>
<li>
<p><strong>Promtail Discovery</strong>:</p>
<ul>
<li>Runs on every node</li>
<li>Discovers pods automatically</li>
<li>Reads log files from <code>/var/log/pods</code></li>
</ul>
</li>
<li>
<p><strong>Log Collection</strong>:</p>
<ul>
<li>Promtail tails log files</li>
<li>Adds Kubernetes labels (namespace, pod, container)</li>
<li>Sends logs to Loki via HTTP</li>
</ul>
</li>
<li>
<p><strong>Loki Storage</strong>:</p>
<ul>
<li>Indexes by labels (not log content)</li>
<li>Efficient storage (compressed)</li>
<li>Fast queries by label</li>
</ul>
</li>
<li>
<p><strong>Grafana Queries</strong>:</p>
<ul>
<li>LogQL query language</li>
<li>Filter by labels</li>
<li>Search log content</li>
<li>Visualize in dashboards</li>
</ul>
</li>
</ol>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-yaml">scrape_configs:
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod
</code></pre>
<p>This provides centralized logging with efficient storage and fast queries."</p>
<h2 id="logging-questions"><a class="header" href="#logging-questions">Logging Questions</a></h2>
<h3 id="q34-how-does-promtail-collect-logs-from-kubernetes-pods"><a class="header" href="#q34-how-does-promtail-collect-logs-from-kubernetes-pods">Q34: "How does Promtail collect logs from Kubernetes pods?"</a></h3>
<p><strong>Answer:</strong>
"Promtail log collection process:</p>
<p><strong>DaemonSet Deployment</strong>:</p>
<ul>
<li>One Promtail pod per node</li>
<li>Runs with hostPath volume mounts</li>
<li>Accesses <code>/var/log/pods</code> directory</li>
</ul>
<p><strong>Log Discovery</strong>:</p>
<ol>
<li>
<p><strong>Kubernetes Service Discovery</strong>:</p>
<ul>
<li>Discovers pods automatically</li>
<li>Reads pod metadata</li>
<li>Extracts labels and annotations</li>
</ul>
</li>
<li>
<p><strong>Log File Reading</strong>:</p>
<ul>
<li>Reads from <code>/var/log/pods/&lt;namespace&gt;_&lt;pod&gt;_&lt;uid&gt;/&lt;container&gt;/&lt;log-file&gt;</code></li>
<li>Tails log files in real-time</li>
<li>Handles log rotation</li>
</ul>
</li>
<li>
<p><strong>Label Enrichment</strong>:</p>
<ul>
<li>Adds Kubernetes labels (namespace, pod, container, node)</li>
<li>Adds custom labels from annotations</li>
<li>Creates unique log stream identifiers</li>
</ul>
</li>
<li>
<p><strong>Log Shipping</strong>:</p>
<ul>
<li>Sends logs to Loki via HTTP POST</li>
<li>Batches logs for efficiency</li>
<li>Retries on failures</li>
</ul>
</li>
</ol>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-yaml">scrape_configs:
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_node_name]
        target_label: __host__
</code></pre>
<p>This provides automatic log collection from all pods without manual configuration."</p>
<h3 id="q35-how-do-you-query-logs-in-loki-using-logql"><a class="header" href="#q35-how-do-you-query-logs-in-loki-using-logql">Q35: "How do you query logs in Loki using LogQL?"</a></h3>
<p><strong>Answer:</strong>
"LogQL (Log Query Language) examples:</p>
<p><strong>Basic Queries</strong>:</p>
<pre><code class="language-logql"># Query logs by namespace
{namespace="online-boutique"}

# Query logs by service
{namespace="online-boutique", service="frontend"}

# Filter by log level
{namespace="online-boutique"} |= "error"
</code></pre>
<p><strong>Advanced Queries</strong>:</p>
<pre><code class="language-logql"># Count errors
count_over_time({namespace="online-boutique"} |= "error" [5m])

# Rate of errors
rate({namespace="online-boutique"} |= "error" [1m])

# Filter and aggregate
{namespace="online-boutique"} 
  |= "error" 
  | json 
  | line_format "{{.timestamp}} {{.message}}"
</code></pre>
<p><strong>Query Features</strong>:</p>
<ul>
<li>Label matching</li>
<li>Log content filtering</li>
<li>Aggregation functions</li>
<li>Time range queries</li>
<li>Log parsing and formatting</li>
</ul>
<p><strong>Use Cases</strong>:</p>
<ul>
<li>Error investigation</li>
<li>Performance analysis</li>
<li>Security auditing</li>
<li>Compliance reporting</li>
</ul>
<p>This provides powerful log querying capabilities similar to PromQL for metrics."</p>
<h2 id="security-questions-2"><a class="header" href="#security-questions-2">Security Questions</a></h2>
<h3 id="q36-how-do-you-implement-network-policies-in-your-cluster"><a class="header" href="#q36-how-do-you-implement-network-policies-in-your-cluster">Q36: "How do you implement network policies in your cluster?"</a></h3>
<p><strong>Answer:</strong>
"Network policies provide pod-to-pod network isolation:</p>
<p><strong>Policy Example</strong>:</p>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-policy
spec:
  podSelector:
    matchLabels:
      app: frontend
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app: loadbalancer
      ports:
        - protocol: TCP
          port: 8080
  egress:
    - to:
        - podSelector:
            matchLabels:
              app: cartservice
      ports:
        - protocol: TCP
          port: 7070
</code></pre>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Network segmentation</li>
<li>Least privilege networking</li>
<li>Multi-tenant isolation</li>
<li>Security compliance</li>
</ul>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Start with deny-all, allow specific</li>
<li>Use labels for policy matching</li>
<li>Test policies in staging first</li>
<li>Document allowed communications"</li>
</ul>
<h3 id="q37-how-do-you-manage-secrets-in-kubernetes"><a class="header" href="#q37-how-do-you-manage-secrets-in-kubernetes">Q37: "How do you manage secrets in Kubernetes?"</a></h3>
<p><strong>Answer:</strong>
"Multi-layered secrets management:</p>
<ol>
<li>
<p><strong>Kubernetes Secrets</strong>:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  password: &lt;base64-encoded&gt;
</code></pre>
<ul>
<li>Encrypted at rest (if enabled)</li>
<li>RBAC protected</li>
<li>Mounted as volumes or env vars</li>
</ul>
</li>
<li>
<p><strong>AWS Secrets Manager Integration</strong>:</p>
<pre><code class="language-hcl">data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "production/database/password"
}
</code></pre>
<ul>
<li>External secrets management</li>
<li>Automatic rotation</li>
<li>Audit logging</li>
</ul>
</li>
<li>
<p><strong>Sealed Secrets</strong> (optional):</p>
<ul>
<li>Encrypt secrets in Git</li>
<li>Decrypt in cluster</li>
<li>GitOps friendly</li>
</ul>
</li>
</ol>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Never commit secrets to Git</li>
<li>Use external secrets manager for production</li>
<li>Rotate secrets regularly</li>
<li>Limit secret access via RBAC</li>
<li>Audit secret access"</li>
</ul>
<h3 id="q38-how-does-rbac-work-in-your-argocd-setup"><a class="header" href="#q38-how-does-rbac-work-in-your-argocd-setup">Q38: "How does RBAC work in your ArgoCD setup?"</a></h3>
<p><strong>Answer:</strong>
"ArgoCD RBAC configuration:</p>
<p><strong>ConfigMap</strong>:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-rbac-cm
data:
  policy.default: role:readonly
  policy.csv: |
    p, role:admin, applications, *, */*, allow
    p, role:admin, clusters, get, *, allow
    g, admins, role:admin
</code></pre>
<p><strong>Roles</strong>:</p>
<ul>
<li><strong>readonly</strong>: Default role, read-only access</li>
<li><strong>admin</strong>: Full access to applications and clusters</li>
</ul>
<p><strong>Policies</strong>:</p>
<ul>
<li><code>p</code>: Policy definition (subject, resource, action, object, effect)</li>
<li><code>g</code>: Group membership</li>
</ul>
<p><strong>Access Control</strong>:</p>
<ul>
<li>Application-level permissions</li>
<li>Cluster-level permissions</li>
<li>Project-based isolation</li>
<li>OIDC integration (optional)</li>
</ul>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Least privilege principle</li>
<li>Separate roles for different teams</li>
<li>Regular access reviews</li>
<li>Audit access logs"</li>
</ul>
<h2 id="infrastructure-questions-2"><a class="header" href="#infrastructure-questions-2">Infrastructure Questions</a></h2>
<h3 id="q39-how-do-you-manage-terraform-state-in-your-infrastructure"><a class="header" href="#q39-how-do-you-manage-terraform-state-in-your-infrastructure">Q39: "How do you manage Terraform state in your infrastructure?"</a></h3>
<p><strong>Answer:</strong>
"Terraform state management:</p>
<p><strong>Current Setup</strong>:</p>
<ul>
<li>Local state file (for demo/single-user)</li>
<li>State file backed up to Git (not recommended for production)</li>
</ul>
<p><strong>Production Best Practices</strong>:</p>
<ol>
<li>
<p><strong>Remote State Backend</strong>:</p>
<pre><code class="language-hcl">terraform {
  backend "s3" {
    bucket = "terraform-state-bucket"
    key    = "eks-cluster/terraform.tfstate"
    region = "us-east-1"
    encrypt = true
  }
}
</code></pre>
<ul>
<li>S3 for state storage</li>
<li>DynamoDB for state locking</li>
<li>Encryption enabled</li>
</ul>
</li>
<li>
<p><strong>State Locking</strong>:</p>
<ul>
<li>Prevents concurrent modifications</li>
<li>Uses DynamoDB table</li>
<li>Automatic lock release</li>
</ul>
</li>
<li>
<p><strong>State Security</strong>:</p>
<ul>
<li>Encrypted at rest</li>
<li>Access controlled via IAM</li>
<li>Versioned in S3</li>
<li>Backup and recovery</li>
</ul>
</li>
</ol>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Team collaboration</li>
<li>State consistency</li>
<li>Disaster recovery</li>
<li>Audit trail"</li>
</ul>
<h3 id="q40-how-do-you-handle-eks-cluster-upgrades"><a class="header" href="#q40-how-do-you-handle-eks-cluster-upgrades">Q40: "How do you handle EKS cluster upgrades?"</a></h3>
<p><strong>Answer:</strong>
"EKS cluster upgrade strategy:</p>
<p><strong>Control Plane Upgrade</strong>:</p>
<ol>
<li><strong>AWS Managed</strong>: Control plane upgrades via AWS Console/CLI</li>
<li><strong>Zero Downtime</strong>: AWS handles upgrade automatically</li>
<li><strong>Version Compatibility</strong>: Check Kubernetes version compatibility</li>
</ol>
<p><strong>Node Group Upgrade</strong>:</p>
<ol>
<li><strong>Create New Node Group</strong>: New nodes with updated AMI</li>
<li><strong>Drain Old Nodes</strong>: <code>kubectl drain</code> to move workloads</li>
<li><strong>Verify</strong>: Ensure all pods are running on new nodes</li>
<li><strong>Delete Old Node Group</strong>: Remove old nodes</li>
</ol>
<p><strong>Application Upgrade</strong>:</p>
<ol>
<li><strong>Git Update</strong>: Update manifests in Git</li>
<li><strong>ArgoCD Sync</strong>: Automatic sync via GitOps</li>
<li><strong>Rolling Update</strong>: Kubernetes rolling update strategy</li>
<li><strong>Health Checks</strong>: Readiness probes validate deployment</li>
</ol>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Test upgrades in staging first</li>
<li>Upgrade control plane before nodes</li>
<li>Use rolling updates for zero downtime</li>
<li>Monitor during upgrades</li>
<li>Have rollback plan ready"</li>
</ul>
<h2 id="advanced-scaling-questions"><a class="header" href="#advanced-scaling-questions">Advanced Scaling Questions</a></h2>
<h3 id="q41-how-do-you-configure-hpa-for-different-workloads"><a class="header" href="#q41-how-do-you-configure-hpa-for-different-workloads">Q41: "How do you configure HPA for different workloads?"</a></h3>
<p><strong>Answer:</strong>
"HPA configuration strategies:</p>
<p><strong>CPU-Based Scaling</strong>:</p>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
spec:
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
</code></pre>
<p><strong>Memory-Based Scaling</strong>:</p>
<pre><code class="language-yaml">metrics:
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
</code></pre>
<p><strong>Custom Metrics Scaling</strong>:</p>
<pre><code class="language-yaml">metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
</code></pre>
<p><strong>Scaling Behavior</strong>:</p>
<pre><code class="language-yaml">behavior:
  scaleDown:
    stabilizationWindowSeconds: 300
    policies:
      - type: Percent
        value: 50
  scaleUp:
    stabilizationWindowSeconds: 0
    policies:
      - type: Percent
        value: 100
</code></pre>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Set appropriate min/max replicas</li>
<li>Use multiple metrics for better decisions</li>
<li>Configure stabilization windows</li>
<li>Test scaling behavior under load"</li>
</ul>
<h3 id="q42-how-does-cluster-autoscaler-work-with-your-node-groups"><a class="header" href="#q42-how-does-cluster-autoscaler-work-with-your-node-groups">Q42: "How does Cluster Autoscaler work with your node groups?"</a></h3>
<p><strong>Answer:</strong>
"Cluster Autoscaler integration:</p>
<p><strong>Node Group Configuration</strong>:</p>
<pre><code class="language-hcl">eks_managed_node_groups = {
  application = {
    name = "application-nodes"
    min_size     = 1
    max_size     = 10
    desired_size = 3
    
    labels = {
      "k8s.io/cluster-autoscaler/enabled" = "true"
      "k8s.io/cluster-autoscaler/${cluster_name}" = "owned"
    }
  }
}
</code></pre>
<p><strong>How It Works</strong>:</p>
<ol>
<li><strong>Unschedulable Pods</strong>: Cluster Autoscaler monitors pods that can't be scheduled</li>
<li><strong>Node Addition</strong>: Adds nodes when pods are pending</li>
<li><strong>Node Removal</strong>: Removes nodes when underutilized</li>
<li><strong>Pod Disruption Budgets</strong>: Respects PDBs during scale-down</li>
</ol>
<p><strong>Scaling Triggers</strong>:</p>
<ul>
<li>Pods pending due to insufficient resources</li>
<li>Node utilization below threshold</li>
<li>Pod affinity/anti-affinity requirements</li>
</ul>
<p><strong>Configuration</strong>:</p>
<ul>
<li>Expansion strategy: least-waste (preferred)</li>
<li>Scale-down delay: 10 minutes</li>
<li>Node utilization threshold: 50%</li>
</ul>
<p>This ensures optimal resource utilization and cost efficiency."</p>
<h2 id="troubleshooting-questions"><a class="header" href="#troubleshooting-questions">Troubleshooting Questions</a></h2>
<h3 id="q43-how-do-you-troubleshoot-argocd-sync-failures"><a class="header" href="#q43-how-do-you-troubleshoot-argocd-sync-failures">Q43: "How do you troubleshoot ArgoCD sync failures?"</a></h3>
<p><strong>Answer:</strong>
"ArgoCD troubleshooting steps:</p>
<ol>
<li>
<p><strong>Check Application Status</strong>:</p>
<pre><code class="language-bash">argocd app get &lt;app-name&gt;
argocd app get &lt;app-name&gt; --refresh
</code></pre>
</li>
<li>
<p><strong>View Sync Operation</strong>:</p>
<pre><code class="language-bash">argocd app sync &lt;app-name&gt; --dry-run
argocd app sync &lt;app-name&gt; --prune
</code></pre>
</li>
<li>
<p><strong>Check Logs</strong>:</p>
<pre><code class="language-bash">argocd app logs &lt;app-name&gt;
kubectl logs -n argocd deployment/argocd-application-controller
</code></pre>
</li>
<li>
<p><strong>Verify Repository Access</strong>:</p>
<pre><code class="language-bash">argocd repo list
argocd repo get &lt;repo-url&gt;
</code></pre>
</li>
<li>
<p><strong>Check Resource Events</strong>:</p>
<pre><code class="language-bash">kubectl get events -n &lt;namespace&gt;
kubectl describe &lt;resource&gt; -n &lt;namespace&gt;
</code></pre>
</li>
</ol>
<p><strong>Common Issues</strong>:</p>
<ul>
<li>Repository authentication failures</li>
<li>Manifest validation errors</li>
<li>Resource conflicts</li>
<li>Network connectivity issues</li>
<li>RBAC permission problems"</li>
</ul>
<h3 id="q44-how-do-you-debug-prometheus-scraping-issues"><a class="header" href="#q44-how-do-you-debug-prometheus-scraping-issues">Q44: "How do you debug Prometheus scraping issues?"</a></h3>
<p><strong>Answer:</strong>
"Prometheus troubleshooting:</p>
<ol>
<li>
<p><strong>Check Targets</strong>:</p>
<ul>
<li>Access Prometheus UI: <code>http://localhost:9090/targets</code></li>
<li>View scrape status for each target</li>
<li>Check for down/unreachable targets</li>
</ul>
</li>
<li>
<p><strong>Verify Service Discovery</strong>:</p>
<pre><code class="language-bash">kubectl get pods -n &lt;namespace&gt; -o yaml | grep prometheus.io
</code></pre>
</li>
<li>
<p><strong>Check Prometheus Logs</strong>:</p>
<pre><code class="language-bash">kubectl logs -n monitoring deployment/prometheus
</code></pre>
</li>
<li>
<p><strong>Test Scraping Manually</strong>:</p>
<pre><code class="language-bash">kubectl port-forward -n monitoring svc/prometheus 9090:9090
curl http://localhost:9090/api/v1/targets
</code></pre>
</li>
<li>
<p><strong>Verify Metrics Endpoint</strong>:</p>
<pre><code class="language-bash">kubectl exec -n &lt;namespace&gt; &lt;pod-name&gt; -- wget -qO- http://localhost:9090/metrics
</code></pre>
</li>
</ol>
<p><strong>Common Issues</strong>:</p>
<ul>
<li>Missing pod annotations</li>
<li>Network policies blocking access</li>
<li>Incorrect service discovery config</li>
<li>Authentication/authorization issues"</li>
</ul>
<h3 id="q45-how-do-you-troubleshoot-opa-policy-violations"><a class="header" href="#q45-how-do-you-troubleshoot-opa-policy-violations">Q45: "How do you troubleshoot OPA policy violations?"</a></h3>
<p><strong>Answer:</strong>
"OPA troubleshooting:</p>
<ol>
<li>
<p><strong>Check Gatekeeper Status</strong>:</p>
<pre><code class="language-bash">kubectl get pods -n gatekeeper-system
kubectl logs -n gatekeeper-system -l control-plane=controller-manager
</code></pre>
</li>
<li>
<p><strong>View Constraint Status</strong>:</p>
<pre><code class="language-bash">kubectl get K8sRequiredNonRoot
kubectl describe K8sRequiredNonRoot &lt;constraint-name&gt;
</code></pre>
</li>
<li>
<p><strong>Check Violations</strong>:</p>
<pre><code class="language-bash">kubectl get K8sRequiredNonRoot &lt;constraint-name&gt; -o jsonpath='{.status.violations}'
</code></pre>
</li>
<li>
<p><strong>Test Policy</strong>:</p>
<pre><code class="language-bash"># Try to create violating resource
kubectl run test-pod --image=nginx -n online-boutique
# Check error message
</code></pre>
</li>
<li>
<p><strong>Verify Enforcement Mode</strong>:</p>
<pre><code class="language-bash">kubectl get K8sRequiredNonRoot &lt;constraint-name&gt; -o yaml | grep enforcementAction
</code></pre>
</li>
</ol>
<p><strong>Common Issues</strong>:</p>
<ul>
<li>Constraint templates not installed</li>
<li>CRDs not ready</li>
<li>Enforcement mode misconfiguration</li>
<li>Policy logic errors in Rego"</li>
</ul>
<h2 id="cost-optimization-questions-1"><a class="header" href="#cost-optimization-questions-1">Cost Optimization Questions</a></h2>
<h3 id="q46-how-do-you-optimize-costs-in-your-eks-cluster"><a class="header" href="#q46-how-do-you-optimize-costs-in-your-eks-cluster">Q46: "How do you optimize costs in your EKS cluster?"</a></h3>
<p><strong>Answer:</strong>
"Cost optimization strategies:</p>
<ol>
<li>
<p><strong>Right-Sizing</strong>:</p>
<ul>
<li>Analyze actual resource usage</li>
<li>Set appropriate requests/limits</li>
<li>Use VPA recommendations</li>
</ul>
</li>
<li>
<p><strong>Auto-Scaling</strong>:</p>
<ul>
<li>HPA for pod scaling</li>
<li>Cluster Autoscaler for node scaling</li>
<li>Scale down during low usage</li>
</ul>
</li>
<li>
<p><strong>Instance Types</strong>:</p>
<ul>
<li>Use appropriate instance sizes</li>
<li>Consider spot instances for non-critical workloads</li>
<li>Reserved instances for predictable workloads</li>
</ul>
</li>
<li>
<p><strong>Resource Quotas</strong>:</p>
<ul>
<li>Set namespace-level quotas</li>
<li>Prevent resource waste</li>
<li>Enforce via OPA policies</li>
</ul>
</li>
<li>
<p><strong>Monitoring</strong>:</p>
<ul>
<li>Track resource usage</li>
<li>Identify idle resources</li>
<li>Cost allocation by namespace/team</li>
</ul>
</li>
</ol>
<p><strong>Expected Costs</strong>:</p>
<ul>
<li>EKS Control Plane: ~$73/month</li>
<li>Worker Nodes: Variable based on usage</li>
<li>Load Balancers: ~$20-30/month each</li>
<li>Data Transfer: Variable</li>
</ul>
<p><strong>Optimization Results</strong>:</p>
<ul>
<li>30-40% cost reduction through right-sizing</li>
<li>20-30% savings with spot instances</li>
<li>Better resource utilization"</li>
</ul>
<h2 id="disaster-recovery-questions"><a class="header" href="#disaster-recovery-questions">Disaster Recovery Questions</a></h2>
<h3 id="q47-what-is-your-disaster-recovery-strategy"><a class="header" href="#q47-what-is-your-disaster-recovery-strategy">Q47: "What is your disaster recovery strategy?"</a></h3>
<p><strong>Answer:</strong>
"Disaster recovery approach:</p>
<ol>
<li>
<p><strong>Infrastructure as Code</strong>:</p>
<ul>
<li>All infrastructure in Terraform</li>
<li>Quick recreation from Git</li>
<li>Version controlled</li>
</ul>
</li>
<li>
<p><strong>GitOps for Applications</strong>:</p>
<ul>
<li>All applications in Git</li>
<li>Automatic deployment via ArgoCD</li>
<li>Reproducible deployments</li>
</ul>
</li>
<li>
<p><strong>Backup Strategy</strong>:</p>
<ul>
<li><strong>ETCD Backups</strong>: EKS control plane (AWS managed)</li>
<li><strong>Application Data</strong>: Database backups, persistent volumes</li>
<li><strong>Configuration</strong>: All in Git (source of truth)</li>
</ul>
</li>
<li>
<p><strong>Recovery Process</strong>:</p>
<ul>
<li>Recreate cluster from Terraform</li>
<li>Restore from backups</li>
<li>ArgoCD syncs applications automatically</li>
<li>Verify with sanity/availability tests</li>
</ul>
</li>
<li>
<p><strong>RTO/RPO</strong>:</p>
<ul>
<li><strong>RTO</strong>: &lt; 1 hour (recovery time objective)</li>
<li><strong>RPO</strong>: &lt; 15 minutes (recovery point objective)</li>
</ul>
</li>
</ol>
<p><strong>Testing</strong>:</p>
<ul>
<li>Regular DR drills</li>
<li>Test cluster recreation</li>
<li>Verify backup restoration</li>
<li>Document procedures"</li>
</ul>
<h2 id="advanced-integration-questions"><a class="header" href="#advanced-integration-questions">Advanced Integration Questions</a></h2>
<h3 id="q48-how-would-you-integrate-this-platform-with-cicd-pipelines"><a class="header" href="#q48-how-would-you-integrate-this-platform-with-cicd-pipelines">Q48: "How would you integrate this platform with CI/CD pipelines?"</a></h3>
<p><strong>Answer:</strong>
"CI/CD integration strategy:</p>
<ol>
<li>
<p><strong>GitHub Actions Workflow</strong>:</p>
<pre><code class="language-yaml">- name: Deploy Infrastructure
  run: terraform apply

- name: Run Sanity Tests
  run: kubectl apply -f sanity-test-job.yaml

- name: Verify Deployment
  run: argocd app wait monitoring-stack --health
</code></pre>
</li>
<li>
<p><strong>Pipeline Stages</strong>:</p>
<ul>
<li><strong>Build</strong>: Container image builds</li>
<li><strong>Test</strong>: Unit tests, integration tests</li>
<li><strong>Deploy</strong>: ArgoCD syncs from Git</li>
<li><strong>Validate</strong>: Sanity tests, availability tests</li>
<li><strong>Monitor</strong>: Prometheus alerts</li>
</ul>
</li>
<li>
<p><strong>GitOps Integration</strong>:</p>
<ul>
<li>Changes committed to Git</li>
<li>ArgoCD automatically syncs</li>
<li>No manual kubectl commands</li>
<li>Full audit trail</li>
</ul>
</li>
<li>
<p><strong>Testing Integration</strong>:</p>
<ul>
<li>Smoke tests after deployment</li>
<li>Performance tests on schedule</li>
<li>Automated rollback on failure</li>
</ul>
</li>
</ol>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Automated deployments</li>
<li>Consistent process</li>
<li>Fast feedback</li>
<li>Easy rollbacks"</li>
</ul>
<h3 id="q49-how-would-you-extend-this-platform-for-multi-cluster-management"><a class="header" href="#q49-how-would-you-extend-this-platform-for-multi-cluster-management">Q49: "How would you extend this platform for multi-cluster management?"</a></h3>
<p><strong>Answer:</strong>
"Multi-cluster extension:</p>
<ol>
<li>
<p><strong>ArgoCD Multi-Cluster</strong>:</p>
<pre><code class="language-yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
spec:
  destination:
    server: https://prod-cluster.example.com
</code></pre>
</li>
<li>
<p><strong>Cluster Management</strong>:</p>
<ul>
<li>Register clusters in ArgoCD</li>
<li>Manage from single ArgoCD instance</li>
<li>Environment-specific applications</li>
</ul>
</li>
<li>
<p><strong>Federation</strong>:</p>
<ul>
<li>Prometheus federation for metrics</li>
<li>Centralized logging</li>
<li>Cross-cluster monitoring</li>
</ul>
</li>
<li>
<p><strong>GitOps Patterns</strong>:</p>
<ul>
<li>Environment-specific branches</li>
<li>Cluster-specific overlays (Kustomize)</li>
<li>Centralized configuration</li>
</ul>
</li>
</ol>
<p><strong>Use Cases</strong>:</p>
<ul>
<li>Dev/Staging/Production separation</li>
<li>Multi-region deployments</li>
<li>Disaster recovery clusters</li>
<li>Blue-green deployments"</li>
</ul>
<h3 id="q50-how-do-you-ensure-platform-reliability-and-observability"><a class="header" href="#q50-how-do-you-ensure-platform-reliability-and-observability">Q50: "How do you ensure platform reliability and observability?"</a></h3>
<p><strong>Answer:</strong>
"Comprehensive reliability strategy:</p>
<ol>
<li>
<p><strong>Monitoring</strong>:</p>
<ul>
<li>Prometheus for metrics</li>
<li>Grafana for visualization</li>
<li>Alerting on thresholds</li>
</ul>
</li>
<li>
<p><strong>Logging</strong>:</p>
<ul>
<li>Loki for log aggregation</li>
<li>Promtail for collection</li>
<li>Centralized querying</li>
</ul>
</li>
<li>
<p><strong>Testing</strong>:</p>
<ul>
<li>Sanity tests (health checks)</li>
<li>Availability tests (SRE metrics)</li>
<li>k6 performance tests</li>
</ul>
</li>
<li>
<p><strong>Observability</strong>:</p>
<ul>
<li>Metrics, logs, traces (3 pillars)</li>
<li>Dashboards for visibility</li>
<li>Alerts for proactive response</li>
</ul>
</li>
<li>
<p><strong>Reliability</strong>:</p>
<ul>
<li>High availability (multi-replica)</li>
<li>Auto-scaling (HPA, Cluster Autoscaler)</li>
<li>Self-healing (ArgoCD, health probes)</li>
<li>Circuit breakers (application level)</li>
</ul>
</li>
</ol>
<p><strong>SLOs</strong>:</p>
<ul>
<li>Uptime: 99.9%</li>
<li>Response Time: p95 &lt; 500ms</li>
<li>Error Rate: &lt; 0.1%</li>
</ul>
<p>This ensures production-ready reliability and full observability."</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
